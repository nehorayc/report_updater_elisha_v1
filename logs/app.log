2025-12-23 20:43:25.330 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:43:25.330 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:43:25.330 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:43:25.330 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:43:25.331 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:43:25.331 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:43:25.331 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:43:25.331 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:43:31.996 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:43:31.996 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:43:31.996 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:43:31.996 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:43:31.997 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:43:31.997 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:43:31.997 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:43:31.997 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:43:31.997 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:43:31.997 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:43:31.997 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:43:31.997 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:57:39.388 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:57:39.388 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:57:39.388 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:57:39.388 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:57:39.389 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:57:39.389 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:57:39.389 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:57:39.389 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:57:45.386 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:57:45.386 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:57:45.386 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:57:45.386 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:57:45.386 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:57:45.386 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:57:45.386 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:57:45.386 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:57:45.386 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:57:45.386 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:57:45.386 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:57:45.386 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:44.819 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 20:58:44.819 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 20:58:44.819 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 20:58:44.819 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 20:58:44.820 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:58:44.820 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:58:44.820 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:58:44.820 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:58:48.969 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:58:48.969 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:58:48.969 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:58:48.969 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:58:48.970 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:58:48.970 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:58:48.970 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:58:48.970 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:58:48.970 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:58:48.970 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:58:48.970 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:58:48.970 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 21:14:44.441 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 21:14:44.441 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 21:14:44.441 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 21:14:44.441 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 21:14:45.102 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 21:14:45.102 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 21:14:45.102 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 21:14:45.102 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 21:14:49.854 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-23 21:14:49.854 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-23 21:14:49.854 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-23 21:14:49.854 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-23 21:14:49.854 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-23 21:14:49.854 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-23 21:14:49.854 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-23 21:14:49.854 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-23 21:14:49.855 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 21:14:49.855 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 21:14:49.855 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 21:14:49.855 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:27:49.696 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-24 10:27:49.696 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-24 10:27:49.696 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-24 10:27:49.696 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-24 10:27:50.456 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-24 10:27:50.456 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-24 10:27:50.456 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-24 10:27:50.456 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-24 10:27:55.243 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-24 10:27:55.243 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-24 10:27:55.243 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-24 10:27:55.243 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-24 10:27:55.245 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-24 10:27:55.245 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-24 10:27:55.245 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-24 10:27:55.245 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-24 10:27:55.247 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-24 10:27:55.247 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-24 10:27:55.247 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-24 10:27:55.247 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-27 23:55:13.299 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-27 23:55:13.299 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-27 23:55:13.299 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-27 23:55:13.299 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-27 23:55:13.917 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-27 23:55:13.917 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-27 23:55:13.917 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-27 23:55:13.917 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-27 23:55:18.345 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-27 23:55:18.345 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-27 23:55:18.345 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-27 23:55:18.345 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-27 23:55:18.346 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-27 23:55:18.346 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-27 23:55:18.346 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-27 23:55:18.346 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-27 23:55:18.347 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-27 23:55:18.347 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-27 23:55:18.347 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-27 23:55:18.347 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:17:48.149 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-28 15:17:48.149 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-28 15:17:48.149 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-28 15:17:48.149 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-28 15:17:48.737 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-28 15:17:48.737 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-28 15:17:48.737 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-28 15:17:48.737 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-28 15:17:52.785 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-28 15:17:52.785 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-28 15:17:52.785 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-28 15:17:52.785 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-28 15:17:52.785 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-28 15:17:52.785 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-28 15:17:52.785 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-28 15:17:52.785 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-28 15:17:52.787 | INFO     | __main__:<module>:133 - Report structure analysis finalized
2025-12-28 15:17:52.787 | INFO     | __main__:<module>:133 - Report structure analysis finalized
2025-12-28 15:17:52.787 | INFO     | __main__:<module>:133 - Report structure analysis finalized
2025-12-28 15:17:52.787 | INFO     | __main__:<module>:133 - Report structure analysis finalized
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:44:42.692 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-29 11:44:42.692 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-29 11:44:42.692 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-29 11:44:42.692 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-29 11:44:42.692 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-29 11:44:43.307 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-29 11:44:43.307 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-29 11:44:43.307 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-29 11:44:43.307 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-29 11:44:43.307 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-29 11:44:47.972 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-29 11:44:47.972 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-29 11:44:47.972 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-29 11:44:47.972 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-29 11:44:47.972 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-29 11:44:47.972 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-29 11:44:47.972 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-29 11:44:47.972 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-29 11:44:47.972 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-29 11:44:47.972 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-29 11:44:47.974 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-29 11:44:47.974 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-29 11:44:47.974 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-29 11:44:47.974 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-29 11:44:47.974 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2026-01-07 09:09:09.396 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:09:09.396 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:09:09.396 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:09:09.396 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:09:09.396 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:09:09.986 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:09:09.986 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:09:09.986 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:09:09.986 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:09:09.986 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:09:14.171 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:09:14.171 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:09:14.171 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:09:14.171 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:09:14.171 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:09:14.171 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:09:14.171 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:09:14.171 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:09:14.171 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:09:14.171 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:09:14.174 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 09:09:14.174 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 09:09:14.174 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 09:09:14.174 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 09:09:14.174 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 10:14:50.470 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:14:50.470 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:14:50.470 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:14:50.470 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:14:50.847 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:14:50.847 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:14:50.847 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:14:50.847 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:14:55.553 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:14:55.553 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:14:55.553 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:14:55.553 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:14:55.554 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:14:55.554 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:14:55.554 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:14:55.554 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:14:55.555 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:14:55.555 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:14:55.555 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:14:55.555 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 14:36:12.208 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 14:36:12.208 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 14:36:12.208 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 14:36:12.208 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 14:36:12.208 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 14:36:12.780 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:36:12.780 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:36:12.780 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:36:12.780 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:36:12.780 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:36:17.840 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 14:36:17.840 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 14:36:17.840 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 14:36:17.840 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 14:36:17.840 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 14:36:17.841 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 14:36:17.841 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 14:36:17.841 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 14:36:17.841 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 14:36:17.841 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 14:36:17.843 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 14:36:17.843 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 14:36:17.843 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 14:36:17.843 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 14:36:17.843 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:15.837 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:15.837 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:15.837 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:15.837 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:15.837 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:16.224 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:16.224 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:16.224 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:16.224 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:16.224 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002401A86BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002401A8B0220>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002401B401C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000002401B51A340>
    └ ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
        └ <function exec_func_with_error_handling at 0x000002401B4A4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000024018F322C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002401B7D3C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000002402057FA60>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000240204F3E20>
               └ <google.genai.client.Client object at 0x000002402058B850>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000240200AE980>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002402000EAC0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002402000E840>
               └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002402000E7A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
           │    └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002401EF9DC60>
         └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002402072A700>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002401EF9D1C0>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002401B1F2FC0>
          │    └ <Future at 0x2402075f150 state=finished raised ClientError>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002401EFB85E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002401EFB8720>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002401A86BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002401A8B0220>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002401B401C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000002401B51A340>
    └ ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
        └ <function exec_func_with_error_handling at 0x000002401B4A4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000024018F322C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002401B7D3C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000002402057FA60>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000240204F3E20>
               └ <google.genai.client.Client object at 0x000002402058B850>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000240200AE980>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002402000EAC0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002402000E840>
               └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002402000E7A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
           │    └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002401EF9DC60>
         └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002402072A700>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002401EF9D1C0>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002401B1F2FC0>
          │    └ <Future at 0x2402075f150 state=finished raised ClientError>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002401EFB85E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002401EFB8720>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002401A86BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002401A8B0220>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002401B401C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000002401B51A340>
    └ ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
        └ <function exec_func_with_error_handling at 0x000002401B4A4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000024018F322C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002401B7D3C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000002402057FA60>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000240204F3E20>
               └ <google.genai.client.Client object at 0x000002402058B850>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000240200AE980>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002402000EAC0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002402000E840>
               └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002402000E7A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
           │    └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002401EF9DC60>
         └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002402072A700>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002401EF9D1C0>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002401B1F2FC0>
          │    └ <Future at 0x2402075f150 state=finished raised ClientError>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002401EFB85E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002401EFB8720>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002401A86BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002401A8B0220>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002401B401C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000002401B51A340>
    └ ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
        └ <function exec_func_with_error_handling at 0x000002401B4A4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000024018F322C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002401B7D3C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000002402057FA60>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000240204F3E20>
               └ <google.genai.client.Client object at 0x000002402058B850>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000240200AE980>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002402000EAC0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002402000E840>
               └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002402000E7A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
           │    └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002401EF9DC60>
         └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002402072A700>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002401EF9D1C0>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002401B1F2FC0>
          │    └ <Future at 0x2402075f150 state=finished raised ClientError>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002401EFB85E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002401EFB8720>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002401A86BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002401A8B0220>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002401B401C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000002401B51A340>
    └ ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
        └ <function exec_func_with_error_handling at 0x000002401B4A4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000024018F322C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002401B7D3C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000002402057FA60>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000240204F3E20>
               └ <google.genai.client.Client object at 0x000002402058B850>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000240200AE980>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002402000EAC0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002402000E840>
               └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002402000E7A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
           │    └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002401EF9DC60>
         └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002402072A700>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002401EF9D1C0>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002401B1F2FC0>
          │    └ <Future at 0x2402075f150 state=finished raised ClientError>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002401EFB85E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002401EFB8720>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.574 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:16.574 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:16.574 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:16.574 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:16.574 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:58.257 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:58.257 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:58.257 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:58.650 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:58.650 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:58.650 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:58.867 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.867 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.867 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.868 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000247F4BDBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000247F4C20220>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000247F5771C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x00000247F588A340>
    └ ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_script_path='app.py', _session_state={chapters: [], $$...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
        └ <function exec_func_with_error_handling at 0x00000247F5814D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000247F2FCA050, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 141, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000247F5B43C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x00000247F9900360>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000247F9894680>
               └ <google.genai.client.Client object at 0x00000247F9A0B910>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000247F93E3380>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x00000247F935F4C0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x00000247F935F240>
               └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x00000247F935F1A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
           │    └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x00000247F92D6660>
         └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000247F9A05C60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x00000247F92D5BC0>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x00000247F5562FC0>
          │    └ <Future at 0x247f9ad4610 state=finished raised ClientError>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x00000247F92ECFE0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x00000247F92ED120>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.868 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000247F4BDBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000247F4C20220>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000247F5771C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x00000247F588A340>
    └ ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_script_path='app.py', _session_state={chapters: [], $$...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
        └ <function exec_func_with_error_handling at 0x00000247F5814D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000247F2FCA050, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 141, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000247F5B43C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x00000247F9900360>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000247F9894680>
               └ <google.genai.client.Client object at 0x00000247F9A0B910>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000247F93E3380>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x00000247F935F4C0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x00000247F935F240>
               └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x00000247F935F1A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
           │    └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x00000247F92D6660>
         └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000247F9A05C60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x00000247F92D5BC0>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x00000247F5562FC0>
          │    └ <Future at 0x247f9ad4610 state=finished raised ClientError>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x00000247F92ECFE0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x00000247F92ED120>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.868 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000247F4BDBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000247F4C20220>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000247F5771C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x00000247F588A340>
    └ ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_script_path='app.py', _session_state={chapters: [], $$...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
        └ <function exec_func_with_error_handling at 0x00000247F5814D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000247F2FCA050, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 141, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000247F5B43C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x00000247F9900360>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000247F9894680>
               └ <google.genai.client.Client object at 0x00000247F9A0B910>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000247F93E3380>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x00000247F935F4C0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x00000247F935F240>
               └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x00000247F935F1A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
           │    └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x00000247F92D6660>
         └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000247F9A05C60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x00000247F92D5BC0>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x00000247F5562FC0>
          │    └ <Future at 0x247f9ad4610 state=finished raised ClientError>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x00000247F92ECFE0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x00000247F92ED120>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.887 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 15:04:58.887 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 15:04:58.887 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 19:16:57.307 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 19:16:57.307 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 19:16:57.307 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 19:16:57.307 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 19:16:57.890 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:16:57.890 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:16:57.890 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:16:57.890 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:17:02.488 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 19:17:02.488 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 19:17:02.488 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 19:17:02.488 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:88 - Expecting ',' delimiter: line 6 column 3 (char 435)
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001CDACEFBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001CDACF40220>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001CDADA91C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001CDADBAA340>
    └ ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
        └ <function exec_func_with_error_handling at 0x000001CDADB34D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001CDAAF41EB0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001CDADE63C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001CDB1C01D00>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 83, in analyze_all_chapters
    results = json.loads(response.text)
              │    │     │        └ <property object at 0x000001CDB1052CF0>
              │    │     └ GenerateContentResponse(
              │    │         automatic_function_calling_history=[],
              │    │         candidates=[
              │    │           Candidate(
              │    │             content=Content(
              │    │             ...
              │    └ <function loads at 0x000001CDAD1D6160>
              └ <module 'json' from 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib...

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           │                │      └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
           │                └ <function JSONDecoder.decode at 0x000001CDAD1D5A80>
           └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    │          │      └ <built-in method match of re.Pattern object at 0x000001CDAD1ADD80>
               │    │          └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <function JSONDecoder.raw_decode at 0x000001CDAD1D5B20>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               │    │         │  └ 0
               │    │         └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <_json.Scanner object at 0x000001CDAD19BBE0>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>

json.decoder.JSONDecodeError: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:88 - Expecting ',' delimiter: line 6 column 3 (char 435)
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001CDACEFBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001CDACF40220>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001CDADA91C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001CDADBAA340>
    └ ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
        └ <function exec_func_with_error_handling at 0x000001CDADB34D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001CDAAF41EB0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001CDADE63C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001CDB1C01D00>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 83, in analyze_all_chapters
    results = json.loads(response.text)
              │    │     │        └ <property object at 0x000001CDB1052CF0>
              │    │     └ GenerateContentResponse(
              │    │         automatic_function_calling_history=[],
              │    │         candidates=[
              │    │           Candidate(
              │    │             content=Content(
              │    │             ...
              │    └ <function loads at 0x000001CDAD1D6160>
              └ <module 'json' from 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib...

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           │                │      └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
           │                └ <function JSONDecoder.decode at 0x000001CDAD1D5A80>
           └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    │          │      └ <built-in method match of re.Pattern object at 0x000001CDAD1ADD80>
               │    │          └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <function JSONDecoder.raw_decode at 0x000001CDAD1D5B20>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               │    │         │  └ 0
               │    │         └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <_json.Scanner object at 0x000001CDAD19BBE0>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>

json.decoder.JSONDecodeError: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:88 - Expecting ',' delimiter: line 6 column 3 (char 435)
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001CDACEFBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001CDACF40220>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001CDADA91C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001CDADBAA340>
    └ ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
        └ <function exec_func_with_error_handling at 0x000001CDADB34D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001CDAAF41EB0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001CDADE63C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001CDB1C01D00>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 83, in analyze_all_chapters
    results = json.loads(response.text)
              │    │     │        └ <property object at 0x000001CDB1052CF0>
              │    │     └ GenerateContentResponse(
              │    │         automatic_function_calling_history=[],
              │    │         candidates=[
              │    │           Candidate(
              │    │             content=Content(
              │    │             ...
              │    └ <function loads at 0x000001CDAD1D6160>
              └ <module 'json' from 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib...

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           │                │      └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
           │                └ <function JSONDecoder.decode at 0x000001CDAD1D5A80>
           └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    │          │      └ <built-in method match of re.Pattern object at 0x000001CDAD1ADD80>
               │    │          └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <function JSONDecoder.raw_decode at 0x000001CDAD1D5B20>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               │    │         │  └ 0
               │    │         └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <_json.Scanner object at 0x000001CDAD19BBE0>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>

json.decoder.JSONDecodeError: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:88 - Expecting ',' delimiter: line 6 column 3 (char 435)
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001CDACEFBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001CDACF40220>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001CDADA91C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001CDADBAA340>
    └ ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
        └ <function exec_func_with_error_handling at 0x000001CDADB34D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001CDAAF41EB0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001CDADE63C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001CDB1C01D00>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 83, in analyze_all_chapters
    results = json.loads(response.text)
              │    │     │        └ <property object at 0x000001CDB1052CF0>
              │    │     └ GenerateContentResponse(
              │    │         automatic_function_calling_history=[],
              │    │         candidates=[
              │    │           Candidate(
              │    │             content=Content(
              │    │             ...
              │    └ <function loads at 0x000001CDAD1D6160>
              └ <module 'json' from 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib...

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           │                │      └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
           │                └ <function JSONDecoder.decode at 0x000001CDAD1D5A80>
           └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    │          │      └ <built-in method match of re.Pattern object at 0x000001CDAD1ADD80>
               │    │          └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <function JSONDecoder.raw_decode at 0x000001CDAD1D5B20>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               │    │         │  └ 0
               │    │         └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <_json.Scanner object at 0x000001CDAD19BBE0>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>

json.decoder.JSONDecodeError: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.503 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:17:02.503 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:17:02.503 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:17:02.503 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:50:16.203 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-07 19:50:16.203 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-07 19:50:16.203 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-07 19:50:16.579 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:50:16.579 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:50:16.579 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:99 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:99 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:99 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:100 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001F636A9BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001F636AE0220>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001F637631C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001F63774A340>
    └ ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_script_path='app.py', _session_state={api_key: 'AIzaSy...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
        └ <function exec_func_with_error_handling at 0x000001F6376D4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001F634F1DD00, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001F637A03C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001F63C796660>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 87, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x000001F63C71ECA0>
               └ <google.genai.client.Client object at 0x000001F636A67A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001F63C29D4E0>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001F63C205620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001F63C2053A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001F63C205300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
           │    └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001F63C19C7C0>
         └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001F63C843420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001F63C187CE0>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001F637422FC0>
          │    └ <Future at 0x1f63c970fd0 state=finished raised ClientError>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001F63C19F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001F63C19F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:100 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001F636A9BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001F636AE0220>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001F637631C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001F63774A340>
    └ ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_script_path='app.py', _session_state={api_key: 'AIzaSy...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
        └ <function exec_func_with_error_handling at 0x000001F6376D4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001F634F1DD00, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001F637A03C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001F63C796660>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 87, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x000001F63C71ECA0>
               └ <google.genai.client.Client object at 0x000001F636A67A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001F63C29D4E0>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001F63C205620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001F63C2053A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001F63C205300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
           │    └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001F63C19C7C0>
         └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001F63C843420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001F63C187CE0>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001F637422FC0>
          │    └ <Future at 0x1f63c970fd0 state=finished raised ClientError>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001F63C19F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001F63C19F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:100 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001F636A9BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001F636AE0220>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001F637631C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001F63774A340>
    └ ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_script_path='app.py', _session_state={api_key: 'AIzaSy...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
        └ <function exec_func_with_error_handling at 0x000001F6376D4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001F634F1DD00, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001F637A03C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001F63C796660>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 87, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x000001F63C71ECA0>
               └ <google.genai.client.Client object at 0x000001F636A67A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001F63C29D4E0>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001F63C205620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001F63C2053A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001F63C205300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
           │    └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001F63C19C7C0>
         └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001F63C843420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001F63C187CE0>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001F637422FC0>
          │    └ <Future at 0x1f63c970fd0 state=finished raised ClientError>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001F63C19F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001F63C19F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:17.020 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:50:17.020 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:50:17.020 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-08 09:27:30.290 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-08 09:27:30.290 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-08 09:27:30.290 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-08 09:27:30.893 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:27:30.893 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:27:30.893 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:27:35.564 | INFO     | processor:analyze_all_chapters:96 - Batch analysis successful
2026-01-08 09:27:35.564 | INFO     | processor:analyze_all_chapters:96 - Batch analysis successful
2026-01-08 09:27:35.564 | INFO     | processor:analyze_all_chapters:96 - Batch analysis successful
2026-01-08 09:27:35.566 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-08 09:27:35.566 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-08 09:27:35.566 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-08 09:44:52,765 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:44:53,189 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:44:53,190 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:44:53,191 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:44:53,208 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CBD3A39D10>
2026-01-08 09:44:53,208 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002CBD39C5520> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:44:53,272 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CBD73C7410>
2026-01-08 09:44:53,272 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:44:53,273 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:44:53,273 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:44:53,273 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:44:53,273 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:44:53,368 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:44:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=86'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:44:53,368 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 403 Forbidden"
2026-01-08 09:44:53,368 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:44:53,370 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:44:53,370 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:44:53,370 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:44:53,370 - processor - ERROR - Error in batch analysis: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 09:44:53,370 - processor - ERROR - 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 09:44:53,443 - __main__ - INFO - Report structure analysis finalized
2026-01-08 09:44:53,493 - httpcore.connection - DEBUG - close.started
2026-01-08 09:44:53,493 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:46:06,396 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:46:06,810 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:46:06,812 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:46:06,813 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:46:06,822 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CBD7497650>
2026-01-08 09:46:06,823 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002CBD39C5520> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:46:06,886 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CBD7209B10>
2026-01-08 09:46:06,887 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:46:06,887 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:46:06,887 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:46:06,887 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:46:06,887 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:46:11,779 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:46:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4868'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:46:11,779 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:46:11,779 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:46:11,779 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:46:11,780 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:46:11,780 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:46:11,781 - processor - INFO - Batch analysis successful
2026-01-08 09:46:11,781 - httpcore.connection - DEBUG - close.started
2026-01-08 09:46:11,781 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:46:11,783 - __main__ - INFO - Report structure analysis finalized
2026-01-08 09:47:59,637 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:48:00,017 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:48:00,017 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:48:00,018 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:48:00,031 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713CE7D0>
2026-01-08 09:48:00,032 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC6D9F6F00> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:48:00,100 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713CE710>
2026-01-08 09:48:00,100 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:48:00,100 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:48:00,100 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:48:00,100 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:48:00,100 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:48:05,075 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:48:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4953'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:48:05,076 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:48:05,076 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:48:05,077 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:48:05,077 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:48:05,077 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:48:05,077 - processor - INFO - Batch analysis successful
2026-01-08 09:48:05,077 - httpcore.connection - DEBUG - close.started
2026-01-08 09:48:05,078 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:48:05,079 - __main__ - INFO - Report structure analysis finalized
2026-01-08 09:48:11,993 - researcher - INFO - Researching 'This chapter introduces the recent surge in Artificial Intelligence's popularity, specifically noting the impact of ChatGPT's release in late 2022. It sets the scope of the report to summarize the industry's state as of mid-2023. The chapter establishes the context for understanding current AI developments and their rapid advancements.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 09:48:12,360 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:48:12,362 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:48:12,372 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713AF650>
2026-01-08 09:48:12,372 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC71376180> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:48:12,437 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713026D0>
2026-01-08 09:48:12,437 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:48:12,437 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:48:12,437 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:48:12,437 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:48:12,437 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:48:29,927 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:48:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=17481'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:48:29,927 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 09:48:29,927 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:48:29,927 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:48:29,929 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:48:29,929 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:48:29,929 - researcher - ERROR - Web research failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 09:48:29,929 - researcher - INFO - Searching OpenAlex for: This chapter introduces the recent surge in Artificial Intelligence's popularity, specifically noting the impact of ChatGPT's release in late 2022. It sets the scope of the report to summarize the industry's state as of mid-2023. The chapter establishes the context for understanding current AI developments and their rapid advancements.
2026-01-08 09:48:29,948 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 09:48:31,843 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20introduces%20the%20recent%20surge%20in%20Artificial%20Intelligence's%20popularity,%20specifically%20noting%20the%20impact%20of%20ChatGPT's%20release%20in%20late%202022.%20It%20sets%20the%20scope%20of%20the%20report%20to%20summarize%20the%20industry's%20state%20as%20of%20mid-2023.%20The%20chapter%20establishes%20the%20context%20for%20understanding%20current%20AI%20developments%20and%20their%20rapid%20advancements.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 09:48:31,845 - httpcore.connection - DEBUG - close.started
2026-01-08 09:48:31,845 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:48:33,847 - updater - INFO - Updating chapter content with research findings
2026-01-08 09:48:34,200 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 09:48:34,200 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:48:34,201 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:48:34,229 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC71300B50>
2026-01-08 09:48:34,229 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC713760F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:48:34,293 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC71303690>
2026-01-08 09:48:34,293 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:48:34,293 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:48:34,293 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:48:34,293 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:48:34,295 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:48:41,393 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:48:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=7089'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:48:41,393 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:48:41,393 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:48:41,395 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:48:41,395 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:48:41,395 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:48:41,395 - updater - INFO - Chapter update successful
2026-01-08 09:48:41,395 - httpcore.connection - DEBUG - close.started
2026-01-08 09:48:41,395 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:48:43,397 - researcher - INFO - Researching 'This chapter details the landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art model as of early 2023. It also mentions other significant releases from major tech companies, such as Google's Bard and Meta's Llama 1. The primary focus in the LLM industry is described as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 09:48:43,745 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:48:43,747 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:48:43,777 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC71360910>
2026-01-08 09:48:43,777 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC7122CEF0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:48:43,851 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713FC790>
2026-01-08 09:48:43,851 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:48:43,851 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:48:43,851 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:48:43,851 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:48:43,851 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:49:11,880 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:49:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=27991'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:49:11,881 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 09:49:11,881 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:49:11,881 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:49:11,881 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:49:11,881 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:49:11,881 - researcher - ERROR - Web research failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 09:49:11,881 - researcher - INFO - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art model as of early 2023. It also mentions other significant releases from major tech companies, such as Google's Bard and Meta's Llama 1. The primary focus in the LLM industry is described as increasing model scale and parameter counts.
2026-01-08 09:49:11,884 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 09:49:12,716 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20details%20the%20landscape%20of%20Large%20Language%20Models%20(LLMs),%20highlighting%20GPT-4%20as%20the%20state-of-the-art%20model%20as%20of%20early%202023.%20It%20also%20mentions%20other%20significant%20releases%20from%20major%20tech%20companies,%20such%20as%20Google's%20Bard%20and%20Meta's%20Llama%201.%20The%20primary%20focus%20in%20the%20LLM%20industry%20is%20described%20as%20increasing%20model%20scale%20and%20parameter%20counts.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 09:49:13,360 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:49:13,362 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:49:13,372 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC714149D0>
2026-01-08 09:49:13,372 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC71375E20> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:49:13,436 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC71414990>
2026-01-08 09:49:13,436 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:49:13,436 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:49:13,436 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:49:13,436 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:49:13,436 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:49:16,727 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:49:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3281'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:49:16,728 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:49:16,728 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:49:16,729 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:49:16,729 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:49:16,729 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:49:16,730 - httpcore.connection - DEBUG - close.started
2026-01-08 09:49:16,731 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:49:16,731 - httpcore.connection - DEBUG - close.started
2026-01-08 09:49:16,731 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:49:18,734 - updater - INFO - Updating chapter content with research findings
2026-01-08 09:49:19,088 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 09:49:19,088 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:49:19,088 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:49:19,098 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713CE510>
2026-01-08 09:49:19,098 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC71375910> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:49:19,202 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC713CCFD0>
2026-01-08 09:49:19,202 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:49:19,202 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:49:19,203 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:49:19,203 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:49:19,203 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:49:24,947 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:49:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5716'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:49:24,947 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:49:24,947 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:49:24,947 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:49:24,947 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:49:24,948 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:49:24,948 - updater - INFO - Chapter update successful
2026-01-08 09:49:24,948 - httpcore.connection - DEBUG - close.started
2026-01-08 09:49:24,948 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:49:26,950 - researcher - INFO - Researching 'This concluding chapter emphasizes the rapid pace of development within the Artificial Intelligence field. It specifically states that 2023 signifies the commencement of the generative AI era. The chapter provides a forward-looking perspective on the ongoing evolution and future direction of AI.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 09:49:27,300 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:49:27,301 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:49:27,315 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC7143EE10>
2026-01-08 09:49:27,315 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC6D9F60F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:49:27,382 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC7143EE50>
2026-01-08 09:49:27,382 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:49:27,382 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:49:27,382 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:49:27,382 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:49:27,382 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:49:45,541 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:49:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=18148'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:49:45,541 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:49:45,541 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:49:45,543 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:49:45,543 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:49:45,543 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:49:45,544 - researcher - INFO - Searching OpenAlex for: This concluding chapter emphasizes the rapid pace of development within the Artificial Intelligence field. It specifically states that 2023 signifies the commencement of the generative AI era. The chapter provides a forward-looking perspective on the ongoing evolution and future direction of AI.
2026-01-08 09:49:45,544 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 09:49:46,677 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20concluding%20chapter%20emphasizes%20the%20rapid%20pace%20of%20development%20within%20the%20Artificial%20Intelligence%20field.%20It%20specifically%20states%20that%202023%20signifies%20the%20commencement%20of%20the%20generative%20AI%20era.%20The%20chapter%20provides%20a%20forward-looking%20perspective%20on%20the%20ongoing%20evolution%20and%20future%20direction%20of%20AI.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 09:49:46,679 - httpcore.connection - DEBUG - close.started
2026-01-08 09:49:46,680 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:49:48,683 - updater - INFO - Updating chapter content with research findings
2026-01-08 09:49:49,020 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 09:49:49,020 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:49:49,023 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:49:49,036 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC7143FB50>
2026-01-08 09:49:49,036 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AC713760F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:49:49,123 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC7143FE90>
2026-01-08 09:49:49,123 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:49:49,123 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:49:49,123 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:49:49,123 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:49:49,123 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:50:01,403 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:50:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=12272'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:50:01,407 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:50:01,407 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:50:01,407 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:50:01,407 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:50:01,407 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:50:01,409 - updater - INFO - Chapter update successful
2026-01-08 09:50:01,409 - httpcore.connection - DEBUG - close.started
2026-01-08 09:50:01,409 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:50:01,471 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:02,236 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHN-F55HggAIpkuzxo9q0yOdbAEYavKaYa_SJjvJaRwPX_LOX75XjFs42u4X5HxW_BMsudSkgql3XPRzvIHG5O85iWkU9DNWCC-IijLuxdeKPo0OaiNnXS8l6OD7-OHzzj70B4cFOjo-kucVR8=) HTTP/1.1" 404 1737
2026-01-08 09:50:02,236 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:02,891 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQG76FpUMCv8cv92HgY3JHhv7kGiGg5LuzP5Gp22-auPgEfzxfj9jRK5N39dFSSSrlOJ_Qz8135MQqafNQvr5mDnR4eRfRfdxHpD9pJerKYGbRV3oyuS8EBGxytbUclF9XApRCgP19pGvWWkcA==) HTTP/1.1" 404 1737
2026-01-08 09:50:02,895 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:03,511 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGT42Syay6Rqyq3jHnmKQdXHGdi_77kpkOPgJL9UwiKTsS-rmMc9N9NEfegpczlr16wqld5rFw_k-OdQJyM7x2dPP6ybXS6lghTgZ9rutKKqH0ZogiQ-dYipguUU2olprAroAX7rqiVOlaw5WyvlJ1gcO9rzFg-6TsPnOlskCiKgBpJ_vvzinrLfJ8=) HTTP/1.1" 404 1777
2026-01-08 09:50:03,513 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:04,124 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFbMctjPZK582kbNnFKVUy5f4gpdZxzKWhRypS_olM0WOk0aUGjBAuYES8sduMZXovtA5WKOE-Qjy1veKMwzYh2HO37QviqOd_VRgle68yrFjdLIrJ9Pw-eI8tTruIa-P6Q7AOt40BaqqxEanM8L4yZINYf-J-Z3iNyXf8=) HTTP/1.1" 404 1757
2026-01-08 09:50:04,127 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:04,778 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEda7bDaJhG8eijAG4JA17oaMUPWb-SBUZ_6l7B-J2f0BRYLY03UMBxw9anA0z0ub07SB-KBiZZcrtqIyjhUDdVIHR6s86xB9lZ7nvMncquZtUXBomudq9Q7URvoGnHiYDL353HwnxFnFCplFT_y4yWRiJqyghgnkJ7Mp_-lGCQNZEDTKobykYJAQz5UJjpXTpk4xlPqGvxU1v68NrXrg==) HTTP/1.1" 404 1805
2026-01-08 09:50:04,780 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:05,391 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQE2Adp7qgEGxZU4Lc2cCWR2CntFE9TnoViS7yiVPBqnTJdG7XcNLl603KvcNG8qPT1Qtnw-2YYJ1skf8vidtSAtGjK73dhxlG_PRBujHqHqK1EiVvqYO-ojajQBcIVp01Qt6J5680bN2bkAR3aA-vZT5JTmWdh_wjWfWHjVxR4MYF5nWNH2N9UQv6pXnJ_RUk367KdThxm4fiBgyMef-VR19TfIkg==) HTTP/1.1" 404 1813
2026-01-08 09:50:05,393 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:05,999 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHzC-uGBiunfOjd6IOtSmsTyWm-XPRykxwjy-5BjHo9XJiDm04WE37lqODxIFvoM3wI1cNtK8d7_CSNhUKKvtU28jCaQPW2iRF3v_lROF6QzaGhUIhl0CguGOaPjlevS3byvVhineeOIUCZ) HTTP/1.1" 404 1733
2026-01-08 09:50:06,002 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:06,597 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQG9VarfmYBoxKzUVA5kdCKQ2RtnTNe6hpyJjNCpVqeLU9gY6b3V1DwCvdr3qRjPd0SkZm4QvBp25k-Ot8S9enqFfAUguZYmlJvavsA_6uUKnHx-FoQeS4Z29LSkaC44Ayg6CCpxa2anwP6DhMlJPX01ZSHg9m_qVH5Gj242kPC93AaV) HTTP/1.1" 404 1765
2026-01-08 09:50:06,600 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:07,217 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEeXvTOdFiCnOIFD7cm8NiNGV-_cLzGeoIjoFu_7lWeBZ09DzBenwlqe3Wsvw-5pVkatR4OCVcxrwUCN5946umLR2zOuVioYHPqTYBhOjJE7_1lF7qBeCpCdEk_KOhsaZQMCWKb-leQMTtQJGZLzy_NQ6l-sjvoGFKge8z6URAKkAvK8HzdHkWQqO4JUFK7XrzsjZfjLvv3TiQj) HTTP/1.1" 404 1797
2026-01-08 09:50:07,220 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:07,810 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFTOjNi7thgC8EZSjL9sg15vCC56N5FTmsI4b_Wbu2n3-Vf1ZlnQteECdcNwWX2_KBwvwiINaGpvNywFs_95WETGPzy7cNrNguQ-ArVj6Vr65A_wsM7H4XDm2bjCMwwQY_4lL9yOUj7EEoCHPUHdTMm-Wr82XK8nCvYJvdORKZsQIH9P9Ssf9_C6IoL4ZkmEA5IivjthwQybSNw0Q==) HTTP/1.1" 404 1801
2026-01-08 09:50:07,812 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:08,416 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFVgq8NhHFWSI6DxXwzjZzvVCOt4wx9HUSdN245VCGFbh0XCBxpurg_7CgHH7k6U8Si_2oqaDCZkYZO7j0piQT3YVJhsWs66CZx4yjINElCFM5yfXrGriMY9aRYWdqv6T9U1raSOovaPfQ-MPys4AxSWLpGO40L9GNvG6WvNt69FiV_62sfFUBg) HTTP/1.1" 404 1773
2026-01-08 09:50:08,418 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:09,016 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGOT77xZ5i-_hCrBsvA1lcsb3XUXAVr4WWdbrvQLQroLknSs-ngtAVWm4gyP2Zjz85QGfYb4BrNyaMhNA7Fb0ZCyLP0i1l3MIxmIfU45mbrTbQyxHjDkfP-KK-HX8ITNAldvZPvzm6fT-aROVZ7TcCNICqo1JGen4I-PtuktyKxg1BQsEQ-9gW14-i7ljbTiPNoWYefER_CbNXHqip8UitxMi-3pttGifEuGvI=) HTTP/1.1" 404 1821
2026-01-08 09:50:09,018 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:09,632 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHNQNgdY61_06KQdBj4fQa7JMGMaX2K_oVH-WpR96kxWgURCAhkdlfQuxJzINIbCi2LvC8dl1wvHUpX3X5uqtSCE4PwKBaLsk9e2-y1YaVIeIauatzJLp-UGftpGsgQ44eW9lwqu6Iq2IoSTrmRWqWZJlwrMjlp9ObSPN3vPISDOFxP3YJxEV2ScwVrjWzBdYxF7NlEA-4J_w==) HTTP/1.1" 404 1797
2026-01-08 09:50:09,635 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:10,233 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHwcGaJC5j1zxKuzScNvhp3VlyMOFrHmYPKeI6EvsRfDINfaG65I4UaEpEZ7KrryX-Taga2TuozvgA3D8MwkZrnqzkC1q-1wNIA3kd-E3s275OGnFlnwZi2J3-TphBBvkrm1M3Pj8fISIxnROObrlH5MpP7axw=) HTTP/1.1" 404 1749
2026-01-08 09:50:10,235 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:10,823 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGS-UF47jgtNoubHZ-Ag3ifU7Sl2UopK2MGl0PM8Mgl3tcDZOZu51tKwLWo24BAtmbxcUcfNwhta502QdO16Gxw6NfU5VW8O6YqQsq04LYe_9Bl8OvFrtt0YDJjs3yWC-mjmODB_wv3P2LD1V8SBNYHt-JEDIhLmzoWqYTGjRg=) HTTP/1.1" 404 1761
2026-01-08 09:50:10,825 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:11,431 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQE94Ai7cWbpf5apPGtkxQezbog0QaF6Zhn4t1M8wMzn4HCDFEEKsvsZupkL6_DBlaetVcw8GAj8onq6emyyOb2nhDKrMY7S8AHadLNaiNNRnKVQq_M-6YuNb60GsgX9HhIh0h_yUHgwxL_YhrUBhTetRC2fI_ks3RMrhhIOk2FGOIQ=) HTTP/1.1" 404 1765
2026-01-08 09:50:11,434 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:12,033 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGFHWVrlPDbUjtfNLOWYn5uAM2IwUeFxSgJbUMN6QOCJ4u5qnAIsECW3W-zKS1J1be-9TBm4YOFVLJcxi_y9TldqUp95slZTWIwREllZxZuJef_f5ORTZm3_3MrYangH4oQIVv4K8J6akH2wxSjV9ScuXp8Mw==) HTTP/1.1" 404 1749
2026-01-08 09:50:12,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:12,629 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGZijlK2GA2sQeE-Erbqa_b1bV1MUW9k4udQGHfagpNsImVm6Cr5_fNkuuDmGWjELL50lCCuNnvmv0P2R6ViEDp-5IX-NHPylXVJonQlIDDRxmtWyoywQz4GekcnDSlxM2gAa9wiyxtPxcqlRVmDB5uFcdUbtwMeSvniYTQ8ScAjVF79H2cQJK-Mf6_Z8APD8I=) HTTP/1.1" 404 1785
2026-01-08 09:50:12,632 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:13,232 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEoe1yvzBFqI2EO8fQVKrovE7pWWoEKL828sKGx95EiRFIZRsmFBCUUrvTWLIY8n2j_QRfpRTnIKKMVPpLXvJUxVmGhPyy8xcmzpgdrkyF0Z-qiY3HaBQrI78kRWS34cnHzXP08eZj5z-Ymo1olbXVLeNQyQ0Nic4h2w7XUQclLxXOPz5E=) HTTP/1.1" 404 1769
2026-01-08 09:50:13,234 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:13,840 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQENpVmqvWkEUKODcSmThdsaTMrVUvIlBI9vdIgIVIjMm0Hlqcnj8J3PhnUsvZ9llyLBCotA78v-BU_4XbzTbVijQMgNPBCITCQdkeR5_Z19LDf5_bZYH9na2z4BrH97_JbBoS6orN4LK7swHtJPa8wWQKA8vpw43XiX4pVfKtIFfFBXjA==) HTTP/1.1" 404 1769
2026-01-08 09:50:13,842 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:14,439 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGYPvW1BnuiEEL19wFvWGAMsauGQlefV3cKLG5k_jh0uEJlzGyxoWPvDPt8-GFUi-H6XUx1lTI8R8k_MqFDmZU9RxrZazIPLg1q-pumXt6h5RaMkCw7lIwzPrNL1vVMIxSeN9OfDaLLfMl2Qtj5zSSprofvys04qFU=) HTTP/1.1" 404 1753
2026-01-08 09:50:14,441 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 09:50:15,046 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQF7Aj8_0AFuC9sfIY_U_RrCSkRkjIzpquPvZEWPVJFL1HKdyBW6FJsWqqXvcJInzvxb0qxs5I9gWMFdyfVayzVNemYL-1a7DG8VvoqMqE8AGonvxjY5UOceYPBEKe8gswy1VbZVK1NwCpnuaMqMoGL3kGb1HfPFbsaJskCy3A_Z-Ddu65E6Isi_XUcl8XCyCvI4kqkcIyvJeFZonpInjPZ8Jw==) HTTP/1.1" 404 1809
2026-01-08 09:57:30,559 - processor - INFO - Starting batch analysis for 12 chapters
2026-01-08 09:57:30,983 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:57:30,984 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:57:30,985 - processor - ERROR - Error in batch analysis: 'ascii' codec can't encode character '\u274c' in position 0: ordinal not in range(128)
2026-01-08 09:57:30,985 - processor - ERROR - 'ascii' codec can't encode character '\u274c' in position 0: ordinal not in range(128)
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1194, in _request_once
    response = self._httpx_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_client.py", line 812, in request
    request = self.build_request(
              ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_client.py", line 367, in build_request
    headers = self._merge_headers(headers)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_client.py", line 430, in _merge_headers
    merged_headers.update(headers)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_models.py", line 275, in update
    headers = Headers(headers)
              ^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_models.py", line 156, in __init__
    bytes_value = _normalize_header_value(v, encoding)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_models.py", line 82, in _normalize_header_value
    return value.encode(encoding or "ascii")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'ascii' codec can't encode character '\u274c' in position 0: ordinal not in range(128)
2026-01-08 09:57:31,015 - __main__ - INFO - Report structure analysis finalized
2026-01-08 09:59:25,259 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:59:25,671 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:59:25,671 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:59:25,673 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:59:25,692 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9470D5010>
2026-01-08 09:59:25,692 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9436C6060> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:59:25,755 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F945E2A190>
2026-01-08 09:59:25,757 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:59:25,757 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:59:25,757 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:59:25,757 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:59:25,757 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 09:59:35,082 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 07:59:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=9295'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 09:59:35,083 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 09:59:35,083 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 09:59:35,084 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 09:59:35,084 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 09:59:35,084 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 09:59:35,084 - processor - INFO - Batch analysis successful
2026-01-08 09:59:35,084 - httpcore.connection - DEBUG - close.started
2026-01-08 09:59:35,085 - httpcore.connection - DEBUG - close.complete
2026-01-08 09:59:35,086 - __main__ - INFO - Report structure analysis finalized
2026-01-08 09:59:55,809 - researcher - INFO - Researching 'Artificial Intelligence experienced significant growth after ChatGPT's release in late 2022, leading to a surge in popularity. This report aims to provide a comprehensive overview of the AI industry's status. It covers the current landscape and key developments. The report's scope is defined by the industry's state as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 09:59:56,173 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 09:59:56,174 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 09:59:56,181 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9470ECA90>
2026-01-08 09:59:56,181 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F943BD68D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 09:59:56,245 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9470137D0>
2026-01-08 09:59:56,245 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 09:59:56,245 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 09:59:56,245 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 09:59:56,245 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 09:59:56,246 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:00:05,090 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:00:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=8834'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:00:05,092 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:00:05,092 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:00:05,092 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:00:05,092 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:00:05,092 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:00:05,093 - researcher - ERROR - Web research failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:00:05,093 - researcher - INFO - Searching OpenAlex for: Artificial Intelligence experienced significant growth after ChatGPT's release in late 2022, leading to a surge in popularity. This report aims to provide a comprehensive overview of the AI industry's status. It covers the current landscape and key developments. The report's scope is defined by the industry's state as of mid-2023.
2026-01-08 10:00:05,094 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:00:06,339 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Artificial%20Intelligence%20experienced%20significant%20growth%20after%20ChatGPT's%20release%20in%20late%202022,%20leading%20to%20a%20surge%20in%20popularity.%20This%20report%20aims%20to%20provide%20a%20comprehensive%20overview%20of%20the%20AI%20industry's%20status.%20It%20covers%20the%20current%20landscape%20and%20key%20developments.%20The%20report's%20scope%20is%20defined%20by%20the%20industry's%20state%20as%20of%20mid-2023.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:00:06,339 - httpcore.connection - DEBUG - close.started
2026-01-08 10:00:06,339 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:00:08,343 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:00:08,691 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:00:08,691 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:00:08,693 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:00:08,703 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9470D6CD0>
2026-01-08 10:00:08,706 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F945EFEC30> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:00:08,771 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9470D4A10>
2026-01-08 10:00:08,771 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:00:08,771 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:00:08,771 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:00:08,771 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:00:08,771 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:00:09,203 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:00:10 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=415'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:00:09,203 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:00:09,203 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:00:09,203 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:00:09,203 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:00:09,203 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:00:09,203 - updater - ERROR - Failed to update chapter: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:00:09,205 - updater - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:00:11,210 - researcher - INFO - Researching 'In early 2023, GPT-4 was recognized as the leading large language model, setting the industry benchmark. Competitors such as Google introduced Bard, while Meta made Llama 1 available for research. The primary focus within the LLM domain is currently on expanding model scale. This includes increasing parameter counts to enhance performance and capabilities.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:00:11,562 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:00:11,562 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:00:11,572 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9471DA550>
2026-01-08 10:00:11,572 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F943BD68D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:00:11,636 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F9471DA590>
2026-01-08 10:00:11,636 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:00:11,636 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:00:11,636 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:00:11,636 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:00:11,636 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:00:37,608 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:00:38 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=25964'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:00:37,609 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:00:37,609 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:00:37,609 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:00:37,609 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:00:37,609 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:00:37,611 - httpcore.connection - DEBUG - close.started
2026-01-08 10:00:37,611 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:00:37,614 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQECyscwiD7EwVgNdk05xS1BSUvwS4uHJ...
2026-01-08 10:00:37,616 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:38,246 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQECyscwiD7EwVgNdk05xS1BSUvwS4uHJgz6Nhn3MF8dctdorphCaTMUIlwyHT9QP1LTpneZeR6oVok7Wb2QxFZK3_eQj2DXT1lw4C9fx6-rOUHEJxKo1ZVdOxUrsgoRB5DF_w== HTTP/1.1" 302 237
2026-01-08 10:00:38,246 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): openai.com:443
2026-01-08 10:00:38,485 - urllib3.connectionpool - DEBUG - https://openai.com:443 "GET /index/gpt-4-research/ HTTP/1.1" 403 None
2026-01-08 10:00:38,486 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): openai.com:443
2026-01-08 10:00:38,695 - urllib3.connectionpool - DEBUG - https://openai.com:443 "GET /index/gpt-4-research/ HTTP/1.1" 403 None
2026-01-08 10:00:38,695 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGX95AzmKNJT7_P88N0CN3PkiUDocQVl...
2026-01-08 10:00:38,697 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:39,253 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGX95AzmKNJT7_P88N0CN3PkiUDocQVlVO_aOxotJWmOfIDF9t-1F8a6cWSQl6h_pc5ciHZDtJp5HnCfZvL5es-RtOff3zRIkLW1QYcQ4kGYwSo1tSO32jCdxJPR5k= HTTP/1.1" 302 232
2026-01-08 10:00:39,253 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:00:39,631 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/GPT-4 HTTP/1.1" 403 2068
2026-01-08 10:00:39,635 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGfTGrZH_WswrN0z-XNFAeKpzxvM3MzB...
2026-01-08 10:00:39,636 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:40,214 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGfTGrZH_WswrN0z-XNFAeKpzxvM3MzB56yosQPqztJVWvNsjwvI-5S0a5VX1bI3mvs8ekhCORK3RxKtrGRDj1wzpERqZQE9qFlL8-oLiWoPy_gq3GhrHZB_GixsRE14NWgKaIIWvlorTMv9_8= HTTP/1.1" 302 247
2026-01-08 10:00:40,214 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): proffiz.com:443
2026-01-08 10:00:41,560 - urllib3.connectionpool - DEBUG - https://proffiz.com:443 "GET /large-language-models-in-2025/ HTTP/1.1" 200 None
2026-01-08 10:00:41,631 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHVIoHs-z6IOI3R7638wLB5j8Jcc2rC-...
2026-01-08 10:00:41,631 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:42,217 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHVIoHs-z6IOI3R7638wLB5j8Jcc2rC-jSghPXrKY_91NdEcZ0CTjJAjQnnd1prQJIdxQplejmarZ59n1WiaSzrAO2GpRIk4frbOSpjQnIaLCbZY1MDXn7Hxxjx7hgKwWFErhCdVoEgJYHSg74H2eC0PZWn37YHQTzPVGSbNgVp-sdFU6ULBJsWlchljqRzjw0= HTTP/1.1" 302 283
2026-01-08 10:00:42,218 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.techtarget.com:443
2026-01-08 10:00:42,786 - urllib3.connectionpool - DEBUG - https://www.techtarget.com:443 "GET /whatis/feature/GPT-4o-explained-Everything-you-need-to-know HTTP/1.1" 200 None
2026-01-08 10:00:42,909 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFDPNOMjfZHREHUM3GIiHWhNxHRpZR-k...
2026-01-08 10:00:42,909 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:43,527 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFDPNOMjfZHREHUM3GIiHWhNxHRpZR-kQWn4DLagEIaCvwnfBUdIJkKUT2gzRvgyWe0O1m8GZUdt1Ypg_Rm3C_M8FB8A39UaX9nMo80rsrZFaklwDrqDX-RKjQ_d7uc-Q== HTTP/1.1" 302 234
2026-01-08 10:00:43,529 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:00:43,924 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/GPT-4.1 HTTP/1.1" 403 2068
2026-01-08 10:00:43,926 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEOpcF_NdZK7LRFh-UNLn_LycADESdLF...
2026-01-08 10:00:43,927 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:44,530 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEOpcF_NdZK7LRFh-UNLn_LycADESdLFbBW7bF2jlXQchxWLZivR_4jhhPYKIXu9I5Jf2ipPc8XE-ouXhM4rJqTHBnHxVsU602KCDqJRKnvFknLtJm07NxrjZYEmdMXHW_lxfb9YA== HTTP/1.1" 302 240
2026-01-08 10:00:44,531 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:00:44,939 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/Google_Gemini HTTP/1.1" 200 109008
2026-01-08 10:00:45,137 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGSa9RpkS4uBisxabM3MShQ26Wb62GvM...
2026-01-08 10:00:45,139 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:45,725 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGSa9RpkS4uBisxabM3MShQ26Wb62GvMLMguAIIo1u-lUi8ZwaAFytbHIiBvOV_-wqMkoURI04jsSbtELhHuKEiNLWSeP8Pp919Blqtd3jKAXu_XTv8hDux14FGttWFgiadNOW3omaIsTnuh9M= HTTP/1.1" 302 247
2026-01-08 10:00:45,726 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.androidpolice.com:443
2026-01-08 10:00:46,538 - urllib3.connectionpool - DEBUG - https://www.androidpolice.com:443 "GET /google-gemini-guide/ HTTP/1.1" 200 None
2026-01-08 10:00:46,727 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFfxxyFrbtu4evjO2SErnxnywyS24-8s...
2026-01-08 10:00:46,728 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:47,318 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFfxxyFrbtu4evjO2SErnxnywyS24-8sJb0BF0DDZjgBeidf6152wh4A-XZP6RG6cqNsJge9D_HovTmQZxpErZOJRPW7qKmo4HZPOuPhTpXhWwXwGVDkIdSlAM2MX5WxLn9dZjwzB-kt2wnl6Xsocv1vFzagvfJY5IaEf8hcxJp HTTP/1.1" 302 266
2026-01-08 10:00:47,318 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.google:443
2026-01-08 10:00:47,858 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /innovation-and-ai/technology/ai/google-gemini-ai/ HTTP/1.1" 200 None
2026-01-08 10:00:47,970 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFYBP5Qm3owiHqQ2viuX2zLyU0SI78Ot...
2026-01-08 10:00:47,972 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:48,554 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFYBP5Qm3owiHqQ2viuX2zLyU0SI78OtMxFnAmvy5Kc2jWBDkrww7tDgPRlev0WStegOyK9HMRyFvTLAX0ITZZgj2i-IQI3tM1znedCwqp_oV0c2OVJEQf3tToE9s-f8sl8H3ohsEfYN7pZz10sOjpcZ6LPbXXYpA5ZoKqk4tsYxVCOfvkeXtL_ HTTP/1.1" 302 275
2026-01-08 10:00:48,555 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): 9to5google.com:443
2026-01-08 10:00:49,631 - urllib3.connectionpool - DEBUG - https://9to5google.com:443 "GET /2024/02/03/google-bard-gemini-rebrand-android-app-date/ HTTP/1.1" 200 None
2026-01-08 10:00:49,735 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGZBdmz3AlvSAZpRhl01eTmeTfZxWwe...
2026-01-08 10:00:49,736 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:50,423 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFGZBdmz3AlvSAZpRhl01eTmeTfZxWwerLFOuB9vlN_QOuQTp9YbcQWp1eVGTqj3tYqOcr6SU3QV9yrybudI_cYpRWc3L2A6kcjf3ySSi9Df6J5RnYoOnIgUr87wRT-RumKHRrCV4PSZm7ioBDnnTNYNXdV93NyY80bDDHmGDanarjQMPvvpjQl HTTP/1.1" 302 275
2026-01-08 10:00:50,424 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cmswire.com:443
2026-01-08 10:00:50,831 - urllib3.connectionpool - DEBUG - https://www.cmswire.com:443 "GET /customer-experience/why-google-renamed-bard-to-gemini/ HTTP/1.1" 200 None
2026-01-08 10:00:50,864 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHHqPT9l9PRmXmTVCCCImnPnhA2J6h9x...
2026-01-08 10:00:50,865 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:51,446 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHHqPT9l9PRmXmTVCCCImnPnhA2J6h9xVSG1mq3VYVCUi_c_eajqmlI22a75xxyhZTQ2zJe_uJWZDYNENi7M-0AOYW2UbjxxJGII2ZV4M5pSy7VRXXQIvBkFlEU3_aIwALtQMLJdUiRpLfaMFoCiGvH6qr3NZ16OA== HTTP/1.1" 302 258
2026-01-08 10:00:51,446 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.google:443
2026-01-08 10:00:51,898 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /products/gemini/bard-gemini-advanced-app/ HTTP/1.1" 301 355
2026-01-08 10:00:52,103 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /products-and-platforms/products/gemini/bard-gemini-advanced-app/ HTTP/1.1" 200 None
2026-01-08 10:00:52,218 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGTyNTc7VVW9ArvbXVhtapn5xmzbtw_O...
2026-01-08 10:00:52,220 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:52,796 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGTyNTc7VVW9ArvbXVhtapn5xmzbtw_OJuLh7hpv-KLm2VqRUviXzQCPETiBk5v51X-W4O8GlLhBlbKlLuCkL9lN9-VuAe1q97eoirccl9LGXRm8stSg0RUsMM4Vw0t5sF3FteZdTktNq7MjCA-5Tgh7ZlwfuWiH8MNGKrY-z3-cSU= HTTP/1.1" 302 268
2026-01-08 10:00:52,796 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): digitalplannet.in:443
2026-01-08 10:00:53,770 - urllib3.connectionpool - DEBUG - https://digitalplannet.in:443 "GET /google-gemini-know-googles-ai-evolution-2025/ HTTP/1.1" 200 None
2026-01-08 10:00:53,857 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEVyHJLua933TFT2SbTOOpiYFgwjYBj9...
2026-01-08 10:00:53,859 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:54,444 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEVyHJLua933TFT2SbTOOpiYFgwjYBj9j2TquMGYPePimxKLcCKtgBSLAr2z5_OBxGGY-FN-OR3JsBjuSBhpr16MAnM0ZDJJfwG9YzaeJNZ90MUZ7fIpEmF0h7kwG85i2M7p707slR7 HTTP/1.1" 302 242
2026-01-08 10:00:54,445 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): explodingtopics.com:443
2026-01-08 10:00:55,073 - urllib3.connectionpool - DEBUG - https://explodingtopics.com:443 "GET /blog/list-of-llms HTTP/1.1" 200 None
2026-01-08 10:00:55,095 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEffykEj7w0bQt-khJP01pwj59Y0WNjl...
2026-01-08 10:00:55,098 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:55,682 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEffykEj7w0bQt-khJP01pwj59Y0WNjlAD25BcyUw8EgsfLG6JyLHkzBTcmixKM2ONrd1cisyRWK4rEJ94XU7-LZxVzP_lzRJvlWdlOiMTJf6EToQN_BmFcwK8kPq2tKEz7KNHMUNKeLrlogKAeeg== HTTP/1.1" 302 249
2026-01-08 10:00:55,682 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:00:56,105 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/Llama_(language_model) HTTP/1.1" 200 58835
2026-01-08 10:00:56,262 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHMhbSbZCXyRCyOVIBy_v7CDEj7dPtEk...
2026-01-08 10:00:56,264 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:56,854 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHMhbSbZCXyRCyOVIBy_v7CDEj7dPtEkFKjdov2Gv92Auash6eIZFYruVur7oTwCuWT8EWodMcya-tIzVqV7QM8Pv39YFKc9f2PIQ5rldMOWvnr3b_HKQ== HTTP/1.1" 302 225
2026-01-08 10:00:56,854 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.namu.wiki:443
2026-01-08 10:00:57,887 - urllib3.connectionpool - DEBUG - https://en.namu.wiki:443 "GET /w/LLaMA HTTP/1.1" 200 None
2026-01-08 10:00:58,143 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.namu.wiki:443
2026-01-08 10:00:58,744 - urllib3.connectionpool - DEBUG - https://en.namu.wiki:443 "GET /w/LLaMA HTTP/1.1" 200 None
2026-01-08 10:00:58,744 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEHEFtNewhA4uhkuSAtAjff00BA5y52k...
2026-01-08 10:00:58,748 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:00:59,348 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEHEFtNewhA4uhkuSAtAjff00BA5y52kALvRLvzxU-TvHryvvZg2YOu00mFX8gfCMA2DkluBU1-GNgLRxpMeKltvkJQQaTsAu-UhNo83B9KsGtbR0d394sH4o9ylwahfSNWl_8dT1P8eHkcPh8RZnGk7UjpjjF1Tjnh3A== HTTP/1.1" 302 261
2026-01-08 10:00:59,349 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): firexcore.com:443
2026-01-08 10:01:00,077 - urllib3.connectionpool - DEBUG - https://firexcore.com:443 "GET /blog/from-llama-1-to-3-metas-ai-evolution/ HTTP/1.1" 200 34603
2026-01-08 10:01:00,171 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGtCZ4eah5pWnVFzc2TX27Tifsr9f0Xq...
2026-01-08 10:01:00,174 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:00,759 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGtCZ4eah5pWnVFzc2TX27Tifsr9f0XqSpMsRDmgaaSIypslzaGe15bBY9_HZc6szZ9Q1_Swj3BCMbR2SP7eMNyj6e9A44vJ3OWciiJ3fBKyUXOjcSZRe4UmnTjS4H2AAuxKoiBlljadMcXg6dXMhFV0u-nIr3k0MbUWMt-EoPPkCE44Y1Zh2Xw8qLGWvdJbtTZqk3BlCqM HTTP/1.1" 302 290
2026-01-08 10:01:00,760 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): towardsdatascience.com:443
2026-01-08 10:01:01,999 - urllib3.connectionpool - DEBUG - https://towardsdatascience.com:443 "GET /the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258/ HTTP/1.1" 200 None
2026-01-08 10:01:02,009 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHudF-aog5mQyrIgo4z8DbLFuw_xuXT1...
2026-01-08 10:01:02,011 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:02,622 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHudF-aog5mQyrIgo4z8DbLFuw_xuXT1mFULhvNya1sgi4WwWaR3uKKSoOv80TTimq-VLkGaZKCdmAimCLMbpaJQ1V36Cmf6YdyeQ8SPv5KwD1B8ImrfubIl2IFAw== HTTP/1.1" 302 231
2026-01-08 10:01:02,624 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): meta-quantum.today:443
2026-01-08 10:01:04,047 - urllib3.connectionpool - DEBUG - https://meta-quantum.today:443 "GET /?p=3263 HTTP/1.1" 200 25977
2026-01-08 10:01:04,272 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFjbMGJXWm4SUKOW43E49cIUpDnGlKGi...
2026-01-08 10:01:04,273 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:04,899 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFjbMGJXWm4SUKOW43E49cIUpDnGlKGi-X4tfh_UxQsP2U5miCjMHdyod-YELXIzgVVozQur_VQsyEPfNMxGVAwOm0mDDfU9_MRGqUjHroVyG5uqz4JDK1hGvKvTaVuzNqQQe2GaXh1ZKpl7_lO6a4TiErM44pP48fp51p-9jIO7VCeIL8eIokxiZtUeGNv0lqsSTGqNe12 HTTP/1.1" 302 290
2026-01-08 10:01:04,900 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:01:05,120 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /data-science/the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258 HTTP/1.1" 403 None
2026-01-08 10:01:05,126 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:01:05,347 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /data-science/the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258 HTTP/1.1" 403 None
2026-01-08 10:01:05,349 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFuwHI0eeKG74OODbmJ4_CSvHeo3O-6A...
2026-01-08 10:01:05,350 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:05,932 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFuwHI0eeKG74OODbmJ4_CSvHeo3O-6AVCHg_9yZGZhO0fbWhTJKCX9tmkSByTbTshKrnl_ZYksq3SMbHFwX3O9Vp_kQZ_ZfBw5S52HDANAIwqSdhgEHWzPwlE8NRaO2c3Iog== HTTP/1.1" 302 237
2026-01-08 10:01:05,934 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.byteplus.com:443
2026-01-08 10:01:06,632 - urllib3.connectionpool - DEBUG - https://www.byteplus.com:443 "GET /en/topic/431106 HTTP/1.1" 200 None
2026-01-08 10:01:06,646 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFQbaB-LmG4WQK58bOpXvC6wxYA0vgOO...
2026-01-08 10:01:06,646 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:07,239 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFQbaB-LmG4WQK58bOpXvC6wxYA0vgOOnqXqubzWEnfwsfuOIMjLBQVxB67Wu9NCkQPs0EMg7AKCJa-WLhE1shVCrGPdpEvgAFqGr4oPMXiDgXeCVhEIE5ry3JlpzPZTQ== HTTP/1.1" 302 234
2026-01-08 10:01:07,240 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:01:07,634 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/Meta_AI HTTP/1.1" 200 41939
2026-01-08 10:01:07,737 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHu_tVv95ICGmMpW6sEoGTi5P50ownFm...
2026-01-08 10:01:07,738 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:08,330 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHu_tVv95ICGmMpW6sEoGTi5P50ownFmh2Idd_bs4K2Sa89YWrf40MGU7SanqVXa5Mj4Z59JWKnzbB6UTkLLDSTXruSkS7pevS0VwE= HTTP/1.1" 302 214
2026-01-08 10:01:08,331 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): epoch.ai:443
2026-01-08 10:01:08,833 - urllib3.connectionpool - DEBUG - https://epoch.ai:443 "GET / HTTP/1.1" 200 82242
2026-01-08 10:01:08,968 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): epoch.ai:443
2026-01-08 10:01:09,336 - urllib3.connectionpool - DEBUG - https://epoch.ai:443 "GET / HTTP/1.1" 200 82242
2026-01-08 10:01:09,464 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFftrPhWLtocn6Cf0zwa7ecgV5rqmJ1X...
2026-01-08 10:01:09,465 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:10,050 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFftrPhWLtocn6Cf0zwa7ecgV5rqmJ1XdRtTjQSc95HYTYBryxehQFV5WdiXKVNmbY7KIPYHksDWLtAW1JmIGBSXzDH4IWJlZLvY-S9KFVcjPTQ9nhch3gLzJgrNThcDBUKp0i5gEdTIC04xcyRwaGX5flge3bvPlh6vWv6 HTTP/1.1" 302 263
2026-01-08 10:01:10,051 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): straitsresearch.com:443
2026-01-08 10:01:10,715 - urllib3.connectionpool - DEBUG - https://straitsresearch.com:443 "GET /report/large-language-model-llm-market HTTP/1.1" 200 19896
2026-01-08 10:01:10,864 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx591YvHkgXLwlM0MkbWrc3596cHVvq...
2026-01-08 10:01:10,865 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:01:11,432 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGx591YvHkgXLwlM0MkbWrc3596cHVvqAE09FaUqvSxdD2PN63sIVpX7Zx2iOV5xyk4TtT7Ej327yASP0DtLFCwJwd6S-i3OCmiBFm5Zjf5vxB77DMDyVt4L7w9sKDtXJBH2AsELptN34k= HTTP/1.1" 302 244
2026-01-08 10:01:11,434 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): powerdrill.ai:443
2026-01-08 10:01:12,060 - urllib3.connectionpool - DEBUG - https://powerdrill.ai:443 "GET /blog/llm-market-landscape HTTP/1.1" 200 83729
2026-01-08 10:01:12,115 - researcher - INFO - Searching OpenAlex for: In early 2023, GPT-4 was recognized as the leading large language model, setting the industry benchmark. Competitors such as Google introduced Bard, while Meta made Llama 1 available for research. The primary focus within the LLM domain is currently on expanding model scale. This includes increasing parameter counts to enhance performance and capabilities.
2026-01-08 10:01:12,117 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:01:13,567 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=In%20early%202023,%20GPT-4%20was%20recognized%20as%20the%20leading%20large%20language%20model,%20setting%20the%20industry%20benchmark.%20Competitors%20such%20as%20Google%20introduced%20Bard,%20while%20Meta%20made%20Llama%201%20available%20for%20research.%20The%20primary%20focus%20within%20the%20LLM%20domain%20is%20currently%20on%20expanding%20model%20scale.%20This%20includes%20increasing%20parameter%20counts%20to%20enhance%20performance%20and%20capabilities.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:01:13,568 - httpcore.connection - DEBUG - close.started
2026-01-08 10:01:13,568 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:01:15,571 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:01:15,918 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:01:15,918 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:01:15,920 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:01:15,942 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F947010350>
2026-01-08 10:01:15,942 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F94701DBE0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:01:16,005 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F947012CD0>
2026-01-08 10:01:16,005 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:01:16,005 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:01:16,005 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:01:16,006 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:01:16,006 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:01:18,906 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:01:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2889'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:01:18,906 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:01:18,906 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:01:18,907 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:01:18,907 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:01:18,907 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:01:18,907 - updater - ERROR - Failed to update chapter: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:01:18,907 - updater - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:01:18,951 - httpcore.connection - DEBUG - close.started
2026-01-08 10:01:18,952 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:01:18,966 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.androidpolice.com:443
2026-01-08 10:01:19,648 - urllib3.connectionpool - DEBUG - https://www.androidpolice.com:443 "GET /google-gemini-guide/) HTTP/1.1" 301 None
2026-01-08 10:01:19,900 - urllib3.connectionpool - DEBUG - https://www.androidpolice.com:443 "GET /google-gemini-guide/)/ HTTP/1.1" 404 None
2026-01-08 10:01:19,902 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.google:443
2026-01-08 10:01:20,407 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /innovation-and-ai/technology/ai/google-gemini-ai/) HTTP/1.1" 308 329
2026-01-08 10:01:20,812 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /innovation-and-ai/technology/ai/google-gemini-ai/)/ HTTP/1.1" 404 None
2026-01-08 10:01:20,815 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:01:21,207 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/Meta_AI) HTTP/1.1" 403 2068
2026-01-08 10:01:21,209 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): powerdrill.ai:443
2026-01-08 10:01:21,523 - urllib3.connectionpool - DEBUG - https://powerdrill.ai:443 "GET /blog/llm-market-landscape) HTTP/1.1" 404 None
2026-01-08 10:01:21,525 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): openai.com:443
2026-01-08 10:01:21,800 - urllib3.connectionpool - DEBUG - https://openai.com:443 "GET /index/gpt-4-research/) HTTP/1.1" 403 None
2026-01-08 10:01:21,803 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): explodingtopics.com:443
2026-01-08 10:01:22,377 - urllib3.connectionpool - DEBUG - https://explodingtopics.com:443 "GET /blog/list-of-llms) HTTP/1.1" 404 None
2026-01-08 10:01:22,379 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:01:22,766 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/GPT-4.1) HTTP/1.1" 403 2068
2026-01-08 10:01:22,768 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:01:22,992 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /data-science/the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258) HTTP/1.1" 403 None
2026-01-08 10:01:22,993 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): straitsresearch.com:443
2026-01-08 10:01:23,600 - urllib3.connectionpool - DEBUG - https://straitsresearch.com:443 "GET /report/large-language-model-llm-market) HTTP/1.1" 400 None
2026-01-08 10:01:23,602 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): firexcore.com:443
2026-01-08 10:01:25,096 - urllib3.connectionpool - DEBUG - https://firexcore.com:443 "GET /blog/from-llama-1-to-3-metas-ai-evolution/) HTTP/1.1" 301 0
2026-01-08 10:01:25,210 - urllib3.connectionpool - DEBUG - https://firexcore.com:443 "GET /blog/from-llama-1-to-3-metas-ai-evolution/ HTTP/1.1" 200 34603
2026-01-08 10:01:25,212 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.google:443
2026-01-08 10:01:25,661 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /products-and-platforms/products/gemini/bard-gemini-advanced-app/) HTTP/1.1" 308 359
2026-01-08 10:01:26,161 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /products-and-platforms/products/gemini/bard-gemini-advanced-app/)/ HTTP/1.1" 404 None
2026-01-08 10:01:26,163 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): proffiz.com:443
2026-01-08 10:01:27,186 - urllib3.connectionpool - DEBUG - https://proffiz.com:443 "GET /large-language-models-in-2025/) HTTP/1.1" 404 None
2026-01-08 10:01:27,188 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:01:27,581 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/Google_Gemini) HTTP/1.1" 403 2068
2026-01-08 10:01:27,583 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cmswire.com:443
2026-01-08 10:01:27,954 - urllib3.connectionpool - DEBUG - https://www.cmswire.com:443 "GET /customer-experience/why-google-renamed-bard-to-gemini/) HTTP/1.1" 308 None
2026-01-08 10:01:28,255 - urllib3.connectionpool - DEBUG - https://www.cmswire.com:443 "GET /customer-experience/why-google-renamed-bard-to-gemini/)/ HTTP/1.1" 404 None
2026-01-08 10:01:28,258 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.namu.wiki:443
2026-01-08 10:01:28,787 - urllib3.connectionpool - DEBUG - https://en.namu.wiki:443 "GET /w/LLaMA) HTTP/1.1" 404 None
2026-01-08 10:01:28,790 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): towardsdatascience.com:443
2026-01-08 10:01:29,252 - urllib3.connectionpool - DEBUG - https://towardsdatascience.com:443 "GET /the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258/) HTTP/1.1" 301 None
2026-01-08 10:01:29,509 - urllib3.connectionpool - DEBUG - https://towardsdatascience.com:443 "GET /the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258 HTTP/1.1" 301 None
2026-01-08 10:01:29,703 - urllib3.connectionpool - DEBUG - https://towardsdatascience.com:443 "GET /the-evolution-of-llama-from-llama-1-to-llama-3-1-13c4ebe96258/ HTTP/1.1" 200 None
2026-01-08 10:01:29,707 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:01:30,148 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/Llama_(language_model)) HTTP/1.1" 403 2068
2026-01-08 10:01:30,149 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): meta-quantum.today:443
2026-01-08 10:01:31,311 - urllib3.connectionpool - DEBUG - https://meta-quantum.today:443 "GET /?p=3263) HTTP/1.1" 301 1
2026-01-08 10:01:31,742 - urllib3.connectionpool - DEBUG - https://meta-quantum.today:443 "GET /?p=3263 HTTP/1.1" 200 25976
2026-01-08 10:01:31,744 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.byteplus.com:443
2026-01-08 10:01:33,210 - urllib3.connectionpool - DEBUG - https://www.byteplus.com:443 "GET /en/topic/431106) HTTP/1.1" 200 None
2026-01-08 10:01:33,213 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): 9to5google.com:443
2026-01-08 10:01:33,883 - urllib3.connectionpool - DEBUG - https://9to5google.com:443 "GET /2024/02/03/google-bard-gemini-rebrand-android-app-date/) HTTP/1.1" 301 None
2026-01-08 10:01:34,562 - urllib3.connectionpool - DEBUG - https://9to5google.com:443 "GET /2024/02/03/google-bard-gemini-rebrand-android-app-date/ HTTP/1.1" 200 None
2026-01-08 10:01:34,564 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): digitalplannet.in:443
2026-01-08 10:01:35,474 - urllib3.connectionpool - DEBUG - https://digitalplannet.in:443 "GET /google-gemini-know-googles-ai-evolution-2025/) HTTP/1.1" 301 0
2026-01-08 10:01:36,066 - urllib3.connectionpool - DEBUG - https://digitalplannet.in:443 "GET /google-gemini-know-googles-ai-evolution-2025/ HTTP/1.1" 200 None
2026-01-08 10:01:36,069 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): en.wikipedia.org:443
2026-01-08 10:01:36,460 - urllib3.connectionpool - DEBUG - https://en.wikipedia.org:443 "GET /wiki/GPT-4) HTTP/1.1" 403 2068
2026-01-08 10:01:36,462 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): epoch.ai:443
2026-01-08 10:01:36,884 - urllib3.connectionpool - DEBUG - https://epoch.ai:443 "GET /) HTTP/1.1" 404 17286
2026-01-08 10:01:36,887 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.techtarget.com:443
2026-01-08 10:01:37,509 - urllib3.connectionpool - DEBUG - https://www.techtarget.com:443 "GET /whatis/feature/GPT-4o-explained-Everything-you-need-to-know) HTTP/1.1" 404 None
2026-01-08 10:18:58,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:18:58,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:18:58,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:18:58,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:18:58,162 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:18:58,162 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:18:58,162 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:18:58,162 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:08,301 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:08,301 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:08,301 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:08,302 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:08,303 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:08,303 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:08,303 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:08,303 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:37,129 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:37,129 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:37,129 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:37,129 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:37,131 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:37,131 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:37,131 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:37,131 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:38,857 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:38,858 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:38,858 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:38,858 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:38,859 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:38,859 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:38,859 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:38,859 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:38,914 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 10:19:39,298 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 10:19:39,298 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:19:39,300 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:19:39,320 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D084D71550>
2026-01-08 10:19:39,320 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0833C5520> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:19:39,381 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C0FD150>
2026-01-08 10:19:39,381 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:19:39,381 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:19:39,383 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:19:39,383 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:19:39,383 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:19:43,772 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:19:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4382'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:19:43,773 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:19:43,773 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:19:43,773 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:19:43,774 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:19:43,774 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:19:43,774 - processor - INFO - Batch analysis successful
2026-01-08 10:19:43,775 - httpcore.connection - DEBUG - close.started
2026-01-08 10:19:43,775 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:19:43,776 - __main__ - INFO - Report structure analysis finalized
2026-01-08 10:19:43,831 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:43,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:43,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:43,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:43,834 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:43,834 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:19:43,834 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:19:43,834 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,284 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,285 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,285 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,285 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,286 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,286 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,286 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,287 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,346 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,346 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,346 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,346 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,348 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,348 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,348 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:20:56,348 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:20:56,352 - researcher - INFO - Researching 'This chapter introduces the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the current state of the AI industry. The scope of the report is set to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:20:56,729 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:20:56,730 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:20:56,740 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D084E54250>
2026-01-08 10:20:56,740 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0833C5910> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:20:56,803 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D084E44290>
2026-01-08 10:20:56,805 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:20:56,805 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:20:56,805 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:20:56,805 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:20:56,805 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:21:17,520 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:21:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=20693'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:21:17,520 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:21:17,520 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:21:17,521 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:21:17,522 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:21:17,522 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:21:17,524 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEmcsGi_yH2d3gc6gk5BlmkiqFkXOmbC...
2026-01-08 10:21:17,525 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:18,264 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEmcsGi_yH2d3gc6gk5BlmkiqFkXOmbCjetR53F4CyXW0usdYvqgHEdVaqzZjzBkh6bgPW1qQVvXqC601drADfA8ucAgx8OvYCOD9nc-GAwSbBkWBlSb0a-jd4AecvbnnsROwecx5lSfvTjruw55licyZ-W HTTP/1.1" 302 253
2026-01-08 10:21:18,265 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): time.com:443
2026-01-08 10:21:18,815 - urllib3.connectionpool - DEBUG - https://time.com:443 "GET /6547982/3-big-ai-innovations-from-2023/ HTTP/1.1" 406 None
2026-01-08 10:21:18,818 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): time.com:443
2026-01-08 10:21:19,311 - urllib3.connectionpool - DEBUG - https://time.com:443 "GET /6547982/3-big-ai-innovations-from-2023/ HTTP/1.1" 406 None
2026-01-08 10:21:19,313 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG9CUEJkvny3Ua4eqealR0HvvvxHNal7...
2026-01-08 10:21:19,314 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:19,930 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQG9CUEJkvny3Ua4eqealR0HvvvxHNal7hBPLznlu-nm_r4lhXq3ODYr3oldBNa67kOyic0FHyo4wfU8EaaoElb9kL9fBXoBZEXd8AaQsimWKwKoW_ll9tvtFtdHcVvImMCMW1RNITKfYjYRqIEtblWaUGo= HTTP/1.1" 302 252
2026-01-08 10:21:19,932 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): aimagazine.com:443
2026-01-08 10:21:20,177 - urllib3.connectionpool - DEBUG - https://aimagazine.com:443 "GET /top10/top-10-innovations-of-2023 HTTP/1.1" 403 None
2026-01-08 10:21:20,180 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGfyByM2Ba4Thw1bwG5sRtkMc-fmU9MB...
2026-01-08 10:21:20,181 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:20,750 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGfyByM2Ba4Thw1bwG5sRtkMc-fmU9MB1PDBOCxZHLANasBvLWfRb-KcGpPXA33G2wrIMIOqrVL4DXscX6b7oAdkxOCLpPHDTnqB5lLl72pJxqxtM81XwtKESdexMkrngFhBwoAf8XZlZiBPXI6QQcAtAXyO6PsXPPHzMqy_y8g89doUfZzxgs1Q1vXOlPydmnd HTTP/1.1" 302 283
2026-01-08 10:21:20,752 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:21:20,994 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /@aarondiblasi/the-10-most-important-ai-moments-of-2023-03269894e1b6 HTTP/1.1" 403 None
2026-01-08 10:21:20,997 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:21:21,235 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /@aarondiblasi/the-10-most-important-ai-moments-of-2023-03269894e1b6 HTTP/1.1" 403 None
2026-01-08 10:21:21,236 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHILcNX-DgjGCoKZialyVhJ5nlTdBr6z...
2026-01-08 10:21:21,237 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:21,825 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHILcNX-DgjGCoKZialyVhJ5nlTdBr6zVEokfjmK103X9q-Z9oTnWipCJe1dyVlgHwOJw9_iPTj5HJkDAHteHBEJMqByj_UBol05cQlTtwYIQja9W8PnLXGqPzUgCuooIlzcmmyD6qc90x44HMTzVnoD98FgHIpccJes2vQr4PfEXAPwIFfaReV9RwXu5Xqr7whJULKJchjdtA29tTqFuNda3cQtV6QsE81Pw== HTTP/1.1" 302 308
2026-01-08 10:21:21,825 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:21:22,055 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /@jyotishmandas85p/the-latest-generative-ai-models-in-2025-a-comprehensive-guide-58f7dcb9f8f3 HTTP/1.1" 403 None
2026-01-08 10:21:22,059 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:21:22,284 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /@jyotishmandas85p/the-latest-generative-ai-models-in-2025-a-comprehensive-guide-58f7dcb9f8f3 HTTP/1.1" 403 None
2026-01-08 10:21:22,286 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE_BzNpSIRrYIxhFiJj9BAi0ZkeIEA-y...
2026-01-08 10:21:22,287 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:22,882 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQE_BzNpSIRrYIxhFiJj9BAi0ZkeIEA-yOyh6gw9iwOMTsoLWFUzqQY9IlT-pYrOMsHXUYmXlczoblLbtPDmaZER95py-nnxsLBht3jx1GqJCPQmzwIomWkRikEtAg5VKA5Q7dzvvEm-z11oCJmZ_yyAZ0mMt9-fBZ4uYAc8wq3LvYNJ6TT3dReNkz-ECA== HTTP/1.1" 302 278
2026-01-08 10:21:22,884 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.timesofai.com:443
2026-01-08 10:21:23,487 - urllib3.connectionpool - DEBUG - https://www.timesofai.com:443 "GET /industry-insights/roundup-of-ai-model-releases-in-2025/ HTTP/1.1" 200 None
2026-01-08 10:21:23,629 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF3WiP0ty5erpWaqCdzT6NpTuZwTaQwR...
2026-01-08 10:21:23,629 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:24,253 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQF3WiP0ty5erpWaqCdzT6NpTuZwTaQwRxFGGK-lmplHk5oCuvyZGS2XL8rjuME1v3IC62Kl42f2zCBT7ohNO-KY3UOy4K0InbD0IzzqpOpOGlcuU5vG_YDZy7xev0ekHqWJc5EI7jchrwhC0Me9ozldeVs_LgoCeHPPoZdnpeAuer9zaw== HTTP/1.1" 302 269
2026-01-08 10:21:24,255 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertu.com:443
2026-01-08 10:21:25,722 - urllib3.connectionpool - DEBUG - https://vertu.com:443 "GET /lifestyle/the-ai-model-race-reaches-singularity-speed/ HTTP/1.1" 200 None
2026-01-08 10:21:26,637 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertu.com:443
2026-01-08 10:21:27,038 - urllib3.connectionpool - DEBUG - https://vertu.com:443 "GET /lifestyle/the-ai-model-race-reaches-singularity-speed/ HTTP/1.1" 200 None
2026-01-08 10:21:27,122 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH7D0asdsU72m6eS45TZl2wdd1QNiubJ...
2026-01-08 10:21:27,124 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:27,706 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQH7D0asdsU72m6eS45TZl2wdd1QNiubJ3OK9JBWAFNFGEEkhZRtkWskBeyIvK2MJCLIAs2bB4FPtH_ysZSxm2ONlIayIxgelnzGNzRjNZpxd0xeVz5qAbZ92El2Httjfp-us-hxVqlvajUXrVPFUQ9qqLAkLsmR44fU0N-OyZm7gjoZw0FLvqD4j588Jm8F2S1J6bnf HTTP/1.1" 302 286
2026-01-08 10:21:27,707 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): autogpt.net:443
2026-01-08 10:21:28,243 - urllib3.connectionpool - DEBUG - https://autogpt.net:443 "GET /ai-in-2023-review-a-timeline-of-artificial-intelligence-advancements/ HTTP/1.1" 200 None
2026-01-08 10:21:28,757 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGn6NmUwi_rhEGHy8pbEn0CbTNid_kKV...
2026-01-08 10:21:28,757 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:29,399 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGn6NmUwi_rhEGHy8pbEn0CbTNid_kKV4d3g6D8eX6Eo6wqeViVFe2ikL36cgQj-Qu0UpJ-v64DbHDE7RS2kkyc7AvNi_8KopkUBPAQSidrrUsCBVbOIqZIbq1h662v_jdQ7PqI8Fg= HTTP/1.1" 302 240
2026-01-08 10:21:29,400 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.youtube.com:443
2026-01-08 10:21:29,769 - urllib3.connectionpool - DEBUG - https://www.youtube.com:443 "GET /watch?v=1KUKh7TofLg HTTP/1.1" 200 None
2026-01-08 10:21:30,257 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG81vhrK14PP4IjcmBnNgIjQY8J6ThCG...
2026-01-08 10:21:30,257 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:30,849 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQG81vhrK14PP4IjcmBnNgIjQY8J6ThCGxjhpKze6zCFQ7LgEGBqtOO-2W82IFFVlm8V-QY_NXM1VibOKqeuYvddvmMFOJWf86wZjr7Uu2NDpwINpWmQ8N0jlZd3n_x3jGc-vdvhZ1eCDmAKZHHnGMSGGcpiCoXbBjrVHITPZg== HTTP/1.1" 302 263
2026-01-08 10:21:30,850 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.kdnuggets.com:443
2026-01-08 10:21:31,255 - urllib3.connectionpool - DEBUG - https://www.kdnuggets.com:443 "GET /the-10-ai-developments-that-defined-2025 HTTP/1.1" 200 None
2026-01-08 10:21:31,414 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHBQPXlCwy9sUxaaRtGd3DojyhwYxF4r...
2026-01-08 10:21:31,416 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:31,999 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHBQPXlCwy9sUxaaRtGd3DojyhwYxF4rblximj91lgWUpayrqWyoS3fMKw9ZPYAkr2FbLCW6y3MmowfO4dM4ckhRBq3eccjYvdZ81qo84OHTGsTF1nofiBWFSeSjxBw2pzurFz2nVta3VDpbYrhviqTst8leiAmS4Nx34WFiuZyFeCxp6A97v6MQ1T_7p_VC4dc5CTp8_jd-GdB4CwtDO0b_DQLF5--NRRgpxk1ppWI HTTP/1.1" 302 313
2026-01-08 10:21:32,000 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): decimalpointanalytics.com:443
2026-01-08 10:21:33,647 - urllib3.connectionpool - DEBUG - https://decimalpointanalytics.com:443 "GET /who-we-are/newsroom/navigating-the-ai-landscape-key-trends-shaping-2025-and-beyond HTTP/1.1" 200 None
2026-01-08 10:21:34,427 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHnoL6CnhIO--jO0e83Y2avjrgOOANV6...
2026-01-08 10:21:34,428 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:35,027 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHnoL6CnhIO--jO0e83Y2avjrgOOANV6Q5YE8wUrPp36w6WN3iSfSTjqpdBZ7Lll6BbkPvBxbX3Kls7BD2J376RUkP61nlVqHmSssu5y_PlxG_02_-IhOvKm5MUf6w-kZ3_pYwPeAZCwyAdWVf4IwhiMYUrgkWfcn-kfTRlxXeB4nGpFpvoG_ibhcQgaflFbgb1VSQT4rw0x99FipZUHbMtBw== HTTP/1.1" 302 299
2026-01-08 10:21:35,028 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): unctad.org:443
2026-01-08 10:21:36,530 - urllib3.connectionpool - DEBUG - https://unctad.org:443 "GET /news/ai-market-projected-hit-48-trillion-2033-emerging-dominant-frontier-technology HTTP/1.1" 200 None
2026-01-08 10:21:36,534 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): unctad.org:443
2026-01-08 10:21:37,846 - urllib3.connectionpool - DEBUG - https://unctad.org:443 "GET /news/ai-market-projected-hit-48-trillion-2033-emerging-dominant-frontier-technology HTTP/1.1" 200 None
2026-01-08 10:21:37,850 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFynft2twncswgKbBnNZsHs8Wyp_vTDP...
2026-01-08 10:21:37,850 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:38,445 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFynft2twncswgKbBnNZsHs8Wyp_vTDPEig77qhjfxeBONBHMZ-euqliOYR1-lzFbgR7QAESDaYcde_nxPtIsVy8R4khA13HYGLdXdFzpljEE9J8lx70uO91RDURqC_rXK5ISCE2gduuKvfGxE= HTTP/1.1" 302 246
2026-01-08 10:21:38,447 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ff.co:443
2026-01-08 10:21:39,026 - urllib3.connectionpool - DEBUG - https://ff.co:443 "GET /ai-statistics-trends-global-market/ HTTP/1.1" 200 None
2026-01-08 10:21:39,031 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ff.co:443
2026-01-08 10:21:39,373 - urllib3.connectionpool - DEBUG - https://ff.co:443 "GET /ai-statistics-trends-global-market/ HTTP/1.1" 200 None
2026-01-08 10:21:39,377 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFwTJlwIhGwWY6ugY4ISMlNiIHnA-Qpq...
2026-01-08 10:21:39,378 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:39,957 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFwTJlwIhGwWY6ugY4ISMlNiIHnA-Qpqs8e8jdAVWI6C-1BzAvgtcqxrR-o-Z5JLxa4n635Ogew0aNMsiXu-ympK5UiHK-l_EaW7Zb65GcVAZLCS2-WnZm3BLKg2l5QUhiBzc1w3wuO3k46rsfuvjrs4XvzrlGwG2sQItEl HTTP/1.1" 302 262
2026-01-08 10:21:39,958 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.precedenceresearch.com:443
2026-01-08 10:21:40,979 - urllib3.connectionpool - DEBUG - https://www.precedenceresearch.com:443 "GET /artificial-intelligence-market HTTP/1.1" 200 None
2026-01-08 10:21:41,203 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGS1LqwK2c_3D4I3eaynjryGw5uGqjz8...
2026-01-08 10:21:41,205 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:41,796 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGS1LqwK2c_3D4I3eaynjryGw5uGqjz8B-ZXxZ2wckbqwMpCns5Z_T5OXvO3u3SqVf28lM8BkDu7gzeKRHnWBoQ9YGHlSDbwZqlapFuaIoMq5N584uhaqtTjjSpipXxqxmB3SVQyRsflT16D-xGUTRxD5PFTeDJUJlhTMLSXWGJYelsUa-5wQ2ql72ZAYJO83d1AuoMLnWsjHNhrix9ub0dsZH1kw== HTTP/1.1" 302 302
2026-01-08 10:21:41,797 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): emmo.net.co:443
2026-01-08 10:21:47,093 - researcher - WARNING - Failed to resolve redirect https://vertexaisearch.cloud.google.com/grounding-: HTTPSConnectionPool(host='emmo.net.co', port=443): Read timed out. (read timeout=5)
2026-01-08 10:21:47,093 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFaKy1vNZ31VevrEVE2CJR0GmFfcZayj...
2026-01-08 10:21:47,094 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:47,704 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFaKy1vNZ31VevrEVE2CJR0GmFfcZayjDWjJZquHftYrKdSH4E30l_L1na-eMqxIl0m9wQHgOFUX4aEu99Rk3TWfRfIsn0UvyZxMslPsliHdZIrfX4GRI12Xuflb5Rr6cbR30JWyKp88LkXSTNcXpv0txLMo_SFkS2Eb2pVf2C_5GdrVbvaWrMDnmyvDrAaK83_W-s4IhQ92JUll6qL_KePvYEUWM3Rrmlz4M2JI_wG_g_X0xTh0TO1R9OSNUoOjPc= HTTP/1.1" 302 329
2026-01-08 10:21:47,706 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bestbrokers.com:443
2026-01-08 10:21:48,577 - urllib3.connectionpool - DEBUG - https://www.bestbrokers.com:443 "GET /forex-brokers/the-state-of-ai-venture-capital-in-2025-ai-boom-slows-with-fewer-startups-but-bigger-bets/ HTTP/1.1" 200 None
2026-01-08 10:21:48,657 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG6tRv1KRTIQfKjNvpD2gfon5Bj6zcms...
2026-01-08 10:21:48,659 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:49,257 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQG6tRv1KRTIQfKjNvpD2gfon5Bj6zcmsWBoA4V1VzhiGmzQzM1A4OQmAS2PRQvZW6jH3n6iZv8krnFqq4Sv_-H1bRGbqtiCeZw-EMwgNGSM9tgcU2QRdLSsZ1MwGJIuqcyMf2Wp6cXSxPQGNaubNSpvDDIGU2OFl8HF_ai0zEOSc8EOI3OdJ73hXoMMBJYP HTTP/1.1" 302 280
2026-01-08 10:21:49,259 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.crunchbase.com:443
2026-01-08 10:21:50,122 - urllib3.connectionpool - DEBUG - https://news.crunchbase.com:443 "GET /venture/state-of-startups-q2-h1-2025-ai-ma-charts-data/ HTTP/1.1" 200 None
2026-01-08 10:21:50,129 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEXeFydllQ2yfZbE21wIQphBcswpbYBQ...
2026-01-08 10:21:50,129 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:50,704 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEXeFydllQ2yfZbE21wIQphBcswpbYBQUJ2YtCE45XQCK3lt8uswLv8o4xRBq02OQv-5V22Hp2vVCZ7I9xxvOi89d9_lXKSRG9SHVzMJaqFMwzCfFythwBsxzGtFBVDy64MQW7mqgbHA7-M2nTj36rimpBS1UuncQ== HTTP/1.1" 302 257
2026-01-08 10:21:50,706 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): aloa.co:443
2026-01-08 10:21:52,055 - urllib3.connectionpool - DEBUG - https://aloa.co:443 "GET /ai/resources/industry-insights/top-ai-trends HTTP/1.1" 200 None
2026-01-08 10:21:52,070 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): aloa.co:443
2026-01-08 10:21:53,060 - urllib3.connectionpool - DEBUG - https://aloa.co:443 "GET /ai/resources/industry-insights/top-ai-trends HTTP/1.1" 200 None
2026-01-08 10:21:53,068 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpQp0P3EN2-1EkM_9IPnljOtyYYHONh...
2026-01-08 10:21:53,070 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:53,395 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHpQp0P3EN2-1EkM_9IPnljOtyYYHONhpTWTVH2QtAf0aOy4ujZ0QsVHR-7RJK2JHmi2XhH8PUs-T52z_PMthNzxzrqIs5L0NffEziFd5REVvOwIANMLS2nOUmazPLVXrODPTpUb2y-ySYHUfoIHhIlFoPbC7TYn6JoW7kpIAovwIm5 HTTP/1.1" 302 268
2026-01-08 10:21:53,396 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.index.dev:443
2026-01-08 10:21:54,352 - urllib3.connectionpool - DEBUG - https://www.index.dev:443 "GET /blog/ai-regulations-and-policy-updates-us-eu-asia HTTP/1.1" 200 None
2026-01-08 10:21:54,506 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.index.dev:443
2026-01-08 10:21:54,967 - urllib3.connectionpool - DEBUG - https://www.index.dev:443 "GET /blog/ai-regulations-and-policy-updates-us-eu-asia HTTP/1.1" 200 None
2026-01-08 10:21:55,124 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGoRRHrc90F4JeDqOULSyzuxjCOviKhJ...
2026-01-08 10:21:55,125 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:55,709 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGoRRHrc90F4JeDqOULSyzuxjCOviKhJ-NJu6ytJF1VDShCObiXlKRDkUXkzkhw91oA9et-o2hqXFCb59s3xEkQtohIJiHHDiIAueQcS7lPqsVY0DhcLkv9moWh0mn_3hZl8wtFenx6dA== HTTP/1.1" 302 242
2026-01-08 10:21:55,710 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.thoropass.com:443
2026-01-08 10:21:56,161 - urllib3.connectionpool - DEBUG - https://www.thoropass.com:443 "GET /blog/ai-regulations HTTP/1.1" 200 None
2026-01-08 10:21:56,163 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHttnmvXmZsvbU9pUdaCG-vTlcxCQbMY...
2026-01-08 10:21:56,164 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:56,746 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHttnmvXmZsvbU9pUdaCG-vTlcxCQbMYt7jolQkZDHCttHcWfbx16RnFCR2hDN3zqsmDOzxUEiqYdcD7NV1t6zVHZ6S7AdLQFm5QFzDoGRNbvCFKBV_APvstWPinIJGrk7JBxorkrsOA2miBSWHHmJr0XCMzz6JYSfHktTODqo7lTJagIZDPwF-Rz-T HTTP/1.1" 302 277
2026-01-08 10:21:56,747 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cimplifi.com:443
2026-01-08 10:21:57,761 - urllib3.connectionpool - DEBUG - https://www.cimplifi.com:443 "GET /resources/the-updated-state-of-ai-regulations-for-2025/ HTTP/1.1" 200 None
2026-01-08 10:21:57,767 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGkpVwmFrBasKzIKnrhNEsjN4QfV3Z3Z...
2026-01-08 10:21:57,768 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:21:58,371 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGkpVwmFrBasKzIKnrhNEsjN4QfV3Z3ZquwRgjsvEfzJQ3Kdghvd5f2qIAXqu4z3eG2hg5BrncMqkpUsnxwAbpHTA_p2mR8K3qKfGusYhTAMs7PRCX4ZCWizG0F1lW1LcQ= HTTP/1.1" 302 234
2026-01-08 10:21:58,372 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): artificialintelligenceact.eu:443
2026-01-08 10:21:59,282 - urllib3.connectionpool - DEBUG - https://artificialintelligenceact.eu:443 "GET / HTTP/1.1" 200 None
2026-01-08 10:21:59,430 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGqscHhznx7MkjCFsNin59FgZXteblvg...
2026-01-08 10:21:59,431 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:00,023 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGqscHhznx7MkjCFsNin59FgZXteblvgh57cqAQ8w6Lt-zVyQDaOdqRHKZznTW_QjxfQonFNvppw2x6hxtcluUzRsbSDdpCIf-iEwF65EhQZJlA2NubizqLp8HcQ4iU9Ro5MUW57m4M0JgQvJ_qdO4fx6NeXHB3Az9QzgdFywuWqrJfymBwXNRbpRB0Jl7p HTTP/1.1" 302 280
2026-01-08 10:22:00,025 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.anecdotes.ai:443
2026-01-08 10:22:00,520 - urllib3.connectionpool - DEBUG - https://www.anecdotes.ai:443 "GET /learn/ai-regulations-in-2025-us-eu-uk-japan-china-and-more HTTP/1.1" 200 None
2026-01-08 10:22:00,523 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFBCpaw55y6Ik107CPA0LCHTu_D_DE4P...
2026-01-08 10:22:00,525 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:01,120 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFBCpaw55y6Ik107CPA0LCHTu_D_DE4PCmS2LJqnCGR0EQ4vUsu2pz0l7HOzTZSl5k3S2NXcLG7ZgDwDr4dLM4VVpFzlUnotReQMERrH-dpsgmBKGnZ-vQHZXV7TU9k_huSuzYhg8TArpUN3MUmOgMirc7iOyMk3jf9QPqZXdclNX7W_MXwOoFD HTTP/1.1" 302 274
2026-01-08 10:22:01,121 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.boardofinnovation.com:443
2026-01-08 10:22:01,644 - urllib3.connectionpool - DEBUG - https://www.boardofinnovation.com:443 "GET /top-ai-conferences-and-events-in-2024-2025/ HTTP/1.1" 200 None
2026-01-08 10:22:01,712 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF6wtszyGBakvajAgnfNQbV7fgZrCye4...
2026-01-08 10:22:01,713 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:02,331 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQF6wtszyGBakvajAgnfNQbV7fgZrCye4HDcoIPiq91uLskU0636u4exHpDdK9tLZL-n6zr_Ovb-kHmBABeKHN14y3klJZawzuZf9Z4C6GPlYjzkdkEvfEsSSOxzkMofVm-x HTTP/1.1" 302 235
2026-01-08 10:22:02,331 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): arize.com:443
2026-01-08 10:22:02,931 - urllib3.connectionpool - DEBUG - https://arize.com:443 "GET /2025-ai-conferences/ HTTP/1.1" 200 None
2026-01-08 10:22:02,938 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): arize.com:443
2026-01-08 10:22:03,171 - urllib3.connectionpool - DEBUG - https://arize.com:443 "GET /2025-ai-conferences/ HTTP/1.1" 200 None
2026-01-08 10:22:03,179 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGGhio0hrtZ6TXzU9HBNS5-g8hdXyMmK...
2026-01-08 10:22:03,181 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:03,764 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGGhio0hrtZ6TXzU9HBNS5-g8hdXyMmKHVFEjK3Kr4n0Xn9ohod4uBYZBWXPp_6bb5IA0lYIzo7EweWawl_eJQu-BX0mRcZASPUoYEJTLg2R-OFlhT59R4BTFRyWu0zsh-sxnx0IXyuXNVz7N2afDtBUxanqhCJ0M8DElCTBeCX6mf4X4-g3jXBTe-93hWqKAg= HTTP/1.1" 302 282
2026-01-08 10:22:03,766 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.ailabs.global:443
2026-01-08 10:22:04,821 - urllib3.connectionpool - DEBUG - https://www.ailabs.global:443 "GET /blog/ai-events-2025-the-must-attend-conferences-and-summits HTTP/1.1" 200 None
2026-01-08 10:22:04,824 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHKvl48dhXajREm8QYi0jPG8jh-E_74z...
2026-01-08 10:22:04,826 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:05,428 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHKvl48dhXajREm8QYi0jPG8jh-E_74zKIFBtOfXeueksYgNh4Ygq5ubZJADDNAJtSA8fb6jYYi38eTRi7d3MAksjh6c63O8PFliDwa1iSV-kPZJgXGJYdv0jDphLL_6lKykRc9V3bz7vxXDBg= HTTP/1.1" 302 246
2026-01-08 10:22:05,429 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bitcot.com:443
2026-01-08 10:22:06,546 - urllib3.connectionpool - DEBUG - https://www.bitcot.com:443 "GET /top-ai-conferences-events/ HTTP/1.1" 200 None
2026-01-08 10:22:06,982 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bitcot.com:443
2026-01-08 10:22:08,009 - urllib3.connectionpool - DEBUG - https://www.bitcot.com:443 "GET /top-ai-conferences-events/ HTTP/1.1" 200 None
2026-01-08 10:22:08,434 - researcher - INFO - Searching OpenAlex for: This chapter introduces the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the current state of the AI industry. The scope of the report is set to mid-2023.
2026-01-08 10:22:08,435 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:22:09,687 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20introduces%20the%20recent%20surge%20in%20Artificial%20Intelligence's%20popularity,%20primarily%20driven%20by%20the%20release%20of%20ChatGPT%20in%20late%202022.%20It%20states%20that%20the%20report%20aims%20to%20summarize%20the%20current%20state%20of%20the%20AI%20industry.%20The%20scope%20of%20the%20report%20is%20set%20to%20mid-2023.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:22:09,689 - httpcore.connection - DEBUG - close.started
2026-01-08 10:22:09,689 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:22:11,691 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:22:12,061 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:22:12,061 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:22:12,061 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:22:12,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1A1C90>
2026-01-08 10:22:12,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0833C7E30> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:22:12,135 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1A1690>
2026-01-08 10:22:12,135 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:22:12,135 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:22:12,135 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:22:12,136 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:22:12,136 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:22:23,342 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:22:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=11199'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:22:23,342 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:22:23,343 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:22:23,343 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:22:23,344 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:22:23,344 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:22:23,344 - updater - INFO - Chapter update successful
2026-01-08 10:22:23,344 - httpcore.connection - DEBUG - close.started
2026-01-08 10:22:23,345 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:22:25,346 - researcher - INFO - Researching 'This chapter focuses on the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major tech companies, such as Google's Bard and Meta's Llama 1, released for research. The primary trend in LLM development is noted to be the emphasis on increasing scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:22:25,720 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:22:25,721 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:22:25,734 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1FD250>
2026-01-08 10:22:25,734 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D09C0CBEC0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:22:25,803 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1FC090>
2026-01-08 10:22:25,803 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:22:25,803 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:22:25,803 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:22:25,803 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:22:25,804 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:22:29,469 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:22:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3649'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:22:29,469 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:22:29,470 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:22:29,470 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:22:29,470 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:22:29,470 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:22:29,470 - researcher - ERROR - Web research failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:22:29,471 - researcher - INFO - Searching OpenAlex for: This chapter focuses on the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major tech companies, such as Google's Bard and Meta's Llama 1, released for research. The primary trend in LLM development is noted to be the emphasis on increasing scale and parameter counts.
2026-01-08 10:22:29,472 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:22:30,703 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20focuses%20on%20the%20current%20landscape%20of%20Large%20Language%20Models%20(LLMs),%20highlighting%20GPT-4%20as%20the%20state-of-the-art%20model%20in%20early%202023.%20It%20also%20mentions%20key%20contributions%20from%20other%20major%20tech%20companies,%20such%20as%20Google's%20Bard%20and%20Meta's%20Llama%201,%20released%20for%20research.%20The%20primary%20trend%20in%20LLM%20development%20is%20noted%20to%20be%20the%20emphasis%20on%20increasing%20scale%20and%20parameter%20counts.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:22:32,705 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:22:33,093 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:22:33,093 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:22:33,093 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:22:33,104 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1E22D0>
2026-01-08 10:22:33,104 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D09C189E20> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:22:33,167 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1E3810>
2026-01-08 10:22:33,169 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:22:33,169 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:22:33,169 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:22:33,169 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:22:33,169 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:22:38,803 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:22:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5624'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:22:38,804 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:22:38,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:22:38,804 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:22:38,804 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:22:38,804 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:22:38,804 - updater - INFO - Chapter update successful
2026-01-08 10:22:38,806 - httpcore.connection - DEBUG - close.started
2026-01-08 10:22:38,806 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:22:40,807 - researcher - INFO - Researching 'This concluding chapter emphasizes the rapid pace of development within the Artificial Intelligence field. It highlights that the year 2023 is significant as it marks the commencement of the generative AI era. The statement suggests a pivotal moment in AI's evolution.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:22:41,200 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:22:41,201 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:22:41,221 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1D99D0>
2026-01-08 10:22:41,221 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0833C4DD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:22:41,293 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1D8110>
2026-01-08 10:22:41,293 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:22:41,293 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:22:41,293 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:22:41,294 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:22:41,294 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:22:52,981 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:22:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=11673'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:22:52,981 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:22:52,981 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:22:52,981 - httpcore.connection - DEBUG - close.started
2026-01-08 10:22:52,981 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:22:52,987 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:22:52,987 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:22:52,987 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:22:52,989 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEcTKK4wSVwtrLDjg5aSYUY41_koYSGn...
2026-01-08 10:22:52,990 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:53,331 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEcTKK4wSVwtrLDjg5aSYUY41_koYSGn0GpxPqCRSoYttDbnsbjHZ0yclWUgKCLONSa06_zSqD9HsciTVk41uqoizdphm1C4Nwzk4NUS6zHi183nvx_3nBi2hPZRBDZ_WWhKeu0K_gdvi0O0HKkSzjJixAJ9OyY3OxavnPL HTTP/1.1" 302 262
2026-01-08 10:22:53,334 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.websensa.com:443
2026-01-08 10:22:53,866 - urllib3.connectionpool - DEBUG - https://www.websensa.com:443 "GET /blog/13-breakthroughs-generative-ai-2023 HTTP/1.1" 200 None
2026-01-08 10:22:53,868 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGRNgqJnPvWA5BqJH2UI_1_f7xwIekD3...
2026-01-08 10:22:53,871 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:54,468 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGRNgqJnPvWA5BqJH2UI_1_f7xwIekD3JCI_yJCE1tlOSBo0Nm6CAPE5QKzLJHHCrJDPh8KAXLcv0zFEKRlTnRSTVin9dT5CAudJI-rC68wt3mBtIUflMohgvhrrvF5v1cJNMIBQ8nrWCXuc9G0BjbkFS8yrQdh7YO0TeN0lfU_rj5ck3zxIC9GOoQCZ-U6t7yBsTijfuMvquwzeGlBmYpx7eo= HTTP/1.1" 302 300
2026-01-08 10:22:54,468 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com:443
2026-01-08 10:22:54,859 - urllib3.connectionpool - DEBUG - https://www.forbes.com:443 "GET /sites/tiriasresearch/2023/04/12/the-dawn-of-creation-2023-rise-of-generative-ai/ HTTP/1.1" 403 770
2026-01-08 10:22:54,862 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com:443
2026-01-08 10:22:55,231 - urllib3.connectionpool - DEBUG - https://www.forbes.com:443 "GET /sites/tiriasresearch/2023/04/12/the-dawn-of-creation-2023-rise-of-generative-ai/ HTTP/1.1" 403 770
2026-01-08 10:22:55,233 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGWgHAmoJeroHGEMA7-Q-mDOddUpBp3K...
2026-01-08 10:22:55,234 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:55,803 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGWgHAmoJeroHGEMA7-Q-mDOddUpBp3KGU4pV0w-ZPZx83vlYwzuBtZ0Ix17kLNuj-ARB3RNJswdyHchcydnnguYBM_xYxcbQ8Rzdrj2VheGnNntEvuNfM3qTQS6FJvQ6ezlb3kHmdIiwXe82ocMJG6QitfAy64EuVq4-SdFh39WuM= HTTP/1.1" 302 267
2026-01-08 10:22:55,804 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.silenteight.com:443
2026-01-08 10:22:56,379 - urllib3.connectionpool - DEBUG - https://www.silenteight.com:443 "GET /explore-learn/major-events-in-ai-2018-2025 HTTP/1.1" 200 41735
2026-01-08 10:22:56,387 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFRxPxY8iHjnawM9LnZl9gDYHlke2ekC...
2026-01-08 10:22:56,392 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:56,972 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFRxPxY8iHjnawM9LnZl9gDYHlke2ekC3gML2P6j6X2AgX_9TPXgH5L_N0eGhasX1sYNNKshmBqjtBHsXRzGWaKNotiSqDc0Rv66Y0QwUcHySWeR_NwXDl8aKx_WkGE69s3_LT9AEEIkqiQ-JZT_fLrzQnbWnp0c7t8RVQj9SMZkw== HTTP/1.1" 302 266
2026-01-08 10:22:56,975 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.analyticsvidhya.com:443
2026-01-08 10:22:57,960 - urllib3.connectionpool - DEBUG - https://www.analyticsvidhya.com:443 "GET /blog/2023/12/ai-in-2023-the-timeline/ HTTP/1.1" 200 None
2026-01-08 10:22:58,116 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFgLMwldrk2fAbyFmJco7JLmvra3W_66...
2026-01-08 10:22:58,117 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:22:58,709 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFgLMwldrk2fAbyFmJco7JLmvra3W_66r1Q0fj8vPLfhpNIaVL4xPS3yMA9K0HTGXLMuW6ZuefH-ogxRnHRlFbELsm7svOIE-UvI3pa1ttwpyELsJKvJytd-eRgqWXgf5rDAxnAM6Q2FT-W8oqd1FkV5abHPmuItcbGJLIG9mNeXHE0xNK3LkoBdQRMfxBKC1I5TQ_epf1ED4FNL6tQ150= HTTP/1.1" 302 297
2026-01-08 10:22:58,709 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zdnet.com:443
2026-01-08 10:23:00,777 - urllib3.connectionpool - DEBUG - https://www.zdnet.com:443 "GET /article/ai-in-2023-a-year-of-breakthroughs-that-left-no-human-thing-unchanged/ HTTP/1.1" 200 165055
2026-01-08 10:23:00,937 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zdnet.com:443
2026-01-08 10:23:01,517 - urllib3.connectionpool - DEBUG - https://www.zdnet.com:443 "GET /article/ai-in-2023-a-year-of-breakthroughs-that-left-no-human-thing-unchanged/ HTTP/1.1" 200 165055
2026-01-08 10:23:01,683 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEeEnXkKnlsKJAEiLE4nOFrvTKt9u9PC...
2026-01-08 10:23:01,684 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:02,318 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEeEnXkKnlsKJAEiLE4nOFrvTKt9u9PC8lfmscRqhyEz0w5Iw_-RsJmGdctNny_4HUMLQFaik5_YKkXH0kXS9F7_h4Ht_qUJE8KJAnmetHjsgC5iKHXmdn942LU2OCwhP-mMVpqNwGVT2tcdGeRKnIkeK5CiKepmHctsr_2JDqB4Y8ANVAA HTTP/1.1" 302 271
2026-01-08 10:23:02,320 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.gminsights.com:443
2026-01-08 10:23:03,485 - urllib3.connectionpool - DEBUG - https://www.gminsights.com:443 "GET /industry-analysis/generative-ai-solution-market HTTP/1.1" 200 None
2026-01-08 10:23:03,583 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGULUHoRJaOHF3J96QoCfdDeDK1v2bSk...
2026-01-08 10:23:03,585 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:04,187 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGULUHoRJaOHF3J96QoCfdDeDK1v2bSkcJc9MYPa3QpoZ46XIIDCNQw12g6WnwC1BQBAleMxp-K3E-L5TKgCULt-6HESPwB2BpmThECeFovsXLm2EcsWSL2hnoLN2R30LPmV8OD_15zkK7aGvhPuC1tYvI0cJX4vw== HTTP/1.1" 302 257
2026-01-08 10:23:04,189 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): hatchworks.com:443
2026-01-08 10:23:04,649 - urllib3.connectionpool - DEBUG - https://hatchworks.com:443 "GET /blog/gen-ai/generative-ai-statistics/ HTTP/1.1" 200 None
2026-01-08 10:23:04,663 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG8-0FrB79SU8zck2mdfBPhrtgDH-A1p...
2026-01-08 10:23:04,664 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:05,273 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQG8-0FrB79SU8zck2mdfBPhrtgDH-A1pMWm_RkO9WdzjdRWTBLxSpDiY9VR8TZMuadroZ8zDc2WehMhZ9_jUX1HpK179qzwd40N8LHRMQn1bO4OvdcHYvICDTO89ro255CRN0y-amKqefHM6EjhmZRHY_r8JHWQugjfNe8tHA== HTTP/1.1" 302 263
2026-01-08 10:23:05,274 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.itpathsolutions.com:443
2026-01-08 10:23:06,577 - urllib3.connectionpool - DEBUG - https://www.itpathsolutions.com:443 "GET /generative-ai-impact-on-industries HTTP/1.1" 200 None
2026-01-08 10:23:06,882 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYcMOaHvGastQiXq9NHn57JaMn_IHdg...
2026-01-08 10:23:06,884 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:07,498 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHYcMOaHvGastQiXq9NHn57JaMn_IHdgzO4gfmanZnvR_tYp0V4q7gYmaUbyLxbIdqJOaB1Ed6799P4SD-gkQ-Sn5bvNvodGbRhJaGH4-j1STLHTqImgKQQep8Z1_QmGmJroG7SROiYsEJ4 HTTP/1.1" 302 244
2026-01-08 10:23:07,500 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai.koombea.com:443
2026-01-08 10:23:07,918 - urllib3.connectionpool - DEBUG - https://ai.koombea.com:443 "GET /blog/key-ai-developments HTTP/1.1" 200 None
2026-01-08 10:23:07,921 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHfGUaMpTV5YordG4OitGZIP1tvrwcTr...
2026-01-08 10:23:07,922 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:08,505 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHfGUaMpTV5YordG4OitGZIP1tvrwcTrAooXVY7x0Hor3DpVKu3WL1eG_WiQQownp8jlg9nQFTL7o5maeKGKx-vAmc9czUScAQ3MOO4rWmlLpJYSu5nQB_WR2Jld2sAP_7A56GA_XzLhnjY5TvA-Pn8NmAywGUAtJun HTTP/1.1" 302 259
2026-01-08 10:23:08,507 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.google:443
2026-01-08 10:23:09,010 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /technology/ai/2025-research-breakthroughs/ HTTP/1.1" 301 337
2026-01-08 10:23:09,235 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /innovation-and-ai/products/2025-research-breakthroughs/ HTTP/1.1" 200 None
2026-01-08 10:23:09,357 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETORRYZfQsEr8nlKTeqrE-COSx2ej9f...
2026-01-08 10:23:09,359 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:09,960 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQETORRYZfQsEr8nlKTeqrE-COSx2ej9fmoJLzHf1QPYDhe4gaHUXopPUGIS69Ow8HhKtyO9N5Z_MlGT__USvNJRextHqPPZbi7WTc_mbt-q8DghHcwC2U9GNnh24vggkg_aNR5YH8bTXbK0_i6q1TYglQ== HTTP/1.1" 302 251
2026-01-08 10:23:09,961 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.amplifai.com:443
2026-01-08 10:23:10,436 - urllib3.connectionpool - DEBUG - https://www.amplifai.com:443 "GET /blog/generative-ai-statistics HTTP/1.1" 200 None
2026-01-08 10:23:10,438 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFcIFo-hZ2EoFaSXczX4hInzmD2za3rf...
2026-01-08 10:23:10,439 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:11,039 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQFcIFo-hZ2EoFaSXczX4hInzmD2za3rf_NeZQDE8OhggjwvZNHdYaZS0BNx0fl_Yr800TRgLLOnPJvFusWEnpAhJwG6JYa6bnybz8tvV7VnsPjN3ShQI7VIvvPGDLBScN2mpbD8NFjH07LrHUU2P5Efn_bJ1YST3cIqWjc98Ovp7uME4HZtc-AmS0YQv0Ga70X2FC2pC2VkthlpLDszdaOlNywVwxSlAqhqt-4XToXf HTTP/1.1" 302 313
2026-01-08 10:23:11,040 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com:443
2026-01-08 10:23:11,426 - urllib3.connectionpool - DEBUG - https://www.forbes.com:443 "GET /councils/forbesbusinesscouncil/2024/12/17/the-future-of-generative-ai-what-to-expect-in-2025/ HTTP/1.1" 403 770
2026-01-08 10:23:11,429 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com:443
2026-01-08 10:23:11,802 - urllib3.connectionpool - DEBUG - https://www.forbes.com:443 "GET /councils/forbesbusinesscouncil/2024/12/17/the-future-of-generative-ai-what-to-expect-in-2025/ HTTP/1.1" 403 770
2026-01-08 10:23:11,803 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGPllPVJNkL9Wbmjjjk2ZLfTlbYYdpwU...
2026-01-08 10:23:11,804 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:12,142 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGPllPVJNkL9Wbmjjjk2ZLfTlbYYdpwUgaleOkZ_3a6h7q0-23aEWkQbEGgu59J4RrcL5f91F-NYXKi5F_Ve7NOgYtBgCbSjhsDlZODCEhqX-2Qxz8O-ESLQgZEsRWOV8Bp3mAATN3u-rOogGcuS3INOaekgn2D7dGBfz37Ig== HTTP/1.1" 302 263
2026-01-08 10:23:12,142 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.kdnuggets.com:443
2026-01-08 10:23:12,499 - urllib3.connectionpool - DEBUG - https://www.kdnuggets.com:443 "GET /the-10-ai-developments-that-defined-2025 HTTP/1.1" 200 None
2026-01-08 10:23:12,644 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGLrxeVDeL9d_zlFHJxm_HTPdYSHKWml...
2026-01-08 10:23:12,645 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:13,249 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGLrxeVDeL9d_zlFHJxm_HTPdYSHKWmlbT3tGoXFhXp_jqDpdbj12S-kPd4BlGZqeEmA3Av7_BK6L3sFurU4oLdMuee7oMFEY2WyamDQySA_n5pBvW0thXJho_BCIv4XGSXBAEw HTTP/1.1" 302 238
2026-01-08 10:23:13,250 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): eu.36kr.com:443
2026-01-08 10:23:14,760 - urllib3.connectionpool - DEBUG - https://eu.36kr.com:443 "GET /en/p/3617661153260292 HTTP/1.1" 200 None
2026-01-08 10:23:14,770 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): eu.36kr.com:443
2026-01-08 10:23:15,997 - urllib3.connectionpool - DEBUG - https://eu.36kr.com:443 "GET /en/p/3617661153260292 HTTP/1.1" 200 None
2026-01-08 10:23:16,259 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGnw7judCdUQ-EMLlImHJTBeUNnI3QYb...
2026-01-08 10:23:16,260 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:16,869 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGnw7judCdUQ-EMLlImHJTBeUNnI3QYbA2Z5h3em17Vt2tGYFismDLvhjcvkbVRLlP2lPufT1sHTRZzCwVx98HGRUc_t08itEv4WG7OhnM9 HTTP/1.1" 302 217
2026-01-08 10:23:16,870 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai-2027.com:443
2026-01-08 10:23:17,379 - urllib3.connectionpool - DEBUG - https://ai-2027.com:443 "GET / HTTP/1.1" 200 None
2026-01-08 10:23:17,509 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGAReeYbPPAioGimEeOJrSBF90ru2D8P...
2026-01-08 10:23:17,510 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:18,103 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGAReeYbPPAioGimEeOJrSBF90ru2D8PfgfKUY5FaVebSDLP1Ow5bp5_qsOg0UVnJ0ezVHh3BQv7BhrE-TxsRaFUcbXXRHBCLlfRkN0UPO54NN08o8VjJlgD5sJC6AjO-YZnE7I4nQfJbrFk-Jfn1wccYNgkW4NFKk5vnJqRla7K7L0vDX80KTO9AweLx0MXDsG HTTP/1.1" 302 283
2026-01-08 10:23:18,104 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.eimt.edu.eu:443
2026-01-08 10:23:18,748 - urllib3.connectionpool - DEBUG - https://www.eimt.edu.eu:443 "GET /the-future-of-generative-ai-trends-to-watch-in-2025-and-beyond HTTP/1.1" 200 None
2026-01-08 10:23:19,162 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEYV5_XZPoaY0orvhT4YW-37FnrIWyFI...
2026-01-08 10:23:19,163 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:19,793 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQEYV5_XZPoaY0orvhT4YW-37FnrIWyFI_Oaai_C0l1oCJpwxAMTKReWWcenl2hhpWHzdB_RqnaP_2hkBDBEytuJCd1X0x1oofNvSOkWA2QXW3fyuKe2AEKJYV3ouIp3r2KTz3Zx5javfqJqtIYnYeMuXMXA4BfBUj0Pl89TTHkaUeJ-XBFfBPFYP74= HTTP/1.1" 302 276
2026-01-08 10:23:19,793 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com.au:443
2026-01-08 10:23:20,696 - urllib3.connectionpool - DEBUG - https://www.forbes.com.au:443 "GET /news/innovation/the-key-ai-moments-that-defined-2025/ HTTP/1.1" 200 None
2026-01-08 10:23:20,785 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlwodK1UDxiVNBLLoK_5xgZLPPo8u3P...
2026-01-08 10:23:20,786 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:21,403 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGlwodK1UDxiVNBLLoK_5xgZLPPo8u3PdwaBE3e_jQGu3PWlDD-LdUQ9VBGTI3tZwx1kXcpT7bsXxGI8wc4iNw54JM6rtGJCp0djP34TqwF4qgaQJqem7gDJMpirNgKDEE2AXaNkDwGWv94TMV41onw7awA HTTP/1.1" 302 253
2026-01-08 10:23:21,404 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.crescendo.ai:443
2026-01-08 10:23:22,008 - urllib3.connectionpool - DEBUG - https://www.crescendo.ai:443 "GET /news/latest-ai-news-and-updates HTTP/1.1" 200 None
2026-01-08 10:23:22,022 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQErdDUvgbvRZOAH9Y8knMB_raGhSheAw...
2026-01-08 10:23:22,023 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:22,617 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQErdDUvgbvRZOAH9Y8knMB_raGhSheAwLsAmHVMnwjkSS1mXjYjOu56w2Gp_uFzP-wQ8fIFKWca8d97S6pinu8Ho0lKJUBOvyhhWEwVB4xMJBd1zhdmIzaNpQ9GMKAethwEoOwNN5YUHSpVYXYZH5948acLxDd435Ju0eE0GtU6bskJ4Rpskk9Fklg= HTTP/1.1" 302 276
2026-01-08 10:23:22,618 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.grandviewresearch.com:443
2026-01-08 10:23:23,023 - urllib3.connectionpool - DEBUG - https://www.grandviewresearch.com:443 "GET /industry-analysis/generative-ai-market-report HTTP/1.1" 200 None
2026-01-08 10:23:23,027 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHy3gxDp4XdPGn6z-selH--KBW0MZd5o...
2026-01-08 10:23:23,027 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:23,620 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHy3gxDp4XdPGn6z-selH--KBW0MZd5oOZbfCzJJPH_NGGjrcO09kbRPN90X9WHA331aKSZGcAs--oyWxiRc7nZr97K-MWtOUSXyEKKaH3ISGUcTDLA76ZjFfWf0UvMPF07q6_gA6YobTOFGC3vuAzbLUKq_1evmaguPA== HTTP/1.1" 302 260
2026-01-08 10:23:23,621 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cloud-awards.com:443
2026-01-08 10:23:24,595 - urllib3.connectionpool - DEBUG - https://www.cloud-awards.com:443 "GET /how-gen-ai-will-revolutionize-2025 HTTP/1.1" 200 None
2026-01-08 10:23:24,609 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHlWeWyBRaorNTWGZJYcmOldALs1byzE...
2026-01-08 10:23:24,609 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:25,191 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQHlWeWyBRaorNTWGZJYcmOldALs1byzEZ-c3fkGALwur_KjmfxMt4LKq-CAksKBcOGo32-z_x5iMmz7YvCpmC5RUwRD3Qt8IuLRfsc2ELHpOvajV0SwxMiU_hrU_-ZmNdZMfbN-DSb5OIgTL6IVOoXF0UoDYcl7rF2h-vM= HTTP/1.1" 302 261
2026-01-08 10:23:25,192 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): fueler.io:443
2026-01-08 10:23:25,955 - urllib3.connectionpool - DEBUG - https://fueler.io:443 "GET /blog/key-ai-research-breakthroughs-from-so-far HTTP/1.1" 200 None
2026-01-08 10:23:26,045 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): fueler.io:443
2026-01-08 10:23:26,550 - urllib3.connectionpool - DEBUG - https://fueler.io:443 "GET /blog/key-ai-research-breakthroughs-from-so-far HTTP/1.1" 200 None
2026-01-08 10:23:26,694 - researcher - DEBUG - Resolving redirect: https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGgxq1EaR-WCQUsKQ_U9usqvFety5tNb...
2026-01-08 10:23:26,695 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:27,319 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGgxq1EaR-WCQUsKQ_U9usqvFety5tNb3lpMIHcPR0MM98H72QFGHZ62mSgaYwETryi9Sg1xq_Y0Hr5dsO3b8AXdgMU3X7b8GJFD7lQy-tDYbGMiBwOCv1BkDBKIMwhwhte2IxtBkYTE1GHzhdNfzxOaiT9S9G1YazVndvqLR9RNtoWqPHKtA== HTTP/1.1" 302 272
2026-01-08 10:23:27,320 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mit.edu:443
2026-01-08 10:23:27,864 - urllib3.connectionpool - DEBUG - https://news.mit.edu:443 "GET /2025/explained-generative-ai-environmental-impact-0117 HTTP/1.1" 200 34523
2026-01-08 10:23:27,942 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mit.edu:443
2026-01-08 10:23:28,303 - urllib3.connectionpool - DEBUG - https://news.mit.edu:443 "GET /2025/explained-generative-ai-environmental-impact-0117 HTTP/1.1" 200 34523
2026-01-08 10:23:28,376 - researcher - INFO - Searching OpenAlex for: This concluding chapter emphasizes the rapid pace of development within the Artificial Intelligence field. It highlights that the year 2023 is significant as it marks the commencement of the generative AI era. The statement suggests a pivotal moment in AI's evolution.
2026-01-08 10:23:28,377 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:23:29,215 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20concluding%20chapter%20emphasizes%20the%20rapid%20pace%20of%20development%20within%20the%20Artificial%20Intelligence%20field.%20It%20highlights%20that%20the%20year%202023%20is%20significant%20as%20it%20marks%20the%20commencement%20of%20the%20generative%20AI%20era.%20The%20statement%20suggests%20a%20pivotal%20moment%20in%20AI's%20evolution.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:23:29,217 - httpcore.connection - DEBUG - close.started
2026-01-08 10:23:29,217 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:23:31,219 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:23:31,583 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:23:31,583 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:23:31,584 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:23:31,595 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D084D737D0>
2026-01-08 10:23:31,596 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D0833C6060> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:23:31,659 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D09C1FDE50>
2026-01-08 10:23:31,659 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:23:31,659 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:23:31,659 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:23:31,659 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:23:31,659 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:23:32,125 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:23:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=455'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:23:32,125 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:23:32,125 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:23:32,125 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:23:32,125 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:23:32,125 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:23:32,125 - updater - ERROR - Failed to update chapter: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:23:32,127 - updater - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:23:32,173 - httpcore.connection - DEBUG - close.started
2026-01-08 10:23:32,173 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:23:32,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:23:32,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:23:32,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:23:32,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:23:32,180 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:23:32,180 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:23:32,180 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:23:32,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:23:32,198 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): arize.com:443
2026-01-08 10:23:33,345 - urllib3.connectionpool - DEBUG - https://arize.com:443 "GET /2025-ai-conferences/) HTTP/1.1" 302 None
2026-01-08 10:23:33,379 - urllib3.connectionpool - DEBUG - https://arize.com:443 "GET /2025-ai-conferences/ HTTP/1.1" 200 None
2026-01-08 10:23:33,380 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.thoropass.com:443
2026-01-08 10:23:34,289 - urllib3.connectionpool - DEBUG - https://www.thoropass.com:443 "GET /blog/ai-regulations) HTTP/1.1" 404 None
2026-01-08 10:23:34,292 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertexaisearch.cloud.google.com:443
2026-01-08 10:23:34,906 - urllib3.connectionpool - DEBUG - https://vertexaisearch.cloud.google.com:443 "GET /grounding-api-redirect/AUZIYQGS1LqwK2c_3D4I3eaynjryGw5uGqjz8B-ZXxZ2wckbqwMpCns5Z_T5OXvO3u3SqVf28lM8BkDu7gzeKRHnWBoQ9YGHlSDbwZqlapFuaIoMq5N584uhaqtTjjSpipXxqxmB3SVQyRsflT16D-xGUTRxD5PFTeDJUJlhTMLSXWGJYelsUa-5wQ2ql72ZAYJO83d1AuoMLnWsjHNhrix9ub0dsZH1kw==) HTTP/1.1" 404 1813
2026-01-08 10:23:34,909 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.itpathsolutions.com:443
2026-01-08 10:23:36,139 - urllib3.connectionpool - DEBUG - https://www.itpathsolutions.com:443 "GET /generative-ai-impact-on-industries) HTTP/1.1" 200 None
2026-01-08 10:23:36,142 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.google:443
2026-01-08 10:23:36,584 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /innovation-and-ai/products/2025-research-breakthroughs/) HTTP/1.1" 308 341
2026-01-08 10:23:37,250 - urllib3.connectionpool - DEBUG - https://blog.google:443 "GET /innovation-and-ai/products/2025-research-breakthroughs/)/ HTTP/1.1" 404 None
2026-01-08 10:23:37,253 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.amplifai.com:443
2026-01-08 10:23:38,250 - urllib3.connectionpool - DEBUG - https://www.amplifai.com:443 "GET /blog/generative-ai-statistics) HTTP/1.1" 404 None
2026-01-08 10:23:38,251 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bitcot.com:443
2026-01-08 10:23:40,136 - urllib3.connectionpool - DEBUG - https://www.bitcot.com:443 "GET /top-ai-conferences-events/) HTTP/1.1" 301 0
2026-01-08 10:23:40,577 - urllib3.connectionpool - DEBUG - https://www.bitcot.com:443 "GET /top-ai-conferences-events/ HTTP/1.1" 200 None
2026-01-08 10:23:40,579 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.timesofai.com:443
2026-01-08 10:23:41,205 - urllib3.connectionpool - DEBUG - https://www.timesofai.com:443 "GET /industry-insights/roundup-of-ai-model-releases-in-2025/) HTTP/1.1" 301 331
2026-01-08 10:23:41,837 - urllib3.connectionpool - DEBUG - https://www.timesofai.com:443 "GET /industry-insights/roundup-of-ai-model-releases-in-2025/)/ HTTP/1.1" 404 None
2026-01-08 10:23:41,840 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cimplifi.com:443
2026-01-08 10:23:42,585 - urllib3.connectionpool - DEBUG - https://www.cimplifi.com:443 "GET /resources/the-updated-state-of-ai-regulations-for-2025/) HTTP/1.1" 301 None
2026-01-08 10:23:42,803 - urllib3.connectionpool - DEBUG - https://www.cimplifi.com:443 "GET /resources/the-updated-state-of-ai-regulations-for-2025/ HTTP/1.1" 200 None
2026-01-08 10:23:42,804 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.youtube.com:443
2026-01-08 10:23:43,205 - urllib3.connectionpool - DEBUG - https://www.youtube.com:443 "GET /watch?v=1KUKh7TofLg) HTTP/1.1" 200 None
2026-01-08 10:23:43,207 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bestbrokers.com:443
2026-01-08 10:23:43,722 - urllib3.connectionpool - DEBUG - https://www.bestbrokers.com:443 "GET /forex-brokers/the-state-of-ai-venture-capital-in-2025-ai-boom-slows-with-fewer-startups-but-bigger-bets/) HTTP/1.1" 301 0
2026-01-08 10:23:43,802 - urllib3.connectionpool - DEBUG - https://www.bestbrokers.com:443 "GET /forex-brokers/the-state-of-ai-venture-capital-in-2025-ai-boom-slows-with-fewer-startups-but-bigger-bets/ HTTP/1.1" 200 15316
2026-01-08 10:23:43,805 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): hatchworks.com:443
2026-01-08 10:23:44,509 - urllib3.connectionpool - DEBUG - https://hatchworks.com:443 "GET /blog/gen-ai/generative-ai-statistics/) HTTP/1.1" 301 None
2026-01-08 10:23:44,529 - urllib3.connectionpool - DEBUG - https://hatchworks.com:443 "GET /blog/gen-ai/generative-ai-statistics/ HTTP/1.1" 200 None
2026-01-08 10:23:44,531 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.analyticsvidhya.com:443
2026-01-08 10:23:45,068 - urllib3.connectionpool - DEBUG - https://www.analyticsvidhya.com:443 "GET /blog/2023/12/ai-in-2023-the-timeline/) HTTP/1.1" 301 None
2026-01-08 10:23:45,390 - urllib3.connectionpool - DEBUG - https://www.analyticsvidhya.com:443 "GET /blog/2023/12/ai-in-2023-the-timeline/ HTTP/1.1" 200 None
2026-01-08 10:23:45,392 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.grandviewresearch.com:443
2026-01-08 10:23:45,779 - urllib3.connectionpool - DEBUG - https://www.grandviewresearch.com:443 "GET /industry-analysis/generative-ai-market-report) HTTP/1.1" 200 None
2026-01-08 10:23:45,781 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.cloud-awards.com:443
2026-01-08 10:23:49,225 - urllib3.connectionpool - DEBUG - https://www.cloud-awards.com:443 "GET /how-gen-ai-will-revolutionize-2025) HTTP/1.1" 301 None
2026-01-08 10:23:49,247 - urllib3.connectionpool - DEBUG - https://www.cloud-awards.com:443 "GET /how-gen-ai-will-revolutionize-2025 HTTP/1.1" 200 None
2026-01-08 10:23:49,250 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): decimalpointanalytics.com:443
2026-01-08 10:23:50,279 - urllib3.connectionpool - DEBUG - https://decimalpointanalytics.com:443 "GET /who-we-are/newsroom/navigating-the-ai-landscape-key-trends-shaping-2025-and-beyond) HTTP/1.1" 200 None
2026-01-08 10:23:50,281 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.boardofinnovation.com:443
2026-01-08 10:23:50,879 - urllib3.connectionpool - DEBUG - https://www.boardofinnovation.com:443 "GET /top-ai-conferences-and-events-in-2024-2025/) HTTP/1.1" 301 None
2026-01-08 10:23:51,320 - urllib3.connectionpool - DEBUG - https://www.boardofinnovation.com:443 "GET /top-ai-conferences-and-events-in-2024-2025/)/ HTTP/1.1" 404 None
2026-01-08 10:23:51,322 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.mit.edu:443
2026-01-08 10:23:51,990 - urllib3.connectionpool - DEBUG - https://news.mit.edu:443 "GET /2025/explained-generative-ai-environmental-impact-0117) HTTP/1.1" 404 16041
2026-01-08 10:23:51,991 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.websensa.com:443
2026-01-08 10:23:53,002 - urllib3.connectionpool - DEBUG - https://www.websensa.com:443 "GET /blog/13-breakthroughs-generative-ai-2023) HTTP/1.1" 404 None
2026-01-08 10:23:53,004 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.anecdotes.ai:443
2026-01-08 10:23:54,643 - urllib3.connectionpool - DEBUG - https://www.anecdotes.ai:443 "GET /learn/ai-regulations-in-2025-us-eu-uk-japan-china-and-more) HTTP/1.1" 404 None
2026-01-08 10:23:54,646 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): vertu.com:443
2026-01-08 10:23:57,382 - urllib3.connectionpool - DEBUG - https://vertu.com:443 "GET /lifestyle/the-ai-model-race-reaches-singularity-speed/) HTTP/1.1" 301 0
2026-01-08 10:23:57,448 - urllib3.connectionpool - DEBUG - https://vertu.com:443 "GET /lifestyle/the-ai-model-race-reaches-singularity-speed/ HTTP/1.1" 200 None
2026-01-08 10:23:57,450 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai-2027.com:443
2026-01-08 10:23:57,810 - urllib3.connectionpool - DEBUG - https://ai-2027.com:443 "GET /) HTTP/1.1" 404 None
2026-01-08 10:23:57,812 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.gminsights.com:443
2026-01-08 10:23:58,460 - urllib3.connectionpool - DEBUG - https://www.gminsights.com:443 "GET /industry-analysis/generative-ai-solution-market) HTTP/1.1" 404 None
2026-01-08 10:23:58,463 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com:443
2026-01-08 10:23:58,858 - urllib3.connectionpool - DEBUG - https://www.forbes.com:443 "GET /councils/forbesbusinesscouncil/2024/12/17/the-future-of-generative-ai-what-to-expect-in-2025/) HTTP/1.1" 403 770
2026-01-08 10:23:58,860 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.eimt.edu.eu:443
2026-01-08 10:23:59,469 - urllib3.connectionpool - DEBUG - https://www.eimt.edu.eu:443 "GET /the-future-of-generative-ai-trends-to-watch-in-2025-and-beyond) HTTP/1.1" 200 None
2026-01-08 10:23:59,472 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.ailabs.global:443
2026-01-08 10:24:00,151 - urllib3.connectionpool - DEBUG - https://www.ailabs.global:443 "GET /blog/ai-events-2025-the-must-attend-conferences-and-summits) HTTP/1.1" 404 None
2026-01-08 10:24:00,153 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai.koombea.com:443
2026-01-08 10:24:01,057 - urllib3.connectionpool - DEBUG - https://ai.koombea.com:443 "GET /blog/key-ai-developments) HTTP/1.1" 404 None
2026-01-08 10:24:01,059 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:24:01,302 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /@aarondiblasi/the-10-most-important-ai-moments-of-2023-03269894e1b6) HTTP/1.1" 403 None
2026-01-08 10:24:01,304 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com.au:443
2026-01-08 10:24:06,643 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): autogpt.net:443
2026-01-08 10:24:07,629 - urllib3.connectionpool - DEBUG - https://autogpt.net:443 "GET /ai-in-2023-review-a-timeline-of-artificial-intelligence-advancements/) HTTP/1.1" 301 None
2026-01-08 10:24:07,785 - urllib3.connectionpool - DEBUG - https://autogpt.net:443 "GET /ai-in-2023-review-a-timeline-of-artificial-intelligence-advancements/ HTTP/1.1" 200 None
2026-01-08 10:24:07,788 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.forbes.com:443
2026-01-08 10:24:08,181 - urllib3.connectionpool - DEBUG - https://www.forbes.com:443 "GET /sites/tiriasresearch/2023/04/12/the-dawn-of-creation-2023-rise-of-generative-ai/) HTTP/1.1" 403 770
2026-01-08 10:24:08,185 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): fueler.io:443
2026-01-08 10:24:08,916 - urllib3.connectionpool - DEBUG - https://fueler.io:443 "GET /blog/key-ai-research-breakthroughs-from-so-far) HTTP/1.1" 404 None
2026-01-08 10:24:08,918 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.silenteight.com:443
2026-01-08 10:24:09,397 - urllib3.connectionpool - DEBUG - https://www.silenteight.com:443 "GET /explore-learn/major-events-in-ai-2018-2025) HTTP/1.1" 404 34013
2026-01-08 10:24:09,398 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): medium.com:443
2026-01-08 10:24:09,645 - urllib3.connectionpool - DEBUG - https://medium.com:443 "GET /@jyotishmandas85p/the-latest-generative-ai-models-in-2025-a-comprehensive-guide-58f7dcb9f8f3) HTTP/1.1" 403 None
2026-01-08 10:24:09,646 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.crescendo.ai:443
2026-01-08 10:24:10,762 - urllib3.connectionpool - DEBUG - https://www.crescendo.ai:443 "GET /news/latest-ai-news-and-updates) HTTP/1.1" 404 None
2026-01-08 10:24:10,762 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.index.dev:443
2026-01-08 10:24:11,771 - urllib3.connectionpool - DEBUG - https://www.index.dev:443 "GET /blog/ai-regulations-and-policy-updates-us-eu-asia) HTTP/1.1" 307 None
2026-01-08 10:24:12,002 - urllib3.connectionpool - DEBUG - https://www.index.dev:443 "GET /blog HTTP/1.1" 200 None
2026-01-08 10:24:12,005 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): unctad.org:443
2026-01-08 10:24:13,479 - urllib3.connectionpool - DEBUG - https://unctad.org:443 "GET /news/ai-market-projected-hit-48-trillion-2033-emerging-dominant-frontier-technology) HTTP/1.1" 404 None
2026-01-08 10:24:13,481 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ff.co:443
2026-01-08 10:24:14,067 - urllib3.connectionpool - DEBUG - https://ff.co:443 "GET /ai-statistics-trends-global-market/) HTTP/1.1" 301 None
2026-01-08 10:24:14,216 - urllib3.connectionpool - DEBUG - https://ff.co:443 "GET /ai-statistics-trends-global-market/ HTTP/1.1" 200 None
2026-01-08 10:24:14,216 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): artificialintelligenceact.eu:443
2026-01-08 10:24:15,520 - urllib3.connectionpool - DEBUG - https://artificialintelligenceact.eu:443 "GET /) HTTP/1.1" 301 None
2026-01-08 10:24:15,830 - urllib3.connectionpool - DEBUG - https://artificialintelligenceact.eu:443 "GET / HTTP/1.1" 200 None
2026-01-08 10:24:15,831 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): news.crunchbase.com:443
2026-01-08 10:24:16,711 - urllib3.connectionpool - DEBUG - https://news.crunchbase.com:443 "GET /venture/state-of-startups-q2-h1-2025-ai-ma-charts-data/) HTTP/1.1" 301 None
2026-01-08 10:24:17,034 - urllib3.connectionpool - DEBUG - https://news.crunchbase.com:443 "GET /venture/state-of-startups-q2-h1-2025-ai-ma-charts-data/ HTTP/1.1" 200 None
2026-01-08 10:24:17,036 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.kdnuggets.com:443
2026-01-08 10:24:17,568 - urllib3.connectionpool - DEBUG - https://www.kdnuggets.com:443 "GET /the-10-ai-developments-that-defined-2025) HTTP/1.1" 429 1168
2026-01-08 10:24:17,570 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): eu.36kr.com:443
2026-01-08 10:24:18,836 - urllib3.connectionpool - DEBUG - https://eu.36kr.com:443 "GET /en/p/3617661153260292) HTTP/1.1" 200 None
2026-01-08 10:24:18,839 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zdnet.com:443
2026-01-08 10:24:19,731 - urllib3.connectionpool - DEBUG - https://www.zdnet.com:443 "GET /article/ai-in-2023-a-year-of-breakthroughs-that-left-no-human-thing-unchanged/) HTTP/1.1" 301 162
2026-01-08 10:24:20,620 - urllib3.connectionpool - DEBUG - https://www.zdnet.com:443 "GET /article/ai-in-2023-a-year-of-breakthroughs-that-left-no-human-thing-unchanged/)/ HTTP/1.1" 404 86392
2026-01-08 10:24:20,622 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): aimagazine.com:443
2026-01-08 10:24:20,845 - urllib3.connectionpool - DEBUG - https://aimagazine.com:443 "GET /top10/top-10-innovations-of-2023) HTTP/1.1" 403 None
2026-01-08 10:24:20,849 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.precedenceresearch.com:443
2026-01-08 10:24:21,699 - urllib3.connectionpool - DEBUG - https://www.precedenceresearch.com:443 "GET /artificial-intelligence-market) HTTP/1.1" 302 262
2026-01-08 10:24:22,059 - urllib3.connectionpool - DEBUG - https://www.precedenceresearch.com:443 "GET /404 HTTP/1.1" 200 None
2026-01-08 10:24:22,063 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): aloa.co:443
2026-01-08 10:24:22,979 - urllib3.connectionpool - DEBUG - https://aloa.co:443 "GET /ai/resources/industry-insights/top-ai-trends) HTTP/1.1" 200 None
2026-01-08 10:24:22,980 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): time.com:443
2026-01-08 10:24:23,381 - urllib3.connectionpool - DEBUG - https://time.com:443 "GET /6547982/3-big-ai-innovations-from-2023/) HTTP/1.1" 301 0
2026-01-08 10:24:23,383 - urllib3.connectionpool - DEBUG - Resetting dropped connection: time.com
2026-01-08 10:24:23,889 - urllib3.connectionpool - DEBUG - https://time.com:443 "GET /6547982/3-big-ai-innovations-from-2023/)/ HTTP/1.1" 406 None
2026-01-08 10:28:58,492 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:28:58,492 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:28:58,493 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:28:58,493 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:28:58,603 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:28:58,603 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:28:58,603 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:28:58,603 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:03,343 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:03,343 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:03,343 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:03,343 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:03,345 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:03,345 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:03,345 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:03,346 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:06,614 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:06,614 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:06,614 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:06,614 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:06,616 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:06,616 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:06,616 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:06,616 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:16,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:16,034 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:16,034 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:16,034 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:16,035 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:16,036 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:16,036 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:16,036 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:16,089 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 10:29:16,479 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 10:29:16,479 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:29:16,481 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:29:16,503 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF467AE050>
2026-01-08 10:29:16,503 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF2C9C5520> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:29:16,596 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF467AE010>
2026-01-08 10:29:16,597 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:29:16,597 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:29:16,597 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:29:16,597 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:29:16,597 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:29:17,471 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:29:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=851'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:29:17,472 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:29:17,472 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:29:17,472 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:29:17,472 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:29:17,473 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:29:17,473 - processor - ERROR - Error in batch analysis: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:29:17,473 - processor - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:29:17,477 - __main__ - INFO - Report structure analysis finalized
2026-01-08 10:29:17,540 - httpcore.connection - DEBUG - close.started
2026-01-08 10:29:17,541 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:29:17,547 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:17,547 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:17,549 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:17,549 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:17,550 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:17,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:17,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:17,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,722 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,722 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,722 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,722 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,723 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,723 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,723 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,723 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,786 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,786 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,786 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,786 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,787 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,787 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,787 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:29:31,787 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:29:31,789 - researcher - INFO - Researching 'Analysis failed.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:29:32,170 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:29:32,170 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:29:32,186 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF46877150>
2026-01-08 10:29:32,186 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF2C9C45F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:29:32,252 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF46876CD0>
2026-01-08 10:29:32,252 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:29:32,252 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:29:32,252 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:29:32,252 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:29:32,252 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:29:57,464 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:29:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=25197'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:29:57,466 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:29:57,466 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:29:57,466 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:29:57,466 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:29:57,466 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:29:57,466 - researcher - INFO - Searching OpenAlex for: Analysis failed.
2026-01-08 10:29:57,469 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:29:58,935 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Analysis%20failed.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:29:59,744 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:29:59,745 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:29:59,756 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF46941E50>
2026-01-08 10:29:59,757 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF468B4DD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:29:59,818 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF46941E10>
2026-01-08 10:29:59,818 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:29:59,820 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:29:59,820 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:29:59,820 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:29:59,820 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:30:05,377 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:30:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5543'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:30:05,377 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:30:05,377 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:30:05,379 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:30:05,379 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:30:05,379 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:30:05,379 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:30:05,380 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:30:05,380 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:30:05,380 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:30:05,381 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:30:05,381 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:30:11,752 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:30:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6360'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:30:11,753 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:30:11,753 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:30:11,753 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:30:11,753 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:30:11,753 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:30:11,754 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:30:11,754 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:30:11,754 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:30:11,754 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:30:11,755 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:30:11,755 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:30:16,193 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:30:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4415'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:30:16,194 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:30:16,195 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:30:16,195 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:30:16,195 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:30:16,195 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:30:16,195 - researcher - ERROR - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:30:18,196 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:30:18,654 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:30:18,654 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:30:18,654 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:30:18,666 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4694DF50>
2026-01-08 10:30:18,666 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF468B51C0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:30:18,731 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4694DF10>
2026-01-08 10:30:18,731 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:30:18,731 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:30:18,734 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:30:18,734 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:30:18,734 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:30:25,435 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:30:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6692'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:30:25,435 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:30:25,435 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:30:25,435 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:30:25,435 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:30:25,435 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:30:25,436 - updater - INFO - Chapter update successful
2026-01-08 10:30:25,436 - httpcore.connection - DEBUG - close.started
2026-01-08 10:30:25,436 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:30:27,438 - researcher - INFO - Researching 'Analysis failed.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:30:27,790 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:30:27,791 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:30:27,802 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4695C0D0>
2026-01-08 10:30:27,802 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF466CBF50> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:30:27,866 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4694FF90>
2026-01-08 10:30:27,866 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:30:27,866 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:30:27,866 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:30:27,867 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:30:27,867 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:30:50,305 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:30:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=22422'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:30:50,305 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:30:50,305 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:30:50,338 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:30:50,338 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:30:50,339 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:30:50,339 - researcher - INFO - Searching OpenAlex for: Analysis failed.
2026-01-08 10:30:50,341 - httpcore.connection - DEBUG - close.started
2026-01-08 10:30:50,341 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:30:50,343 - httpcore.connection - DEBUG - close.started
2026-01-08 10:30:50,343 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:30:50,346 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:30:51,779 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Analysis%20failed.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:30:52,543 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:30:52,545 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:30:52,558 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4691C410>
2026-01-08 10:30:52,559 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF468B4710> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:30:52,621 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4691C3D0>
2026-01-08 10:30:52,621 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:30:52,621 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:30:52,621 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:30:52,621 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:30:52,621 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:30:56,887 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:30:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4257'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:30:56,887 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:30:56,887 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:30:56,887 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:30:56,887 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:30:56,887 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:30:56,887 - researcher - ERROR - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:30:58,892 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:30:59,237 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:30:59,237 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:30:59,237 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:30:59,249 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF46933F90>
2026-01-08 10:30:59,249 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF2C9C7F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:30:59,317 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4691D090>
2026-01-08 10:30:59,317 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:30:59,317 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:30:59,317 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:30:59,317 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:30:59,317 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:31:00,200 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:31:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=871'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:31:00,202 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:31:00,202 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:31:00,202 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:31:00,202 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:31:00,202 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:31:00,203 - updater - ERROR - Failed to update chapter: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:31:00,203 - updater - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:31:02,205 - researcher - INFO - Researching 'Analysis failed.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 10:31:02,632 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:31:02,634 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:31:02,645 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF46930890>
2026-01-08 10:31:02,645 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF2E151F40> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:31:02,711 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF469308D0>
2026-01-08 10:31:02,713 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:31:02,713 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:31:02,713 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:31:02,713 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:31:02,713 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:31:06,718 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:31:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3993'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:31:06,718 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:31:06,718 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:31:06,720 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:31:06,720 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:31:06,720 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:31:06,720 - researcher - INFO - Searching OpenAlex for: Analysis failed.
2026-01-08 10:31:06,720 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 10:31:07,600 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Analysis%20failed.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 10:31:07,602 - httpcore.connection - DEBUG - close.started
2026-01-08 10:31:07,602 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:31:07,603 - httpcore.connection - DEBUG - close.started
2026-01-08 10:31:07,603 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:31:07,605 - httpcore.connection - DEBUG - close.started
2026-01-08 10:31:07,605 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:31:08,353 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:31:08,354 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:31:08,389 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4695CA50>
2026-01-08 10:31:08,389 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF468B51C0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:31:08,452 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF4691B1D0>
2026-01-08 10:31:08,452 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:31:08,452 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:31:08,453 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:31:08,453 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:31:08,453 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:31:13,364 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:31:14 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4899'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:31:13,365 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 10:31:13,365 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:31:13,366 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:31:13,366 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:31:13,366 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:31:13,366 - researcher - ERROR - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 10:31:15,367 - updater - INFO - Updating chapter content with research findings
2026-01-08 10:31:15,716 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 10:31:15,716 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 10:31:15,717 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 10:31:15,728 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF468A4D50>
2026-01-08 10:31:15,728 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AF468B4170> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 10:31:15,796 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AF468A4D10>
2026-01-08 10:31:15,796 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 10:31:15,796 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 10:31:15,797 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 10:31:15,797 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 10:31:15,797 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 10:31:21,845 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 08:31:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6033'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 10:31:21,846 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 10:31:21,846 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 10:31:21,846 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 10:31:21,846 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 10:31:21,846 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 10:31:21,847 - updater - INFO - Chapter update successful
2026-01-08 10:31:21,847 - httpcore.connection - DEBUG - close.started
2026-01-08 10:31:21,847 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:31:21,882 - httpcore.connection - DEBUG - close.started
2026-01-08 10:31:21,882 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:31:21,882 - httpcore.connection - DEBUG - close.started
2026-01-08 10:31:21,882 - httpcore.connection - DEBUG - close.complete
2026-01-08 10:31:21,889 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:31:21,890 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:31:21,890 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:31:21,890 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:31:21,891 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:31:21,891 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:31:21,891 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 10:31:21,891 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 10:31:21,900 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-08 10:31:22,285 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.2307/1164923 HTTP/1.1" 302 None
2026-01-08 10:31:22,286 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.jstor.org:443
2026-01-08 10:31:22,689 - urllib3.connectionpool - DEBUG - https://www.jstor.org:443 "GET /stable/1164923?origin=crossref HTTP/1.1" 403 5814
2026-01-08 10:31:22,691 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-08 10:31:23,036 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.1073/pnas.012283399 HTTP/1.1" 302 None
2026-01-08 10:31:23,037 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): pnas.org:443
2026-01-08 10:31:23,252 - urllib3.connectionpool - DEBUG - https://pnas.org:443 "GET /doi/full/10.1073/pnas.012283399 HTTP/1.1" 403 None
2026-01-08 13:02:57,401 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:02:57,402 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:02:57,402 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:02:57,402 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:02:57,597 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:02:57,597 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:02:57,597 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:02:57,597 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:02,186 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:02,186 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:02,186 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:02,186 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:02,187 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:02,187 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:02,187 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:02,188 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:05,315 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:05,315 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:05,315 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:05,315 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:05,317 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:05,317 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:05,318 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:05,318 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:05,373 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 13:03:06,077 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 13:03:06,080 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 13:03:06,083 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 13:03:06,105 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DDF7963410>
2026-01-08 13:03:06,105 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DDF777CF80> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 13:03:06,171 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DDF79633D0>
2026-01-08 13:03:06,173 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 13:03:06,173 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 13:03:06,174 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 13:03:06,174 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 13:03:06,174 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 13:03:10,047 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 11:03:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3865'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 13:03:10,047 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 13:03:10,047 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 13:03:10,047 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 13:03:10,047 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 13:03:10,047 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 13:03:10,052 - processor - INFO - Batch analysis successful
2026-01-08 13:03:10,052 - httpcore.connection - DEBUG - close.started
2026-01-08 13:03:10,052 - httpcore.connection - DEBUG - close.complete
2026-01-08 13:03:10,052 - __main__ - INFO - Report structure analysis finalized
2026-01-08 13:03:10,110 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:10,110 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:10,112 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:10,112 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:10,113 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:10,113 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:10,113 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:10,113 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,667 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,667 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,667 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,667 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,668 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,669 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,669 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,669 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,734 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,734 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,734 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,734 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,736 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,736 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:18,736 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:18,736 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,898 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,899 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,899 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,899 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,900 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,900 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,900 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,901 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,968 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,968 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,968 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,969 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,970 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,970 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,970 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:23,971 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:23,973 - researcher - INFO - Researching 'This chapter introduces the recent surge in Artificial Intelligence's popularity, largely attributed to ChatGPT's release in late 2022. It sets the scope of the report, indicating that it will summarize the state of the industry. The report's information is current as of mid-2023.' via sources: ['Web Search']
2026-01-08 13:03:23,973 - researcher - INFO - Searching DuckDuckGo for: This chapter introduces the recent surge in Artificial Intelligence's popularity, largely attributed to ChatGPT's release in late 2022. It sets the scope of the report, indicating that it will summarize the state of the industry. The report's information is current as of mid-2023. (since mid-2023)
2026-01-08 13:03:23,980 - primp.utils - DEBUG - Loaded CA certs
2026-01-08 13:03:23,982 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-08 13:03:23,982 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-08 13:03:23,997 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.155:443
2026-01-08 13:03:24,006 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.155:443
2026-01-08 13:03:24,025 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 13:03:24,251 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-08 13:03:24,251 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=30F6B3A946B16F953401A57247046EB5; expires=Tue, 02-Feb-2027 11:03:26 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 11:03:26.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:24,251 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=1FFB8BDC8A4267101D2A9D078BF7662F; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Tue, 02-Feb-2027 11:03:26 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-02 11:03:26.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHD'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUID'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting secure cookie '_SS'
2026-01-08 13:03:24,252 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=3CC418AED16282020229C2585027BE56~000000000000000000000000000000~YAAQp5hmUjiowIibAQAA2ZFGnR7AWlYvLe9yBV9xcDFugA36rScuxrX/nhdZ+jUp5guoEp2RzBwrEOLL6s/seQQSue8w9ffHd65jhEPdmf053OMmXSvG7wD+zXaqEir3wHOhmDt1EtmiNV2lSdIy7CAmqfBk5SPugQPjISN0t5kAGO0RFlB/KiuE9MmUsMGNn4TXCHnOuInOj65o7li9UtKZUkai51z0BHJNFyeig34kVIp2DROetFz5K2yxtihacnMo+XVycA9C8ao0kdZP2hM67UGXFA206nmMdhymVOvhM46zcOZrutbUMU6O9xOzcizVVertO7eE6zcZPetEWzG1sLxeXHvMCU5Z7bws/TYmJbxA6VdyYctrlJOn/mCCifNwhrMOIe95; Domain=.bing.com; Path=/; Expires=Thu, 08 Jan 2026 13:03:26 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 468), expires: Some(DateTime(2026-01-08 13:03:26.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(477, 486)), path: Some(Indexed(493, 494)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:24,252 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+introduces+the+recent+surge+in+Artificial+Intelligence%27s+popularity%2C+largely+attributed+to+ChatGPT%27s+release+in+late+2022.+It+sets+the+scope+of+the+report%2C+indicating+that+it+will+summarize+the+state+of+the+industry.+The+report%27s+information+is+current+as+of+mid-2023.+since+mid-2023 200
2026-01-08 13:03:24,253 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+introduces+the+recent+surge+in+Artificial+Intelligence%27s+popularity%2C+largely+attributed+to+ChatGPT%27s+release+in+late+2022.+It+sets+the+scope+of+the+report%2C+indicating+that+it+will+summarize+the+state+of+the+industry.+The+report%27s+information+is+current+as+of+mid-2023.+since+mid-2023 200
2026-01-08 13:03:26,326 - updater - INFO - Updating chapter content with research findings
2026-01-08 13:03:26,730 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 13:03:26,730 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 13:03:26,730 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 13:03:26,743 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DDF7977650>
2026-01-08 13:03:26,743 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DDF78E2720> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 13:03:26,808 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DDF79E5B90>
2026-01-08 13:03:26,809 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 13:03:26,809 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 13:03:26,809 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 13:03:26,809 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 13:03:26,809 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 13:03:26,916 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 11:03:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=84'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 13:03:26,916 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 403 Forbidden"
2026-01-08 13:03:26,917 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 13:03:26,917 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 13:03:26,917 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 13:03:26,917 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 13:03:26,917 - updater - ERROR - Failed to update chapter: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 13:03:26,918 - updater - ERROR - 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 13:03:29,006 - researcher - INFO - Researching 'This chapter discusses the landscape of Large Language Models (LLMs), highlighting GPT-4 as the current state-of-the-art as of early 2023. It also mentions other significant models from Google (Bard) and Meta (Llama 1), which is intended for research. The chapter notes that the industry's focus is on increasing model scale and parameter counts.' via sources: ['Web Search']
2026-01-08 13:03:29,006 - researcher - INFO - Searching DuckDuckGo for: This chapter discusses the landscape of Large Language Models (LLMs), highlighting GPT-4 as the current state-of-the-art as of early 2023. It also mentions other significant models from Google (Bard) and Meta (Llama 1), which is intended for research. The chapter notes that the industry's focus is on increasing model scale and parameter counts. (since early 2023)
2026-01-08 13:03:29,006 - primp.utils - DEBUG - Loaded CA certs
2026-01-08 13:03:29,007 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-08 13:03:29,007 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-08 13:03:29,008 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.155:443
2026-01-08 13:03:29,018 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.155:443
2026-01-08 13:03:29,043 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 13:03:29,248 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-08 13:03:29,248 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=1FAC26E494F162C32C32303F95B8634F; expires=Tue, 02-Feb-2027 11:03:31 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 11:03:31.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:29,248 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=105F9CEE60846A92333F8A3561CD6B0A; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:29,248 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Tue, 02-Feb-2027 11:03:31 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-02 11:03:31.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:29,248 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sat, 08-Jan-2028 11:03:31 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-08 11:03:31.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:03:29,249 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=9D8BEE4BE4154D7EB2BAE69747773B2B&dmnchg=1; domain=.bing.com; expires=Sat, 08-Jan-2028 11:03:31 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-08 11:03:31.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:03:29,249 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260108; domain=.bing.com; expires=Sat, 08-Jan-2028 11:03:31 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-08 11:03:31.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:03:29,249 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=A30CBB945A9B4D269355F41373EF458D; domain=.bing.com; expires=Sat, 08-Jan-2028 11:03:31 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 11:03:31.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:03:29,249 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=105F9CEE60846A92333F8A3561CD6B0A; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:03:29,249 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=AB21F42EBEAB8C26014902FAAFFE1FE7~000000000000000000000000000000~YAAQlphmUuDJKiybAQAAdKVGnR51h//ffdvlU+DyMOA6fuZHxgkBIgt+eUwLWtDbXxsNnzTCW4aC6/MgEQhkAM9Uuk4sIWIGyX7+QlHlqqoTRzARW5Y+SRzGdUHMMQ7D+HlQG1li3NSqIaG1OzqEfx0iSm/voR+dgjMnAGUU41JsLr3Ij0FNJl6Ky8o44mHsvE16O8D23lKcU/1ycQ3yYV8W7DJwe91EwlvoL7+5affvTP415S1jg8NK3s8PA0JKZakccVEnPIlmQAuOGQt6TUCwXw/eFAAxsSrZT2QzzZdELFr7Uxs1pP+alu9x+W6QJU2v2s4myLB3AKIJyEY+lwP0nYFUwz7r50Aj80fRmV2i5tVKI4+2kxHzdA65qsE53Ngo5q/xgWY=; Domain=.bing.com; Path=/; Expires=Thu, 08 Jan 2026 13:03:31 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 468), expires: Some(DateTime(2026-01-08 13:03:31.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(477, 486)), path: Some(Indexed(493, 494)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:03:29,249 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+discusses+the+landscape+of+Large+Language+Models+%28LLMs%29%2C+highlighting+GPT-4+as+the+current+state-of-the-art+as+of+early+2023.+It+also+mentions+other+significant+models+from+Google+%28Bard%29+and+Meta+%28Llama+1%29%2C+which+is+intended+for+research.+The+chapter+notes+that+the+industry%27s+focus+is+on+increasing+model+scale+and+parameter+counts.+since+early+2023 200
2026-01-08 13:03:29,249 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+discusses+the+landscape+of+Large+Language+Models+%28LLMs%29%2C+highlighting+GPT-4+as+the+current+state-of-the-art+as+of+early+2023.+It+also+mentions+other+significant+models+from+Google+%28Bard%29+and+Meta+%28Llama+1%29%2C+which+is+intended+for+research.+The+chapter+notes+that+the+industry%27s+focus+is+on+increasing+model+scale+and+parameter+counts.+since+early+2023 200
2026-01-08 13:03:31,577 - updater - INFO - Updating chapter content with research findings
2026-01-08 13:03:31,969 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 13:03:31,969 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 13:03:31,969 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 13:03:31,986 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DDF7A63190>
2026-01-08 13:03:31,986 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001DDF7A31D90> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 13:03:32,051 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001DDF7A63150>
2026-01-08 13:03:32,051 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 13:03:32,052 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 13:03:32,052 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 13:03:32,052 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 13:03:32,052 - httpcore.connection - DEBUG - close.started
2026-01-08 13:03:32,053 - httpcore.connection - DEBUG - close.complete
2026-01-08 13:03:32,052 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 13:03:32,143 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 403, b'Forbidden', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 11:03:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=80'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 13:03:32,143 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 403 Forbidden"
2026-01-08 13:03:32,143 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 13:03:32,144 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 13:03:32,144 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 13:03:32,144 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 13:03:32,144 - updater - ERROR - Failed to update chapter: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 13:03:32,144 - updater - ERROR - 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 13:03:32,196 - httpcore.connection - DEBUG - close.started
2026-01-08 13:03:32,196 - httpcore.connection - DEBUG - close.complete
2026-01-08 13:03:32,227 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:32,227 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:32,227 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:32,227 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:32,228 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:32,228 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:32,230 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:32,230 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:32,242 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:32,695 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/246804/centering-chapter-titles) HTTP/1.1" 200 None
2026-01-08 13:03:32,697 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:33,140 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/604927/how-to-use-chapter-in-article-class) HTTP/1.1" 200 None
2026-01-08 13:03:33,144 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:33,556 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/62516/how-to-suppress-chapter-in-chapter-while-keeping-numbering) HTTP/1.1" 200 None
2026-01-08 13:03:33,558 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:33,961 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/745949/how-to-reference-appendix-tables-in-latex-with-chapter-based-numbering-e-g-ta) HTTP/1.1" 200 None
2026-01-08 13:03:33,964 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:34,380 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/741432/scrreprt-how-to-add-chapter-and-section-in-header-when-sections-appear-otherw) HTTP/1.1" 200 None
2026-01-08 13:03:34,383 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:34,782 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/734572/different-chapter-formatting) HTTP/1.1" 200 None
2026-01-08 13:03:34,785 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:35,226 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/89914/chapter-name-in-the-header-with-chapter) HTTP/1.1" 200 None
2026-01-08 13:03:35,228 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-08 13:03:35,676 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/585916/use-arabic-chapter-label-for-figure-and-table-if-chapter-use-numberstringchap) HTTP/1.1" 200 None
2026-01-08 13:03:39,375 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,375 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,375 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,375 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,377 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,377 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,377 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,377 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,436 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,436 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,436 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,436 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,437 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,437 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:03:39,437 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:03:39,438 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:04:57,010 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:04:57,010 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:04:57,010 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:04:57,010 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:04:57,159 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:04:57,159 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:04:57,159 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:04:57,159 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:02,925 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:02,925 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:02,926 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:02,926 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:02,927 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:02,928 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:02,928 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:02,928 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:04,029 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:04,030 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:04,030 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:04,030 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:17,321 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:17,321 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:17,321 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:17,323 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:17,324 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:17,324 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:17,324 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:17,324 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:18,864 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:18,864 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:18,864 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:18,864 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:18,866 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:18,866 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:18,866 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:18,867 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:18,922 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 13:05:19,353 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 13:05:19,355 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 13:05:19,356 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 13:05:19,395 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025D2A377190>
2026-01-08 13:05:19,395 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025D104FBA40> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 13:05:19,458 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025D2A377150>
2026-01-08 13:05:19,460 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 13:05:19,460 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 13:05:19,460 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 13:05:19,461 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 13:05:19,461 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 13:05:20,000 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 11:05:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=531'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 13:05:20,001 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 13:05:20,001 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 13:05:20,001 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 13:05:20,001 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 13:05:20,002 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 13:05:20,002 - processor - ERROR - Error in batch analysis: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 13:05:20,002 - processor - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 13:05:20,006 - __main__ - INFO - Report structure analysis finalized
2026-01-08 13:05:20,059 - httpcore.connection - DEBUG - close.started
2026-01-08 13:05:20,060 - httpcore.connection - DEBUG - close.complete
2026-01-08 13:05:20,065 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:20,065 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:20,065 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:20,065 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:20,066 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:20,067 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:05:20,067 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:05:20,067 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:24,108 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:24,108 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:24,110 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:24,110 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:24,264 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:24,264 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:24,264 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:24,264 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:59,561 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:59,561 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:59,562 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:59,562 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:59,563 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:59,563 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:11:59,563 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:11:59,563 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:04,123 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:04,123 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:04,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:04,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:04,125 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:04,125 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:04,125 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:04,125 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:07,658 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:07,658 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:07,658 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:07,659 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:07,660 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:07,660 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:07,661 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:07,661 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:09,086 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:09,087 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:09,087 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:09,087 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:09,088 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:09,088 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:09,088 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:09,088 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:09,142 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 13:12:09,593 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 13:12:09,594 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 13:12:09,595 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 13:12:09,618 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E4DB263650>
2026-01-08 13:12:09,618 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E4DB07CC20> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 13:12:09,682 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E4DB1B19D0>
2026-01-08 13:12:09,682 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 13:12:09,683 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 13:12:09,683 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 13:12:09,683 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 13:12:09,683 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 13:12:13,535 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 11:12:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3828'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 13:12:13,536 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 13:12:13,536 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 13:12:13,537 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 13:12:13,537 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 13:12:13,537 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 13:12:13,537 - processor - INFO - Batch analysis successful
2026-01-08 13:12:13,537 - httpcore.connection - DEBUG - close.started
2026-01-08 13:12:13,538 - httpcore.connection - DEBUG - close.complete
2026-01-08 13:12:13,538 - __main__ - INFO - Report structure analysis finalized
2026-01-08 13:12:13,590 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:13,590 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:13,591 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:13,591 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:13,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:13,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:13,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:13,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:19,963 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:19,963 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:19,963 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:19,963 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:19,964 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:19,964 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:19,965 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:19,965 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:20,016 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:20,016 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:20,018 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:20,018 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:20,019 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:20,019 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:20,019 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:20,019 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,244 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,244 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,244 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,244 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,245 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,245 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,245 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,245 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,298 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,298 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,298 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,298 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,299 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,299 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:23,300 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:23,300 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,580 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,580 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,580 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,580 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,581 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,581 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,581 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,581 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,633 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,633 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,633 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,633 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,634 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,634 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,634 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:25,634 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:25,637 - researcher - INFO - Researching 'As of early 2023, GPT-4 is considered the state-of-the-art model in the Large Language Models industry. Other significant players, such as Google, have introduced models like Bard, and Meta has released Llama 1 for research. The current industry focus is heavily on increasing scale and parameter counts in these models, indicating a trend towards larger and more complex systems.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 13:12:25,637 - researcher - INFO - Searching DuckDuckGo for: As of early 2023, GPT-4 is considered the state-of-the-art model in the Large Language Models industry. Other significant players, such as Google, have introduced models like Bard, and Meta has released Llama 1 for research. The current industry focus is heavily on increasing scale and parameter counts in these models, indicating a trend towards larger and more complex systems. (since early 2023)
2026-01-08 13:12:25,643 - primp.utils - DEBUG - Loaded CA certs
2026-01-08 13:12:25,644 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-08 13:12:25,644 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-08 13:12:25,658 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.178:443
2026-01-08 13:12:25,679 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.178:443
2026-01-08 13:12:25,693 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 13:12:25,850 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-08 13:12:25,850 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=37959E6B59DF698631B288B058AD6808; expires=Tue, 02-Feb-2027 11:12:27 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 11:12:27.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:12:25,850 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=05E00583ACF1649023031358AD8365FC; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:12:25,850 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Tue, 02-Feb-2027 11:12:27 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-02 11:12:27.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:12:25,850 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sat, 08-Jan-2028 11:12:28 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-08 11:12:28.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:12:25,852 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=991198ADC4824C4490A725EA5F4A9E80&dmnchg=1; domain=.bing.com; expires=Sat, 08-Jan-2028 11:12:28 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-08 11:12:28.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:12:25,852 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260108; domain=.bing.com; expires=Sat, 08-Jan-2028 11:12:28 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-08 11:12:28.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:12:25,852 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=5D7AFFFD76904513BA3D98B583B9022E; domain=.bing.com; expires=Sat, 08-Jan-2028 11:12:28 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 11:12:28.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:12:25,852 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=05E00583ACF1649023031358AD8365FC; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 13:12:25,852 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=AA91A9C74E60E092E46FB774F029CADE~000000000000000000000000000000~YAAQnJhmUn+qCi6bAQAAtdVOnR4fhIrHBcZtfBxX1M0hGGPwPUB4FP37xuQgPhzBiPyZwiNJRTZdioUSo3KMp4bAzel4D2TudJVPS6lpvOe3DuxUmzkOEJqxAfp/uOVEKqCTo5F7+3rO77JYDT2KYMWraaLSg/ACLX6OV9tq6nC+qbVe4wSMl9ir5BC8fXV8aEix/VqkWg5nT2rG/T/1CsDR8YS0B3iGj3AEdlUEx40jFw7SaAQ1tXL6JeoXmQDx3bgsw0YsuqiVeU1DCDkhe/xLFP1qpqNEZs0SyVvAlMLj5uGtQB/hsCegb39lNJrpCrT6PRbdJv28nfxIOEksJwCFdFj0X6vLRApQZ/rL0a4zH0wnteftWkjzBPZ03tzuKngJZA9u46ml; Domain=.bing.com; Path=/; Expires=Thu, 08 Jan 2026 13:12:27 GMT; Max-Age=7199; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 468), expires: Some(DateTime(2026-01-08 13:12:27.0 +00:00:00)), max_age: Some(Duration { seconds: 7199, nanoseconds: 0 }), domain: Some(Indexed(477, 486)), path: Some(Indexed(493, 494)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 13:12:25,852 - primp - INFO - response: https://www.bing.com/search?q=As+of+early+2023%2C+GPT-4+is+considered+the+state-of-the-art+model+in+the+Large+Language+Models+industry.+Other+significant+players%2C+such+as+Google%2C+have+introduced+models+like+Bard%2C+and+Meta+has+released+Llama+1+for+research.+The+current+industry+focus+is+heavily+on+increasing+scale+and+parameter+counts+in+these+models%2C+indicating+a+trend+towards+larger+and+more+complex+systems.+since+early+2023 200
2026-01-08 13:12:25,852 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=As+of+early+2023%2C+GPT-4+is+considered+the+state-of-the-art+model+in+the+Large+Language+Models+industry.+Other+significant+players%2C+such+as+Google%2C+have+introduced+models+like+Bard%2C+and+Meta+has+released+Llama+1+for+research.+The+current+industry+focus+is+heavily+on+increasing+scale+and+parameter+counts+in+these+models%2C+indicating+a+trend+towards+larger+and+more+complex+systems.+since+early+2023 200
2026-01-08 13:12:25,979 - researcher - INFO - Searching OpenAlex for: As of early 2023, GPT-4 is considered the state-of-the-art model in the Large Language Models industry. Other significant players, such as Google, have introduced models like Bard, and Meta has released Llama 1 for research. The current industry focus is heavily on increasing scale and parameter counts in these models, indicating a trend towards larger and more complex systems.
2026-01-08 13:12:25,982 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 13:12:27,390 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=As%20of%20early%202023,%20GPT-4%20is%20considered%20the%20state-of-the-art%20model%20in%20the%20Large%20Language%20Models%20industry.%20Other%20significant%20players,%20such%20as%20Google,%20have%20introduced%20models%20like%20Bard,%20and%20Meta%20has%20released%20Llama%201%20for%20research.%20The%20current%20industry%20focus%20is%20heavily%20on%20increasing%20scale%20and%20parameter%20counts%20in%20these%20models,%20indicating%20a%20trend%20towards%20larger%20and%20more%20complex%20systems.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 13:12:29,396 - updater - INFO - Updating chapter content with research findings
2026-01-08 13:12:29,755 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 13:12:29,755 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 13:12:29,757 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 13:12:29,768 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E4DB283690>
2026-01-08 13:12:29,768 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E4DB1DA7B0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 13:12:29,829 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E4DB282990>
2026-01-08 13:12:29,829 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 13:12:29,829 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 13:12:29,830 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 13:12:29,830 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 13:12:29,830 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 13:12:44,971 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 11:12:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=15133'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 13:12:44,971 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 13:12:44,972 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 13:12:44,972 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 13:12:44,972 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 13:12:44,972 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 13:12:44,973 - updater - INFO - Chapter update successful
2026-01-08 13:12:44,973 - httpcore.connection - DEBUG - close.started
2026-01-08 13:12:44,973 - httpcore.connection - DEBUG - close.complete
2026-01-08 13:12:45,037 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:45,037 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:45,037 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:45,038 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:45,038 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:45,038 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:45,040 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 13:12:45,040 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 13:12:45,050 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bwl-lexikon.de:443
2026-01-08 13:12:45,579 - urllib3.connectionpool - DEBUG - https://www.bwl-lexikon.de:443 "GET /wiki/churn-rate/ HTTP/1.1" 200 None
2026-01-08 13:12:45,580 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): praxistipps.focus.de:443
2026-01-08 13:12:46,337 - urllib3.connectionpool - DEBUG - https://praxistipps.focus.de:443 "GET /churn-rate-bedeutung-ursachen-und-was-hilft_188092) HTTP/1.1" 404 53925
2026-01-08 13:12:46,340 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.bwl-lexikon.de:443
2026-01-08 13:12:47,049 - urllib3.connectionpool - DEBUG - https://www.bwl-lexikon.de:443 "GET /wiki/churn-rate/) HTTP/1.1" 404 None
2026-01-08 13:12:47,052 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.datamart.de:443
2026-01-08 13:12:48,437 - urllib3.connectionpool - DEBUG - https://www.datamart.de:443 "GET /churn-management/) HTTP/1.1" 301 0
2026-01-08 13:12:50,015 - urllib3.connectionpool - DEBUG - https://www.datamart.de:443 "GET /churn-management/ HTTP/1.1" 200 None
2026-01-08 13:12:50,018 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.hubspot.de:443
2026-01-08 13:12:51,523 - urllib3.connectionpool - DEBUG - https://blog.hubspot.de:443 "GET /service/churn-rate HTTP/1.1" 200 None
2026-01-08 13:12:51,526 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): de.wikipedia.org:443
2026-01-08 13:12:51,934 - urllib3.connectionpool - DEBUG - https://de.wikipedia.org:443 "GET /wiki/Churn_Management HTTP/1.1" 403 2068
2026-01-08 13:12:51,936 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.riddle.com:443
2026-01-08 13:12:53,167 - urllib3.connectionpool - DEBUG - https://www.riddle.com:443 "GET /blog/de/use-cases/engagement/was-ist-churn-management-definition-ursachen-und-massnahmen/ HTTP/1.1" 200 28565
2026-01-08 13:12:53,170 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.one.com:443
2026-01-08 13:12:53,653 - urllib3.connectionpool - DEBUG - https://www.one.com:443 "GET /de-de/webshop/was-ist-churn/) HTTP/1.1" 308 31
2026-01-08 13:12:53,850 - urllib3.connectionpool - DEBUG - https://www.one.com:443 "GET /de-de/webshop/was-ist-churn/)/ HTTP/1.1" 404 None
2026-01-08 13:12:53,853 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.riddle.com:443
2026-01-08 13:12:54,609 - urllib3.connectionpool - DEBUG - https://www.riddle.com:443 "GET /blog/de/use-cases/engagement/was-ist-churn-management-definition-ursachen-und-massnahmen/) HTTP/1.1" 301 0
2026-01-08 13:12:54,802 - urllib3.connectionpool - DEBUG - https://www.riddle.com:443 "GET /blog/de/use-cases/engagement/was-ist-churn-management-definition-ursachen-und-massnahmen/ HTTP/1.1" 200 28565
2026-01-08 13:12:54,805 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.datamart.de:443
2026-01-08 13:12:55,227 - urllib3.connectionpool - DEBUG - https://www.datamart.de:443 "GET /churn-management/ HTTP/1.1" 200 None
2026-01-08 13:12:55,233 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): blog.hubspot.de:443
2026-01-08 13:12:57,846 - urllib3.connectionpool - DEBUG - https://blog.hubspot.de:443 "GET /service/churn-rate) HTTP/1.1" 404 None
2026-01-08 13:12:57,848 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.signo-media.de:443
2026-01-08 13:13:00,334 - urllib3.connectionpool - DEBUG - https://www.signo-media.de:443 "GET /wissensdatenbank/churn-rate/) HTTP/1.1" 301 None
2026-01-08 13:13:00,495 - urllib3.connectionpool - DEBUG - https://www.signo-media.de:443 "GET /wissensdatenbank/churn-rate/ HTTP/1.1" 200 None
2026-01-08 13:13:00,501 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): praxistipps.focus.de:443
2026-01-08 13:13:00,936 - urllib3.connectionpool - DEBUG - https://praxistipps.focus.de:443 "GET /churn-rate-bedeutung-ursachen-und-was-hilft_188092 HTTP/1.1" 200 63773
2026-01-08 13:13:00,941 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.one.com:443
2026-01-08 13:13:01,452 - urllib3.connectionpool - DEBUG - https://www.one.com:443 "GET /de-de/webshop/was-ist-churn/ HTTP/1.1" 200 109751
2026-01-08 13:13:01,456 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): de.wikipedia.org:443
2026-01-08 13:13:01,860 - urllib3.connectionpool - DEBUG - https://de.wikipedia.org:443 "GET /wiki/Churn_Management) HTTP/1.1" 403 2068
2026-01-08 13:13:01,864 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.signo-media.de:443
2026-01-08 13:13:02,374 - urllib3.connectionpool - DEBUG - https://www.signo-media.de:443 "GET /wissensdatenbank/churn-rate/ HTTP/1.1" 200 None
2026-01-08 16:35:46,240 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,240 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,241 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,241 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,241 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,241 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,242 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,242 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:35:46,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:36,939 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:36,939 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:36,939 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:36,940 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:36,941 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:36,941 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:36,942 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:36,942 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:37,373 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:37,373 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:37,373 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:37,373 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:37,376 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:37,376 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:49:37,376 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:49:37,376 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:06,438 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:06,438 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:06,438 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:06,438 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:06,441 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:06,441 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:06,441 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:06,441 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:09,042 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:09,043 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:09,043 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:09,043 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:09,044 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:09,044 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:09,044 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:09,044 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:10,142 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:10,142 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:10,142 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:10,144 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:10,145 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:10,145 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:10,145 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:10,145 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:10,202 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 16:50:10,683 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 16:50:10,685 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 16:50:10,692 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 16:50:10,713 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E4DB332050>
2026-01-08 16:50:10,713 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E4C23C95B0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 16:50:10,787 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E4DB331DD0>
2026-01-08 16:50:10,787 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 16:50:10,790 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 16:50:10,790 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 16:50:10,790 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 16:50:10,790 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 16:50:12,943 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 14:50:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2112'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 16:50:12,943 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 16:50:12,945 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 16:50:12,945 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 16:50:12,945 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 16:50:12,945 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 16:50:12,945 - processor - ERROR - Error in batch analysis: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 16:50:12,945 - processor - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 16:50:13,052 - __main__ - INFO - Report structure analysis finalized
2026-01-08 16:50:13,110 - httpcore.connection - DEBUG - close.started
2026-01-08 16:50:13,110 - httpcore.connection - DEBUG - close.complete
2026-01-08 16:50:13,114 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:13,114 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:13,114 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:13,114 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:13,117 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:13,117 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 16:50:13,117 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 16:50:13,117 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:06,413 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:06,413 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:06,413 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:06,415 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:06,598 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:06,598 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:06,599 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:06,599 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:39,821 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:39,823 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:39,823 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:39,823 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:39,824 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:39,824 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:39,824 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:39,824 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:42,522 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:42,522 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:42,525 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:42,525 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:42,525 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:42,525 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:42,526 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:42,526 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:44,546 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:44,546 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:44,546 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:44,546 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:44,549 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:44,549 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:44,549 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:44,549 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:45,698 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:45,698 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:45,698 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:45,698 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:45,700 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:45,700 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:45,700 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:45,700 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:45,753 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 18:56:46,377 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 18:56:46,377 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 18:56:46,379 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 18:56:46,421 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD8A8A10>
2026-01-08 18:56:46,421 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000243A2A48320> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 18:56:46,495 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD8A8D10>
2026-01-08 18:56:46,495 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 18:56:46,496 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 18:56:46,496 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 18:56:46,496 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 18:56:46,496 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 18:56:52,249 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 16:56:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5743'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 18:56:52,250 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 18:56:52,250 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 18:56:52,251 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 18:56:52,251 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 18:56:52,251 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 18:56:52,252 - processor - INFO - Batch analysis successful
2026-01-08 18:56:52,252 - httpcore.connection - DEBUG - close.started
2026-01-08 18:56:52,252 - httpcore.connection - DEBUG - close.complete
2026-01-08 18:56:52,254 - __main__ - INFO - Report structure analysis finalized
2026-01-08 18:56:52,301 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:52,301 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:52,301 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:52,302 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:52,302 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:52,302 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:56:52,302 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:56:52,302 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:03,942 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:03,942 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:03,942 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:03,942 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:03,943 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:03,943 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:03,943 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:03,943 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,192 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,193 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,193 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,193 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,194 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,194 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,194 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,194 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,996 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,996 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,996 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,998 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,999 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,999 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:05,999 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:05,999 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:09,357 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:09,357 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:09,357 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:09,357 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:09,359 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:09,359 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:09,359 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:09,359 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,464 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,464 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,464 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,464 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,466 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,466 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,466 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,466 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,524 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,524 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,524 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,526 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,527 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,527 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,527 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:57:18,527 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:57:18,529 - researcher - INFO - Researching 'Artificial Intelligence has experienced significant growth in popularity, particularly after the launch of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the AI industry's current status. It specifically focuses on the landscape as it stood in mid-2023. The rapid advancements in AI have made it a prominent topic.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 18:57:18,530 - researcher - INFO - Searching DuckDuckGo for: Artificial Intelligence has experienced significant growth in popularity, particularly after the launch of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the AI industry's current status. It specifically focuses on the landscape as it stood in mid-2023. The rapid advancements in AI have made it a prominent topic. (since mid-2023)
2026-01-08 18:57:18,536 - primp.utils - DEBUG - Loaded CA certs
2026-01-08 18:57:18,536 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-08 18:57:18,536 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-08 18:57:18,551 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.160:443
2026-01-08 18:57:18,560 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.160:443
2026-01-08 18:57:18,572 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:57:18,715 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-08 18:57:18,715 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=331ACB177CD5676214C8DDCC7DB466F4; expires=Tue, 02-Feb-2027 16:57:18 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:57:18.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:18,715 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=0B67B2657B916EB2261DA4BE7AF06F02; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:18,715 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Tue, 02-Feb-2027 16:57:18 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-02 16:57:18.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:18,715 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:18 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-08 16:57:18.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:18,716 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=0A630CFDBD254EE89F9C224251710AB4&dmnchg=1; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:18 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-08 16:57:18.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:18,716 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260108; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:18 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-08 16:57:18.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:18,716 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=091D3E8E4D9949B3B30894FEC3EF34D6; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:18 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:57:18.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:18,716 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=0B67B2657B916EB2261DA4BE7AF06F02; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:18,716 - primp - INFO - response: https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023 200
2026-01-08 18:57:18,716 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023 200
2026-01-08 18:57:19,625 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:57:19,800 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=331ACB177CD5676214C8DDCC7DB466F4; expires=Tue, 02-Feb-2027 16:57:20 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:57:20.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:19,800 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-08 18:57:19,800 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=5E2007C356F3467A8BA3B4213C8D2727; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:20 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:57:20.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:19,800 - primp - INFO - response: https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=11&FORM=PERE 200
2026-01-08 18:57:19,800 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=11&FORM=PERE 200
2026-01-08 18:57:20,564 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:57:20,688 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=331ACB177CD5676214C8DDCC7DB466F4; expires=Tue, 02-Feb-2027 16:57:20 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:57:20.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:20,688 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=C4E1EF0980A84647B7F251BC2083A515; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:20 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:57:20.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:20,688 - primp - INFO - response: https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=21&FORM=PERE1 200
2026-01-08 18:57:20,688 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=21&FORM=PERE1 200
2026-01-08 18:57:21,507 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:57:21,711 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=331ACB177CD5676214C8DDCC7DB466F4; expires=Tue, 02-Feb-2027 16:57:21 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:57:21.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:21,711 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=97DC637B67A5442E9C39DC8129C48C2B; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:21 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:57:21.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:21,711 - primp - INFO - response: https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=31&FORM=PERE2 200
2026-01-08 18:57:21,711 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=31&FORM=PERE2 200
2026-01-08 18:57:22,522 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:57:22,656 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=331ACB177CD5676214C8DDCC7DB466F4; expires=Tue, 02-Feb-2027 16:57:22 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:57:22.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:22,656 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=383661255E6E471DAD955ADA66CA5EC9; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:22 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:57:22.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:22,656 - primp - INFO - response: https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=41&FORM=PERE3 200
2026-01-08 18:57:22,656 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Artificial+Intelligence+has+experienced+significant+growth+in+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+This+report+aims+to+provide+a+comprehensive+overview+of+the+AI+industry%27s+current+status.+It+specifically+focuses+on+the+landscape+as+it+stood+in+mid-2023.+The+rapid+advancements+in+AI+have+made+it+a+prominent+topic.+since+mid-2023&first=41&FORM=PERE3 200
2026-01-08 18:57:22,807 - researcher - INFO - Searching OpenAlex for: Artificial Intelligence has experienced significant growth in popularity, particularly after the launch of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the AI industry's current status. It specifically focuses on the landscape as it stood in mid-2023. The rapid advancements in AI have made it a prominent topic.
2026-01-08 18:57:22,828 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 18:57:24,189 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Artificial%20Intelligence%20has%20experienced%20significant%20growth%20in%20popularity,%20particularly%20after%20the%20launch%20of%20ChatGPT%20in%20late%202022.%20This%20report%20aims%20to%20provide%20a%20comprehensive%20overview%20of%20the%20AI%20industry's%20current%20status.%20It%20specifically%20focuses%20on%20the%20landscape%20as%20it%20stood%20in%20mid-2023.%20The%20rapid%20advancements%20in%20AI%20have%20made%20it%20a%20prominent%20topic.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 18:57:26,191 - updater - INFO - Updating chapter content with research findings
2026-01-08 18:57:26,552 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 18:57:26,552 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 18:57:26,554 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 18:57:26,560 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD977650>
2026-01-08 18:57:26,560 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000243BD8DE690> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 18:57:26,640 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD962B10>
2026-01-08 18:57:26,642 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 18:57:26,642 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 18:57:26,642 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 18:57:26,642 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 18:57:26,642 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 18:57:42,865 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 16:57:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=16206'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 18:57:42,866 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 18:57:42,866 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 18:57:42,866 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 18:57:42,867 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 18:57:42,867 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 18:57:42,867 - updater - INFO - Chapter update successful
2026-01-08 18:57:42,867 - httpcore.connection - DEBUG - close.started
2026-01-08 18:57:42,868 - httpcore.connection - DEBUG - close.complete
2026-01-08 18:57:44,870 - researcher - INFO - Researching 'In early 2023, GPT-4 emerged as the leading model in the Large Language Model (LLM) industry, setting new benchmarks for performance. Other major technology companies, such as Google and Meta, have also contributed to the field with their own models, Bard and Llama 1 respectively, the latter primarily for research. The current emphasis within the LLM domain is on scaling up these models and significantly increasing their parameter counts to enhance capabilities. This indicates a competitive and rapidly evolving landscape.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 18:57:44,870 - researcher - INFO - Searching DuckDuckGo for: In early 2023, GPT-4 emerged as the leading model in the Large Language Model (LLM) industry, setting new benchmarks for performance. Other major technology companies, such as Google and Meta, have also contributed to the field with their own models, Bard and Llama 1 respectively, the latter primarily for research. The current emphasis within the LLM domain is on scaling up these models and significantly increasing their parameter counts to enhance capabilities. This indicates a competitive and rapidly evolving landscape. (since early 2023)
2026-01-08 18:57:44,870 - primp.utils - DEBUG - Loaded CA certs
2026-01-08 18:57:44,870 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-08 18:57:44,870 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-08 18:57:44,883 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.195:443
2026-01-08 18:57:44,896 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.195:443
2026-01-08 18:57:44,911 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=09BF5CDCF4496F7615E94A07F5916E29; expires=Tue, 02-Feb-2027 16:57:45 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:57:45.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=00A5F3B9241D61661DF0E56225C560F0; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Tue, 02-Feb-2027 16:57:45 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-02 16:57:45.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:45 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-08 16:57:45.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=EC8E94E3299B42B998A37A31D2F7AEA0&dmnchg=1; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:45 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-08 16:57:45.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:45,049 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260108; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:45 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-08 16:57:45.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:45,050 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=4CBEAF6639DD49ECBBE50E6B2C0A8F71; domain=.bing.com; expires=Sat, 08-Jan-2028 16:57:45 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:57:45.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:45,050 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=00A5F3B9241D61661DF0E56225C560F0; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:57:45,050 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=2C2684A775C8E8226ED70009BEEEBAD0~000000000000000000000000000000~YAAQlphmUlBlMSybAQAAd/SKnh4jamqtQvak696929atimOLOedd/eAzW7f9Mj4ZUSAMkmDoRJVKJZ0s+wlJ/KuJtUqxwYYhv2jfiioqD6Ok8ZNcgBgTvGK9JvfwKkr3Gckm6jjHlyiGZI+txMTYyHf48l3mblCI9kmy34RVe3LxkbC5Kckpp5glHiHx3JBj8CEchStMnYvdQZoQAm9yMom43hmOVbnUovC+RAsG/keSOAcYwKirtQgqexDPi8x4oHKvqL0wdbChMP5nGSrnL2rCfrv33vWPmC7cIU9574BnqNSgUYMhUBKAo8GHfimENsPR+nYkk7nlaW3kiNKJHUigvM4Pk/A6epLHQzDgLJxlHo0Bji2VxIQ8R9yqv534c/QnoGwN7n4w; Domain=.bing.com; Path=/; Expires=Thu, 08 Jan 2026 18:57:45 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 468), expires: Some(DateTime(2026-01-08 18:57:45.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(477, 486)), path: Some(Indexed(493, 494)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:57:45,050 - primp - INFO - response: https://www.bing.com/search?q=In+early+2023%2C+GPT-4+emerged+as+the+leading+model+in+the+Large+Language+Model+%28LLM%29+industry%2C+setting+new+benchmarks+for+performance.+Other+major+technology+companies%2C+such+as+Google+and+Meta%2C+have+also+contributed+to+the+field+with+their+own+models%2C+Bard+and+Llama+1+respectively%2C+the+latter+primarily+for+research.+The+current+emphasis+within+the+LLM+domain+is+on+scaling+up+these+models+and+significantly+increasing+their+parameter+counts+to+enhance+capabilities.+This+indicates+a+competitive+and+rapidly+evolving+landscape.+since+early+2023 200
2026-01-08 18:57:45,050 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=In+early+2023%2C+GPT-4+emerged+as+the+leading+model+in+the+Large+Language+Model+%28LLM%29+industry%2C+setting+new+benchmarks+for+performance.+Other+major+technology+companies%2C+such+as+Google+and+Meta%2C+have+also+contributed+to+the+field+with+their+own+models%2C+Bard+and+Llama+1+respectively%2C+the+latter+primarily+for+research.+The+current+emphasis+within+the+LLM+domain+is+on+scaling+up+these+models+and+significantly+increasing+their+parameter+counts+to+enhance+capabilities.+This+indicates+a+competitive+and+rapidly+evolving+landscape.+since+early+2023 200
2026-01-08 18:57:45,116 - researcher - INFO - Searching OpenAlex for: In early 2023, GPT-4 emerged as the leading model in the Large Language Model (LLM) industry, setting new benchmarks for performance. Other major technology companies, such as Google and Meta, have also contributed to the field with their own models, Bard and Llama 1 respectively, the latter primarily for research. The current emphasis within the LLM domain is on scaling up these models and significantly increasing their parameter counts to enhance capabilities. This indicates a competitive and rapidly evolving landscape.
2026-01-08 18:57:45,119 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 18:57:46,369 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=In%20early%202023,%20GPT-4%20emerged%20as%20the%20leading%20model%20in%20the%20Large%20Language%20Model%20(LLM)%20industry,%20setting%20new%20benchmarks%20for%20performance.%20Other%20major%20technology%20companies,%20such%20as%20Google%20and%20Meta,%20have%20also%20contributed%20to%20the%20field%20with%20their%20own%20models,%20Bard%20and%20Llama%201%20respectively,%20the%20latter%20primarily%20for%20research.%20The%20current%20emphasis%20within%20the%20LLM%20domain%20is%20on%20scaling%20up%20these%20models%20and%20significantly%20increasing%20their%20parameter%20counts%20to%20enhance%20capabilities.%20This%20indicates%20a%20competitive%20and%20rapidly%20evolving%20landscape.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 18:57:48,373 - updater - INFO - Updating chapter content with research findings
2026-01-08 18:57:48,740 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 18:57:48,740 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 18:57:48,743 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 18:57:48,751 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD9E2890>
2026-01-08 18:57:48,751 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000243BD8DE570> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 18:57:48,810 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD9E2850>
2026-01-08 18:57:48,814 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 18:57:48,814 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 18:57:48,814 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 18:57:48,814 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 18:57:48,814 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 18:58:08,511 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 16:58:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=19688'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 18:58:08,511 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 18:58:08,514 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 18:58:08,514 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 18:58:08,514 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 18:58:08,514 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 18:58:08,515 - updater - INFO - Chapter update successful
2026-01-08 18:58:08,515 - httpcore.connection - DEBUG - close.started
2026-01-08 18:58:08,515 - httpcore.connection - DEBUG - close.complete
2026-01-08 18:58:10,518 - researcher - INFO - Researching 'The field of Artificial Intelligence is experiencing incredibly rapid advancements, with new developments emerging constantly. The year 2023 is particularly significant as it is identified as the start of the generative AI era. This period signifies a major shift towards AI systems capable of creating new content. The quick pace of innovation suggests a dynamic and transformative future for AI.' via sources: ['Web Search', 'Academic Papers']
2026-01-08 18:58:10,518 - researcher - INFO - Searching DuckDuckGo for: The field of Artificial Intelligence is experiencing incredibly rapid advancements, with new developments emerging constantly. The year 2023 is particularly significant as it is identified as the start of the generative AI era. This period signifies a major shift towards AI systems capable of creating new content. The quick pace of innovation suggests a dynamic and transformative future for AI. (since 2023)
2026-01-08 18:58:10,518 - primp.utils - DEBUG - Loaded CA certs
2026-01-08 18:58:10,519 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-08 18:58:10,519 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-08 18:58:10,543 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.178:443
2026-01-08 18:58:10,554 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.178:443
2026-01-08 18:58:10,574 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-08 18:58:10,717 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-08 18:58:10,717 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=17AC94D9B310662E10808202B263670E; expires=Tue, 02-Feb-2027 16:58:10 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-02 16:58:10.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:58:10,717 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=1D7F09466E046187019F1F9D6F776020; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:58:10,717 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Tue, 02-Feb-2027 16:58:10 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-02 16:58:10.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:58:10,717 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sat, 08-Jan-2028 16:58:10 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-08 16:58:10.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:58:10,719 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=AD900D80C8E44DB08451121BAD8B40AE&dmnchg=1; domain=.bing.com; expires=Sat, 08-Jan-2028 16:58:10 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-08 16:58:10.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:58:10,719 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260108; domain=.bing.com; expires=Sat, 08-Jan-2028 16:58:10 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-08 16:58:10.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:58:10,719 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=6C829230B11D43E3BF395A2C09375677; domain=.bing.com; expires=Sat, 08-Jan-2028 16:58:10 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-08 16:58:10.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:58:10,719 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=1D7F09466E046187019F1F9D6F776020; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-08 18:58:10,719 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=7FDC9345B76AE07F02B51B29B0504607~000000000000000000000000000000~YAAQpphmUlHtSyybAQAAxFiLnh768LvS6Ww7DDiyA1mIUQAjshImqDJRE8SuHvHo+8Dh55KiLVb0I/eGzav7/N8EV2n+MXpHSFN7pCmm6DVKzt3te4ku32nnlk68RAOGz7kmDW23gcn8jtIUkHYRq4QvT9tF60Wcj8ZzYNiIX/9bN/uUtNAgDTS/ZyHAOmpayyCyQB7gcbvMySGFTMj49An0OP2Y6eAT/KT5QdWYmrojy/v4lS8zPsqn0hPU/4cFw6MGVtIp0ksTaOZM7e8+zjevNVXDef1QzTPVmuJmVlTndnpTGlhMuiJsu2/SbdQiORrhcM6c4QiIC277HqokHjmneS/UWIH2jvdV4yRruWeDmtqB1cqQbl/Aa7C/qNBviQ9c7SPKBP5V; Domain=.bing.com; Path=/; Expires=Thu, 08 Jan 2026 18:58:10 GMT; Max-Age=7199; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 468), expires: Some(DateTime(2026-01-08 18:58:10.0 +00:00:00)), max_age: Some(Duration { seconds: 7199, nanoseconds: 0 }), domain: Some(Indexed(477, 486)), path: Some(Indexed(493, 494)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-08 18:58:10,719 - primp - INFO - response: https://www.bing.com/search?q=The+field+of+Artificial+Intelligence+is+experiencing+incredibly+rapid+advancements%2C+with+new+developments+emerging+constantly.+The+year+2023+is+particularly+significant+as+it+is+identified+as+the+start+of+the+generative+AI+era.+This+period+signifies+a+major+shift+towards+AI+systems+capable+of+creating+new+content.+The+quick+pace+of+innovation+suggests+a+dynamic+and+transformative+future+for+AI.+since+2023 200
2026-01-08 18:58:10,719 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=The+field+of+Artificial+Intelligence+is+experiencing+incredibly+rapid+advancements%2C+with+new+developments+emerging+constantly.+The+year+2023+is+particularly+significant+as+it+is+identified+as+the+start+of+the+generative+AI+era.+This+period+signifies+a+major+shift+towards+AI+systems+capable+of+creating+new+content.+The+quick+pace+of+innovation+suggests+a+dynamic+and+transformative+future+for+AI.+since+2023 200
2026-01-08 18:58:10,954 - researcher - INFO - Searching OpenAlex for: The field of Artificial Intelligence is experiencing incredibly rapid advancements, with new developments emerging constantly. The year 2023 is particularly significant as it is identified as the start of the generative AI era. This period signifies a major shift towards AI systems capable of creating new content. The quick pace of innovation suggests a dynamic and transformative future for AI.
2026-01-08 18:58:10,954 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-08 18:58:12,238 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=The%20field%20of%20Artificial%20Intelligence%20is%20experiencing%20incredibly%20rapid%20advancements,%20with%20new%20developments%20emerging%20constantly.%20The%20year%202023%20is%20particularly%20significant%20as%20it%20is%20identified%20as%20the%20start%20of%20the%20generative%20AI%20era.%20This%20period%20signifies%20a%20major%20shift%20towards%20AI%20systems%20capable%20of%20creating%20new%20content.%20The%20quick%20pace%20of%20innovation%20suggests%20a%20dynamic%20and%20transformative%20future%20for%20AI.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-08 18:58:12,882 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 18:58:12,882 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 18:58:12,891 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD997650>
2026-01-08 18:58:12,891 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000243BD8DE960> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 18:58:12,961 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD997610>
2026-01-08 18:58:12,961 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 18:58:12,961 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 18:58:12,961 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 18:58:12,961 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 18:58:12,961 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 18:58:17,783 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 16:58:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4812'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 18:58:17,783 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-08 18:58:17,783 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 18:58:17,783 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 18:58:17,783 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 18:58:17,783 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 18:58:17,786 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 18:58:17,786 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 18:58:17,786 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 18:58:17,786 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 18:58:17,786 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 18:58:17,786 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 18:58:18,621 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 16:58:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=824'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 18:58:18,621 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 18:58:18,621 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 18:58:18,621 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 18:58:18,621 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 18:58:18,621 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 18:58:18,621 - researcher - ERROR - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 18:58:20,623 - updater - INFO - Updating chapter content with research findings
2026-01-08 18:58:20,999 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-08 18:58:20,999 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-08 18:58:20,999 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-08 18:58:21,016 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD999490>
2026-01-08 18:58:21,016 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000243BD8DF530> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08 18:58:21,083 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000243BD999450>
2026-01-08 18:58:21,083 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-08 18:58:21,083 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-08 18:58:21,083 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-08 18:58:21,083 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-08 18:58:21,083 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-08 18:58:22,231 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 503, b'Service Unavailable', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 16:58:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1137'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08 18:58:22,231 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2026-01-08 18:58:22,232 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-08 18:58:22,232 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-08 18:58:22,232 - httpcore.http11 - DEBUG - response_closed.started
2026-01-08 18:58:22,233 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-08 18:58:22,233 - updater - ERROR - Failed to update chapter: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 18:58:22,233 - httpcore.connection - DEBUG - close.started
2026-01-08 18:58:22,233 - httpcore.connection - DEBUG - close.complete
2026-01-08 18:58:22,233 - updater - ERROR - 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 55, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 148, in raise_error
    raise ServerError(status_code, response_json, response)
google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-08 18:58:22,295 - httpcore.connection - DEBUG - close.started
2026-01-08 18:58:22,296 - httpcore.connection - DEBUG - close.complete
2026-01-08 18:58:22,326 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:58:22,326 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:58:22,327 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:58:22,327 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:58:22,328 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:58:22,328 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:58:22,328 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-08 18:58:22,329 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-08 18:58:22,345 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:23,999 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/1315553855969434219.html) HTTP/1.1" 404 192
2026-01-08 18:58:24,001 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:25,386 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/382551031018850524.html HTTP/1.1" 302 None
2026-01-08 18:58:25,388 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): wappass.baidu.com:443
2026-01-08 18:58:26,933 - urllib3.connectionpool - DEBUG - https://wappass.baidu.com:443 "GET /static/captcha/tuxing_v2.html?ak=c66NZZrP4HZtBDgXqdByfpyEtsGH55H3&backurl=https%3A%2F%2Fzhidao.baidu.com%2Fquestion%2F382551031018850524.html&bfe_logid=10472854002930956307&timestamp=1767891505&signature=4f2f598791701babb512522badafdabd HTTP/1.1" 200 1488
2026-01-08 18:58:26,933 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:28,319 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/565894051830710132.html) HTTP/1.1" 404 192
2026-01-08 18:58:28,324 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:28,856 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/news/) HTTP/1.1" 301 None
2026-01-08 18:58:29,098 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/ HTTP/1.1" 200 None
2026-01-08 18:58:29,101 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:58:29,892 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/377482124) HTTP/1.1" 403 None
2026-01-08 18:58:29,896 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:31,396 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/436235934469167524.html) HTTP/1.1" 404 192
2026-01-08 18:58:31,397 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:31,746 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/news/127595-gears-war-4-hacks-gow4-hacks.html) HTTP/1.1" 301 None
2026-01-08 18:58:31,945 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/ HTTP/1.1" 200 None
2026-01-08 18:58:31,947 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:32,288 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/index.php) HTTP/1.1" 301 None
2026-01-08 18:58:32,440 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/ HTTP/1.1" 200 None
2026-01-08 18:58:32,443 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:33,781 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/38629772.html) HTTP/1.1" 404 192
2026-01-08 18:58:33,782 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:58:34,436 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/66954030/answers/updated) HTTP/1.1" 403 None
2026-01-08 18:58:34,438 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:58:35,041 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/557993905) HTTP/1.1" 403 None
2026-01-08 18:58:35,045 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:36,827 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/128760971.html HTTP/1.1" 302 None
2026-01-08 18:58:36,827 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): wappass.baidu.com:443
2026-01-08 18:58:38,143 - urllib3.connectionpool - DEBUG - https://wappass.baidu.com:443 "GET /static/captcha/tuxing_v2.html?ak=c66NZZrP4HZtBDgXqdByfpyEtsGH55H3&backurl=https%3A%2F%2Fzhidao.baidu.com%2Fquestion%2F128760971.html&bfe_logid=9206603759846327089&timestamp=1767891516&signature=3e4f02c29a5129646e31ccfaa9b478a4 HTTP/1.1" 200 1488
2026-01-08 18:58:38,146 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:39,489 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/340664983072344285.html) HTTP/1.1" 404 192
2026-01-08 18:58:39,491 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:58:40,117 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/23712890) HTTP/1.1" 403 None
2026-01-08 18:58:40,119 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:40,436 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/719088-post2.html HTTP/1.1" 200 None
2026-01-08 18:58:40,438 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:41,883 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/1315553855969434219.html HTTP/1.1" 302 None
2026-01-08 18:58:41,883 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): wappass.baidu.com:443
2026-01-08 18:58:43,164 - urllib3.connectionpool - DEBUG - https://wappass.baidu.com:443 "GET /static/captcha/tuxing_v2.html?ak=c66NZZrP4HZtBDgXqdByfpyEtsGH55H3&backurl=https%3A%2F%2Fzhidao.baidu.com%2Fquestion%2F1315553855969434219.html&bfe_logid=11232173400292071819&timestamp=1767891522&signature=35eb641b84c951cedd24cedfe51cb570 HTTP/1.1" 200 1488
2026-01-08 18:58:43,166 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:44,767 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/38629434219.html HTTP/1.1" 302 None
2026-01-08 18:58:44,769 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): wappass.baidu.com:443
2026-01-08 18:58:46,056 - urllib3.connectionpool - DEBUG - https://wappass.baidu.com:443 "GET /static/captcha/tuxing_v2.html?ak=c66NZZrP4HZtBDgXqdByfpyEtsGH55H3&backurl=https%3A%2F%2Fzhidao.baidu.com%2Fquestion%2F38629434219.html&bfe_logid=11866290854619908613&timestamp=1767891524&signature=e1dce97ed53777f894c747b8cf9554c3 HTTP/1.1" 200 1488
2026-01-08 18:58:46,060 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:46,374 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/719088-post2.html) HTTP/1.1" 301 None
2026-01-08 18:58:46,560 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/ HTTP/1.1" 200 None
2026-01-08 18:58:46,565 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:47,928 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/436235934469167524.html HTTP/1.1" 302 None
2026-01-08 18:58:47,928 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): wappass.baidu.com:443
2026-01-08 18:58:49,221 - urllib3.connectionpool - DEBUG - https://wappass.baidu.com:443 "GET /static/captcha/tuxing_v2.html?ak=c66NZZrP4HZtBDgXqdByfpyEtsGH55H3&backurl=https%3A%2F%2Fzhidao.baidu.com%2Fquestion%2F436235934469167524.html&bfe_logid=8025840451652957588&timestamp=1767891528&signature=11e70b9855e3b00807bd5d1dc0470f59 HTTP/1.1" 200 1488
2026-01-08 18:58:49,224 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:50,567 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/565894051830710132.html HTTP/1.1" 200 None
2026-01-08 18:58:50,571 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:51,815 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/340664983072344285.html HTTP/1.1" 200 None
2026-01-08 18:58:51,817 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:52,164 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/news/127595-gears-war-4-hacks-gow4-hacks.html HTTP/1.1" 200 None
2026-01-08 18:58:52,167 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:53,496 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/382551031018850524.html) HTTP/1.1" 404 192
2026-01-08 18:58:53,496 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:58:54,156 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/664304568?write) HTTP/1.1" 403 None
2026-01-08 18:58:54,161 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:54,488 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/search.php HTTP/1.1" 200 None
2026-01-08 18:58:54,492 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:54,927 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/news/ HTTP/1.1" 200 None
2026-01-08 18:58:54,931 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:58:55,601 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /tardis/bd/ans/3356163643) HTTP/1.1" 302 79
2026-01-08 18:58:55,922 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /tardis/error?status=400 HTTP/1.1" 200 None
2026-01-08 18:58:55,924 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:57,319 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/1971826765810554940.html) HTTP/1.1" 404 192
2026-01-08 18:58:57,321 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-08 18:58:57,712 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.48550/arxiv.2406.11844 HTTP/1.1" 302 None
2026-01-08 18:58:57,714 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): arxiv.org:443
2026-01-08 18:58:58,142 - urllib3.connectionpool - DEBUG - https://arxiv.org:443 "GET /abs/2406.11844 HTTP/1.1" 200 46538
2026-01-08 18:58:58,145 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-08 18:58:59,489 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/128760971.html) HTTP/1.1" 404 192
2026-01-08 18:58:59,495 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:58:59,799 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/search.php) HTTP/1.1" 404 None
2026-01-08 18:58:59,802 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:59:00,454 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /tardis/bd/ans/1910838113) HTTP/1.1" 302 79
2026-01-08 18:59:00,800 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /tardis/error?status=400 HTTP/1.1" 200 None
2026-01-08 18:59:00,802 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-08 18:59:01,426 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/572116481) HTTP/1.1" 403 None
2026-01-08 18:59:01,428 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-08 18:59:01,861 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/index.php HTTP/1.1" 200 None
2026-01-09 14:46:42,391 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:42,391 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:42,391 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:42,391 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:42,569 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:42,569 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:42,570 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:42,570 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:46,258 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:46,258 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:46,258 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:46,258 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:46,261 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:46,261 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:46:46,261 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:46:46,261 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:01,122 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:01,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:01,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:01,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:01,126 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:01,126 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:01,126 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:01,126 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:04,032 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:04,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:04,033 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:04,034 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:04,034 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:04,087 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-09 14:47:04,718 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-09 14:47:04,719 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-09 14:47:04,719 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-09 14:47:04,746 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2E75FD510>
2026-01-09 14:47:04,746 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A2E777CC20> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-09 14:47:04,812 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2E789A950>
2026-01-09 14:47:04,812 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-09 14:47:04,814 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-09 14:47:04,814 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-09 14:47:04,814 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-09 14:47:04,814 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-09 14:47:07,395 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 09 Jan 2026 12:47:09 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2573'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-09 14:47:07,395 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-09 14:47:07,395 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-09 14:47:07,395 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-09 14:47:07,396 - httpcore.http11 - DEBUG - response_closed.started
2026-01-09 14:47:07,396 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-09 14:47:07,396 - processor - INFO - Batch analysis successful
2026-01-09 14:47:07,396 - httpcore.connection - DEBUG - close.started
2026-01-09 14:47:07,396 - httpcore.connection - DEBUG - close.complete
2026-01-09 14:47:07,396 - __main__ - INFO - Report structure analysis finalized
2026-01-09 14:47:07,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:07,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:07,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:07,452 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:07,454 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:07,454 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:07,454 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:07,454 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:10,446 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:10,446 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:10,446 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:10,446 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:10,450 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:10,450 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:10,450 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:10,450 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:12,275 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:12,276 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:12,276 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:12,276 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:12,277 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:12,277 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:12,277 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:12,277 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:14,532 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:14,533 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:14,533 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:14,533 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:14,534 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:14,534 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:14,534 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:14,534 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,605 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,605 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,605 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,605 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,606 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,606 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,607 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,607 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,671 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,671 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,672 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,672 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,672 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,672 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,672 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-09 14:47:23,672 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-09 14:47:23,674 - researcher - INFO - Researching 'This chapter introduces the report, highlighting the significant increase in Artificial Intelligence's popularity, particularly after the launch of ChatGPT in late 2022. It states that the report aims to summarize the industry's condition as of mid-2023, setting the stage for subsequent detailed analyses.' via sources: ['Web Search', 'Academic Papers']
2026-01-09 14:47:23,677 - researcher - INFO - Searching DuckDuckGo for: This chapter introduces the report, highlighting the significant increase in Artificial Intelligence's popularity, particularly after the launch of ChatGPT in late 2022. It states that the report aims to summarize the industry's condition as of mid-2023, setting the stage for subsequent detailed analyses. (since mid-2023)
2026-01-09 14:47:23,682 - primp.utils - DEBUG - Loaded CA certs
2026-01-09 14:47:23,683 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-09 14:47:23,683 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-09 14:47:23,716 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.195:443
2026-01-09 14:47:23,724 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.195:443
2026-01-09 14:47:23,739 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-09 14:47:23,886 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-09 14:47:23,886 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=30F5E3D7227164233BC2F50B23C065C3; expires=Wed, 03-Feb-2027 12:47:25 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-03 12:47:25.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=0642E7FCFEB267533FB6F120FF036634; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Wed, 03-Feb-2027 12:47:25 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-03 12:47:25.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:25 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-09 12:47:25.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=35EEA2F9046146348ACA3999E7EE2A34&dmnchg=1; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:25 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-09 12:47:25.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260109; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:25 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-09 12:47:25.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=7BB54381AC884657A19CEBA3607025A4; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:25 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-09 12:47:25.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=0642E7FCFEB267533FB6F120FF036634; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=24F7873EFD1E1AF8B5236F476B73022D~000000000000000000000000000000~YAAQlJhmUnZGQiibAQAAaCLMoh4+gCS9kgQRC6mTszXrm7nhRjLgONg5fnbVhYncdLQe06/mi17G82oGILsUGFvD7Ib5e6Y5b7uSNEqYYSuN6KYBdEVBB/8y4+SEC1P3PubVQiJdW6ijEpwxwoKfrVJMBE1QiULzAaITFhTqe6PTbU+q1EHzQuKbsumJnO6v6wjb7qg4yW0+Jfap+JlrDqwKCOSEoz/+Csc/oGoSG6i4eoiBP5DX6pvStBsdsEGRnHsB3/rWpgS2qlnh+Iev0k9hbmqik3WbR/AWMbz/7BCMQtVKI7ESoiA5zeok5ztH9qXVUcbjM7WOhOYUxSvVkBU3cALwdsibaLSWS//Vhu1Oc/Tfn4VnCJPBF+5qcs1hTgMzC99249I=; Domain=.bing.com; Path=/; Expires=Fri, 09 Jan 2026 14:47:25 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 468), expires: Some(DateTime(2026-01-09 14:47:25.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(477, 486)), path: Some(Indexed(493, 494)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:23,887 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+introduces+the+report%2C+highlighting+the+significant+increase+in+Artificial+Intelligence%27s+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+It+states+that+the+report+aims+to+summarize+the+industry%27s+condition+as+of+mid-2023%2C+setting+the+stage+for+subsequent+detailed+analyses.+since+mid-2023 200
2026-01-09 14:47:23,887 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+introduces+the+report%2C+highlighting+the+significant+increase+in+Artificial+Intelligence%27s+popularity%2C+particularly+after+the+launch+of+ChatGPT+in+late+2022.+It+states+that+the+report+aims+to+summarize+the+industry%27s+condition+as+of+mid-2023%2C+setting+the+stage+for+subsequent+detailed+analyses.+since+mid-2023 200
2026-01-09 14:47:23,946 - researcher - INFO - Searching OpenAlex for: This chapter introduces the report, highlighting the significant increase in Artificial Intelligence's popularity, particularly after the launch of ChatGPT in late 2022. It states that the report aims to summarize the industry's condition as of mid-2023, setting the stage for subsequent detailed analyses.
2026-01-09 14:47:23,965 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-09 14:47:25,883 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20introduces%20the%20report,%20highlighting%20the%20significant%20increase%20in%20Artificial%20Intelligence's%20popularity,%20particularly%20after%20the%20launch%20of%20ChatGPT%20in%20late%202022.%20It%20states%20that%20the%20report%20aims%20to%20summarize%20the%20industry's%20condition%20as%20of%20mid-2023,%20setting%20the%20stage%20for%20subsequent%20detailed%20analyses.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-09 14:47:35,886 - updater - INFO - Updating chapter content with research findings
2026-01-09 14:47:36,219 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-09 14:47:36,219 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-09 14:47:36,220 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-09 14:47:36,231 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2E7984CD0>
2026-01-09 14:47:36,231 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A2E78DEA80> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-09 14:47:36,304 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001A2E7984C50>
2026-01-09 14:47:36,304 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-09 14:47:36,304 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-09 14:47:36,304 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-09 14:47:36,304 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-09 14:47:36,305 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-09 14:47:46,927 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Fri, 09 Jan 2026 12:47:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=10613'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-09 14:47:46,927 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-09 14:47:46,927 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-09 14:47:46,927 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-09 14:47:46,927 - httpcore.http11 - DEBUG - response_closed.started
2026-01-09 14:47:46,927 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-09 14:47:46,931 - updater - INFO - Chapter update successful
2026-01-09 14:47:46,931 - httpcore.connection - DEBUG - close.started
2026-01-09 14:47:46,931 - httpcore.connection - DEBUG - close.complete
2026-01-09 14:47:56,934 - researcher - INFO - Researching 'This chapter focuses on Large Language Models, identifying GPT-4 as the current state-of-the-art model in early 2023. It also mentions other significant contributions from Google with Bard and Meta with Llama 1, which was released for research. The chapter notes that the industry's primary focus is on expanding model scale and increasing parameter counts to enhance capabilities.' via sources: ['Web Search', 'Academic Papers']
2026-01-09 14:47:56,934 - researcher - INFO - Searching DuckDuckGo for: This chapter focuses on Large Language Models, identifying GPT-4 as the current state-of-the-art model in early 2023. It also mentions other significant contributions from Google with Bard and Meta with Llama 1, which was released for research. The chapter notes that the industry's primary focus is on expanding model scale and increasing parameter counts to enhance capabilities. (since early 2023)
2026-01-09 14:47:56,935 - primp.utils - DEBUG - Loaded CA certs
2026-01-09 14:47:56,935 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-09 14:47:56,936 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-09 14:47:56,945 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.171:443
2026-01-09 14:47:56,954 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.171:443
2026-01-09 14:47:56,967 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=15338FFDE91F6F4500FC9921E8716E93; expires=Wed, 03-Feb-2027 12:47:58 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-03 12:47:58.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=133C22E30CEB638C01DF343F0D85621D; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Wed, 03-Feb-2027 12:47:58 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-03 12:47:58.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:58 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-09 12:47:58.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=106F9F1CB6DC4C5B802CD0B3625AEEDD&dmnchg=1; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:58 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-09 12:47:58.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260109; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:58 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-09 12:47:58.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=778F5AC6338C4BAAA8113F7468802B03; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:58 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-09 12:47:58.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=133C22E30CEB638C01DF343F0D85621D; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:57,127 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023 200
2026-01-09 14:47:57,127 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023 200
2026-01-09 14:47:57,927 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-09 14:47:58,058 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=15338FFDE91F6F4500FC9921E8716E93; expires=Wed, 03-Feb-2027 12:47:59 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-03 12:47:59.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:58,058 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-09 14:47:58,058 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=88C7C9FDABD24A3E9F32FE120B386E36; domain=.bing.com; expires=Sun, 09-Jan-2028 12:47:59 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-09 12:47:59.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:58,058 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=11&FORM=PERE 200
2026-01-09 14:47:58,058 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=11&FORM=PERE 200
2026-01-09 14:47:58,863 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-09 14:47:59,027 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=15338FFDE91F6F4500FC9921E8716E93; expires=Wed, 03-Feb-2027 12:48:00 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-03 12:48:00.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:47:59,027 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=243117983B26434B9C3F1DEA5660C0FB; domain=.bing.com; expires=Sun, 09-Jan-2028 12:48:00 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-09 12:48:00.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:47:59,027 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=21&FORM=PERE1 200
2026-01-09 14:47:59,027 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=21&FORM=PERE1 200
2026-01-09 14:47:59,927 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-09 14:48:00,061 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=15338FFDE91F6F4500FC9921E8716E93; expires=Wed, 03-Feb-2027 12:48:01 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-03 12:48:01.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:48:00,061 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=125E460DBF2840F2898456533703D64F; domain=.bing.com; expires=Sun, 09-Jan-2028 12:48:01 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-09 12:48:01.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:48:00,061 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=31&FORM=PERE2 200
2026-01-09 14:48:00,061 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=31&FORM=PERE2 200
2026-01-09 14:48:00,861 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-09 14:48:00,995 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=15338FFDE91F6F4500FC9921E8716E93; expires=Wed, 03-Feb-2027 12:48:02 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-03 12:48:02.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-09 14:48:00,995 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=AA12A170D5424DE0AF2F22D4ACB8AA81; domain=.bing.com; expires=Sun, 09-Jan-2028 12:48:02 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-09 12:48:02.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-09 14:48:00,995 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=41&FORM=PERE3 200
2026-01-09 14:48:00,996 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+focuses+on+Large+Language+Models%2C+identifying+GPT-4+as+the+current+state-of-the-art+model+in+early+2023.+It+also+mentions+other+significant+contributions+from+Google+with+Bard+and+Meta+with+Llama+1%2C+which+was+released+for+research.+The+chapter+notes+that+the+industry%27s+primary+focus+is+on+expanding+model+scale+and+increasing+parameter+counts+to+enhance+capabilities.+since+early+2023&first=41&FORM=PERE3 200
2026-01-09 14:48:01,043 - researcher - INFO - Searching OpenAlex for: This chapter focuses on Large Language Models, identifying GPT-4 as the current state-of-the-art model in early 2023. It also mentions other significant contributions from Google with Bard and Meta with Llama 1, which was released for research. The chapter notes that the industry's primary focus is on expanding model scale and increasing parameter counts to enhance capabilities.
2026-01-09 14:48:01,045 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-09 14:48:02,620 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20focuses%20on%20Large%20Language%20Models,%20identifying%20GPT-4%20as%20the%20current%20state-of-the-art%20model%20in%20early%202023.%20It%20also%20mentions%20other%20significant%20contributions%20from%20Google%20with%20Bard%20and%20Meta%20with%20Llama%201,%20which%20was%20released%20for%20research.%20The%20chapter%20notes%20that%20the%20industry's%20primary%20focus%20is%20on%20expanding%20model%20scale%20and%20increasing%20parameter%20counts%20to%20enhance%20capabilities.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-11 13:50:43,297 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:50:43,297 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:50:43,298 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:50:43,298 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:50:43,484 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:50:43,484 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:50:43,484 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:50:43,484 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:06,583 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:06,583 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:06,584 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:06,584 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:06,584 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:06,584 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:06,584 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:06,584 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:09,927 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:09,927 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:09,928 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:09,928 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:09,930 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:09,930 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:09,930 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:09,931 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:40,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:40,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:40,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:40,551 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:40,552 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:40,552 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:40,552 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:40,552 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:40,607 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-11 13:55:41,358 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-11 13:55:41,359 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-11 13:55:41,360 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-11 13:55:41,391 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2724D0>
2026-01-11 13:55:41,393 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C6833CADE0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-11 13:55:41,463 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C096910>
2026-01-11 13:55:41,463 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-11 13:55:41,464 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-11 13:55:41,464 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-11 13:55:41,464 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-11 13:55:41,464 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-11 13:55:45,777 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:55:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4303'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-11 13:55:45,777 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-11 13:55:45,777 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-11 13:55:45,778 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-11 13:55:45,778 - httpcore.http11 - DEBUG - response_closed.started
2026-01-11 13:55:45,778 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-11 13:55:45,779 - processor - INFO - Batch analysis successful
2026-01-11 13:55:45,779 - httpcore.connection - DEBUG - close.started
2026-01-11 13:55:45,779 - httpcore.connection - DEBUG - close.complete
2026-01-11 13:55:45,780 - __main__ - INFO - Report structure analysis finalized
2026-01-11 13:55:45,831 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:45,831 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:45,831 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:45,831 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:45,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:45,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:55:45,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:55:45,832 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:34,771 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:34,771 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:34,771 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:34,771 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:34,773 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:34,773 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:34,773 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:34,773 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:36,986 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:36,987 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:36,987 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:36,987 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:36,988 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:36,988 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:36,988 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:36,988 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:37,676 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:37,676 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:37,676 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:37,676 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:37,677 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:37,677 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:37,677 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:37,677 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:38,333 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:38,333 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:38,333 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:38,333 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:38,335 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:38,335 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:38,335 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:38,335 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:39,462 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:39,462 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:39,462 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:39,462 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:39,463 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:39,463 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:39,463 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:39,463 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:41,947 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:41,947 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:41,947 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:41,947 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:41,948 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:41,948 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:41,948 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:41,948 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,789 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,789 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,789 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,790 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,791 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,791 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,791 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,791 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:56:45,852 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:56:45,856 - researcher - INFO - Researching 'The introduction highlights the significant increase in Artificial Intelligence's popularity, largely driven by the release of ChatGPT in late 2022. It sets the scope of the report, stating it will cover the state of the AI industry. The report's analysis is current as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2026-01-11 13:56:45,856 - researcher - INFO - Searching DuckDuckGo for: The introduction highlights the significant increase in Artificial Intelligence's popularity, largely driven by the release of ChatGPT in late 2022. It sets the scope of the report, stating it will cover the state of the AI industry. The report's analysis is current as of mid-2023. (since mid-2023)
2026-01-11 13:56:45,863 - primp.utils - DEBUG - Loaded CA certs
2026-01-11 13:56:45,863 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-11 13:56:45,863 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-11 13:56:45,878 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.171:443
2026-01-11 13:56:45,891 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.171:443
2026-01-11 13:56:45,906 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=173EFECA3EFC698033C0E8143F476893; expires=Fri, 05-Feb-2027 11:56:47 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:56:47.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=3A56A8D3666D6C920848BE0D67D66D4F; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Fri, 05-Feb-2027 11:56:47 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-05 11:56:47.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHD'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUID'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting secure cookie '_SS'
2026-01-11 13:56:46,186 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=5980BAEB2FF7A01A41BAE7BC6C647383~000000000000000000000000000000~YAAQrphmUvnM5iabAQAA4XzqrB73O7EDP/1L0mjtH/XRvBgPltkJaeT9k14ewcLyTUwCEuuACw9NxRn3W2iXeR9yOMUhPbKbWaOadv/IFCWbQ0LOPQuHGa3V0FM58vSq4fVO+gwr49g7NYeqL2t8C1Ctdcw9s+16BCOtcbRNv3WBw4g1cd7JRzQH26AxIVdzGmO/XcXj3/wqjMDq58Qt10/rgOtzrRRF3fucFNSH/mXV7NphoKD2HLqlJOQKhROpaPpdBPkhOoRmRTAscZV/V8yr/jcb+ucIILGcC7IJDlP3R/QMdVrtX2cbzm05XOJwieEF3LBXEucOqbfYe4T3TEmj6HIFSTo7mnZ2Ugz/Q1oYYLOaIxoB/JvjmgxazOSHi8rZI5bIGFb7nS9Q; Domain=.bing.com; Path=/; Expires=Sun, 11 Jan 2026 13:56:46 GMT; Max-Age=7199; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 472), expires: Some(DateTime(2026-01-11 13:56:46.0 +00:00:00)), max_age: Some(Duration { seconds: 7199, nanoseconds: 0 }), domain: Some(Indexed(481, 490)), path: Some(Indexed(497, 498)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:56:46,186 - primp - INFO - response: https://www.bing.com/search?q=The+introduction+highlights+the+significant+increase+in+Artificial+Intelligence%27s+popularity%2C+largely+driven+by+the+release+of+ChatGPT+in+late+2022.+It+sets+the+scope+of+the+report%2C+stating+it+will+cover+the+state+of+the+AI+industry.+The+report%27s+analysis+is+current+as+of+mid-2023.+since+mid-2023 200
2026-01-11 13:56:46,186 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=The+introduction+highlights+the+significant+increase+in+Artificial+Intelligence%27s+popularity%2C+largely+driven+by+the+release+of+ChatGPT+in+late+2022.+It+sets+the+scope+of+the+report%2C+stating+it+will+cover+the+state+of+the+AI+industry.+The+report%27s+analysis+is+current+as+of+mid-2023.+since+mid-2023 200
2026-01-11 13:56:46,321 - researcher - INFO - Searching OpenAlex for: The introduction highlights the significant increase in Artificial Intelligence's popularity, largely driven by the release of ChatGPT in late 2022. It sets the scope of the report, stating it will cover the state of the AI industry. The report's analysis is current as of mid-2023.
2026-01-11 13:56:46,345 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-11 13:56:48,423 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=The%20introduction%20highlights%20the%20significant%20increase%20in%20Artificial%20Intelligence's%20popularity,%20largely%20driven%20by%20the%20release%20of%20ChatGPT%20in%20late%202022.%20It%20sets%20the%20scope%20of%20the%20report,%20stating%20it%20will%20cover%20the%20state%20of%20the%20AI%20industry.%20The%20report's%20analysis%20is%20current%20as%20of%20mid-2023.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-11 13:56:58,429 - updater - INFO - Updating chapter content with research findings
2026-01-11 13:56:58,796 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-11 13:56:58,797 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-11 13:56:58,797 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-11 13:56:58,809 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2F0C50>
2026-01-11 13:56:58,810 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C69C1DA2A0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-11 13:56:58,872 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2F0A90>
2026-01-11 13:56:58,872 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-11 13:56:58,872 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-11 13:56:58,872 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-11 13:56:58,873 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-11 13:56:58,873 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-11 13:57:11,423 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:57:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=12516'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-11 13:57:11,424 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-11 13:57:11,424 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-11 13:57:11,425 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-11 13:57:11,425 - httpcore.http11 - DEBUG - response_closed.started
2026-01-11 13:57:11,425 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-11 13:57:11,426 - updater - INFO - Chapter update successful
2026-01-11 13:57:11,426 - httpcore.connection - DEBUG - close.started
2026-01-11 13:57:11,426 - httpcore.connection - DEBUG - close.complete
2026-01-11 13:57:21,429 - researcher - INFO - Researching 'This chapter discusses the state of Large Language Models, noting that GPT-4 was the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's Llama 1, which was released for research. The primary trend in LLMs is the continuous effort to scale models and increase their parameter counts.' via sources: ['Web Search', 'Academic Papers']
2026-01-11 13:57:21,429 - researcher - INFO - Searching DuckDuckGo for: This chapter discusses the state of Large Language Models, noting that GPT-4 was the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's Llama 1, which was released for research. The primary trend in LLMs is the continuous effort to scale models and increase their parameter counts. (since early 2023)
2026-01-11 13:57:21,430 - primp.utils - DEBUG - Loaded CA certs
2026-01-11 13:57:21,430 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-11 13:57:21,430 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-11 13:57:21,447 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.160:443
2026-01-11 13:57:21,456 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.160:443
2026-01-11 13:57:21,477 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:57:21,754 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-11 13:57:21,754 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=29ADAC9704886B5A1DA5BA4905C46AB2; expires=Fri, 05-Feb-2027 11:57:22 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:57:22.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=0AEE58933EA163C434F74E4D3FED6246; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Fri, 05-Feb-2027 11:57:22 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-05 11:57:22.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHD'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUID'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:57:21,755 - cookie_store.cookie_store - DEBUG - inserting secure cookie '_SS'
2026-01-11 13:57:21,756 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=875D049C45941B0F7D8709CA95DD1BEC~000000000000000000000000000000~YAAQr5hmUnCkESebAQAAtgfrrB4thZOSG3vZeULH42rOUO/iapHFPkB8aKBBF0nKd7O7NS4B2DDsyUP+3TnWug4LQrw8yPnGTlQBfPAqYe4Tv6NrETSN87AhYuhIqnBW4bsaf9ciIS7+AV42Sz9iYj48OzI5PkTSARWkVSrZc+D0r9EivAuDHEl5hIPQ6pjQF/wnHJ9d7BQYm3hTOQGccfWBmV2uXjq6N/zDloK9qqDutBL/6wsR3ldFJMDje/OJgkd+oHol03Nr4tWHNqgnfeuioxIGTw2gzO1mGWzMjnCoNsReB7XYIxsmiRufoDw9r9CQ9/LjfFAQsUEQXa052E3NLbz+MjEHctfe75VY5e6U03+/wYeg1sKUuJ5WMWtVCSbTqCkYQ3JsGtyd; Domain=.bing.com; Path=/; Expires=Sun, 11 Jan 2026 13:57:22 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 472), expires: Some(DateTime(2026-01-11 13:57:22.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(481, 490)), path: Some(Indexed(497, 498)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:21,756 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023 200
2026-01-11 13:57:21,756 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023 200
2026-01-11 13:57:22,603 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:57:22,893 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=29ADAC9704886B5A1DA5BA4905C46AB2; expires=Fri, 05-Feb-2027 11:57:23 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:57:23.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:22,893 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-11 13:57:22,895 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:57:22,895 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'bm_sv'
2026-01-11 13:57:22,895 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=11&FORM=PERE 200
2026-01-11 13:57:22,895 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=11&FORM=PERE 200
2026-01-11 13:57:23,819 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:57:24,104 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=29ADAC9704886B5A1DA5BA4905C46AB2; expires=Fri, 05-Feb-2027 11:57:25 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:57:25.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:24,104 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:57:24,104 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'bm_sv'
2026-01-11 13:57:24,104 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=21&FORM=PERE1 200
2026-01-11 13:57:24,104 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=21&FORM=PERE1 200
2026-01-11 13:57:24,894 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:57:25,189 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=29ADAC9704886B5A1DA5BA4905C46AB2; expires=Fri, 05-Feb-2027 11:57:26 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:57:26.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:25,189 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:57:25,189 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'bm_sv'
2026-01-11 13:57:25,190 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=31&FORM=PERE2 200
2026-01-11 13:57:25,190 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=31&FORM=PERE2 200
2026-01-11 13:57:25,979 - rquest.util.client.pool - DEBUG - reuse idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:57:26,120 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=29ADAC9704886B5A1DA5BA4905C46AB2; expires=Fri, 05-Feb-2027 11:57:27 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:57:27.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:57:26,120 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:57:26,120 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'bm_sv'
2026-01-11 13:57:26,120 - primp - INFO - response: https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=41&FORM=PERE3 200
2026-01-11 13:57:26,120 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=This+chapter+discusses+the+state+of+Large+Language+Models%2C+noting+that+GPT-4+was+the+leading+model+in+early+2023.+It+also+mentions+key+competitors+like+Google%27s+Bard+and+Meta%27s+Llama+1%2C+which+was+released+for+research.+The+primary+trend+in+LLMs+is+the+continuous+effort+to+scale+models+and+increase+their+parameter+counts.+since+early+2023&first=41&FORM=PERE3 200
2026-01-11 13:57:26,333 - researcher - INFO - Searching OpenAlex for: This chapter discusses the state of Large Language Models, noting that GPT-4 was the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's Llama 1, which was released for research. The primary trend in LLMs is the continuous effort to scale models and increase their parameter counts.
2026-01-11 13:57:26,335 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-11 13:57:27,731 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=This%20chapter%20discusses%20the%20state%20of%20Large%20Language%20Models,%20noting%20that%20GPT-4%20was%20the%20leading%20model%20in%20early%202023.%20It%20also%20mentions%20key%20competitors%20like%20Google's%20Bard%20and%20Meta's%20Llama%201,%20which%20was%20released%20for%20research.%20The%20primary%20trend%20in%20LLMs%20is%20the%20continuous%20effort%20to%20scale%20models%20and%20increase%20their%20parameter%20counts.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-11 13:57:37,734 - updater - INFO - Updating chapter content with research findings
2026-01-11 13:57:38,150 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-11 13:57:38,152 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-11 13:57:38,152 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-11 13:57:38,161 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2F10D0>
2026-01-11 13:57:38,161 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C69C1DB6E0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-11 13:57:38,222 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2F1E90>
2026-01-11 13:57:38,222 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-11 13:57:38,222 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-11 13:57:38,223 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-11 13:57:38,223 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-11 13:57:38,223 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-11 13:57:54,568 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:57:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=16335'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-11 13:57:54,568 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-11 13:57:54,568 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-11 13:57:54,569 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-11 13:57:54,569 - httpcore.http11 - DEBUG - response_closed.started
2026-01-11 13:57:54,569 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-11 13:57:54,570 - updater - INFO - Chapter update successful
2026-01-11 13:57:54,570 - httpcore.connection - DEBUG - close.started
2026-01-11 13:57:54,570 - httpcore.connection - DEBUG - close.complete
2026-01-11 13:58:04,572 - researcher - INFO - Researching 'The conclusion emphasizes the rapid evolution of the AI field. It pinpoints 2023 as a pivotal year, marking the commencement of the generative AI era. This highlights a significant shift in AI development and application.' via sources: ['Web Search', 'Academic Papers']
2026-01-11 13:58:04,573 - researcher - INFO - Searching DuckDuckGo for: The conclusion emphasizes the rapid evolution of the AI field. It pinpoints 2023 as a pivotal year, marking the commencement of the generative AI era. This highlights a significant shift in AI development and application. (since 2023)
2026-01-11 13:58:04,573 - primp.utils - DEBUG - Loaded CA certs
2026-01-11 13:58:04,573 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-11 13:58:04,574 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-11 13:58:04,583 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.171:443
2026-01-11 13:58:04,591 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.171:443
2026-01-11 13:58:04,611 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-11 13:58:04,743 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=2508A32D929C6AF30255B5F393636BF2; expires=Fri, 05-Feb-2027 11:58:05 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-05 11:58:05.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=02C5461E9B72695F301450C09A8D68A7; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Fri, 05-Feb-2027 11:58:05 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-05 11:58:05.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHD'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUID'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-11 13:58:04,744 - cookie_store.cookie_store - DEBUG - inserting secure cookie '_SS'
2026-01-11 13:58:04,745 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=EA5ED21F48AFD4BD4CACF2B7FCFDD31F~000000000000000000000000000000~YAAQlphmUn7bbCybAQAAwa/rrB7jO1Athem+dfpRbALc89E71uCxeevYis0tW5nWIvi7/m3NABg/cZE5YUNJsMeVJs8HRmQ4HE/MhZJ79CaesIqZMrQCRcWjl44MxMp+ye1Gr3IxYZV8dzsK01t0CD7BLENi1pVPymEMrtSpdQaZctDdgwtaXXSbdr1TbEmjp1ghwwUPY+otHcGA6DTQO91oa6S3H1moXPqdKG0Wqec81ODoRsAl3rh9pSmxRuqja9mR9VRx+sj0mQdgP46h6Wz9D+5M3A1CHoqRv2v27xuLqFg8kcmox2JvjZBEYSd3ovA/cmP9eXim8zkce0sSJW3pYlqCEmo42OBwx4fdElWSBiGSOC29CeBQqVk2RNNDyEyCoXG8i7+K+0pL; Domain=.bing.com; Path=/; Expires=Sun, 11 Jan 2026 13:58:05 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 472), expires: Some(DateTime(2026-01-11 13:58:05.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(481, 490)), path: Some(Indexed(497, 498)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-11 13:58:04,745 - primp - INFO - response: https://www.bing.com/search?q=The+conclusion+emphasizes+the+rapid+evolution+of+the+AI+field.+It+pinpoints+2023+as+a+pivotal+year%2C+marking+the+commencement+of+the+generative+AI+era.+This+highlights+a+significant+shift+in+AI+development+and+application.+since+2023 200
2026-01-11 13:58:04,745 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=The+conclusion+emphasizes+the+rapid+evolution+of+the+AI+field.+It+pinpoints+2023+as+a+pivotal+year%2C+marking+the+commencement+of+the+generative+AI+era.+This+highlights+a+significant+shift+in+AI+development+and+application.+since+2023 200
2026-01-11 13:58:04,800 - researcher - INFO - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the AI field. It pinpoints 2023 as a pivotal year, marking the commencement of the generative AI era. This highlights a significant shift in AI development and application.
2026-01-11 13:58:04,801 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-11 13:58:05,543 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=The%20conclusion%20emphasizes%20the%20rapid%20evolution%20of%20the%20AI%20field.%20It%20pinpoints%202023%20as%20a%20pivotal%20year,%20marking%20the%20commencement%20of%20the%20generative%20AI%20era.%20This%20highlights%20a%20significant%20shift%20in%20AI%20development%20and%20application.&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-11 13:58:16,065 - updater - INFO - Updating chapter content with research findings
2026-01-11 13:58:16,452 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-11 13:58:16,452 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-11 13:58:16,453 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-11 13:58:16,463 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2DF0D0>
2026-01-11 13:58:16,463 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C69C1DB5C0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-11 13:58:16,524 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C69C2DF090>
2026-01-11 13:58:16,526 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-11 13:58:16,526 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-11 13:58:16,526 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-11 13:58:16,526 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-11 13:58:16,526 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-11 13:58:33,267 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 11 Jan 2026 11:58:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=16731'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-11 13:58:33,268 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-11 13:58:33,268 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-11 13:58:33,268 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-11 13:58:33,268 - httpcore.http11 - DEBUG - response_closed.started
2026-01-11 13:58:33,268 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-11 13:58:33,269 - updater - INFO - Chapter update successful
2026-01-11 13:58:33,270 - httpcore.connection - DEBUG - close.started
2026-01-11 13:58:33,270 - httpcore.connection - DEBUG - close.complete
2026-01-11 13:58:33,370 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:58:33,370 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:58:33,371 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:58:33,371 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:58:33,372 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:58:33,372 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:58:33,372 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 13:58:33,372 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 13:58:33,388 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): eslforums.com:443
2026-01-11 13:58:34,338 - urllib3.connectionpool - DEBUG - https://eslforums.com:443 "GET /conclusion-transition-words/) HTTP/1.1" 301 None
2026-01-11 13:58:34,491 - urllib3.connectionpool - DEBUG - https://eslforums.com:443 "GET /conclusion-transition-words/ HTTP/1.1" 200 None
2026-01-11 13:58:34,493 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-11 13:58:36,127 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/1830762252119687908.html) HTTP/1.1" 404 192
2026-01-11 13:58:36,130 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:36,984 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/272089322) HTTP/1.1" 403 None
2026-01-11 13:58:36,987 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:37,671 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/391626655) HTTP/1.1" 403 None
2026-01-11 13:58:37,674 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:38,447 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/49355121/answer/322451208?utm_oi=1125040691583348736) HTTP/1.1" 403 None
2026-01-11 13:58:38,450 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:39,139 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/1895961661610897493) HTTP/1.1" 403 None
2026-01-11 13:58:39,142 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): forum.wordreference.com:443
2026-01-11 13:58:39,999 - urllib3.connectionpool - DEBUG - https://forum.wordreference.com:443 "GET /threads/im-in-on-at-chapter-8.3336580/) HTTP/1.1" 404 13437
2026-01-11 13:58:40,002 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:40,645 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/500568684) HTTP/1.1" 403 None
2026-01-11 13:58:40,649 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-11 13:58:41,137 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/604927/how-to-use-chapter-in-article-class) HTTP/1.1" 200 None
2026-01-11 13:58:41,141 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): eslforums.com:443
2026-01-11 13:58:42,054 - urllib3.connectionpool - DEBUG - https://eslforums.com:443 "GET /in-conclusion-synonym/) HTTP/1.1" 301 1
2026-01-11 13:58:42,202 - urllib3.connectionpool - DEBUG - https://eslforums.com:443 "GET /in-conclusion-synonym/ HTTP/1.1" 200 None
2026-01-11 13:58:42,207 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): english.stackexchange.com:443
2026-01-11 13:58:42,745 - urllib3.connectionpool - DEBUG - https://english.stackexchange.com:443 "GET /questions/26508/difference-between-introduction-to-and-introduction-of) HTTP/1.1" 200 None
2026-01-11 13:58:42,749 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:43,428 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/551747204) HTTP/1.1" 403 None
2026-01-11 13:58:43,433 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-11 13:58:43,900 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/62516/how-to-suppress-chapter-in-chapter-while-keeping-numbering) HTTP/1.1" 200 None
2026-01-11 13:58:43,903 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:44,568 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/49355121?sort=created) HTTP/1.1" 403 None
2026-01-11 13:58:44,571 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tex.stackexchange.com:443
2026-01-11 13:58:45,024 - urllib3.connectionpool - DEBUG - https://tex.stackexchange.com:443 "GET /questions/585916/use-arabic-chapter-label-for-figure-and-table-if-chapter-use-numberstringchap) HTTP/1.1" 200 None
2026-01-11 13:58:45,026 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:45,668 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/483747578) HTTP/1.1" 403 None
2026-01-11 13:58:45,670 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:46,374 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/606698988) HTTP/1.1" 403 None
2026-01-11 13:58:46,377 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-11 13:58:47,760 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/74405138.html) HTTP/1.1" 404 192
2026-01-11 13:58:47,763 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:48,403 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /question/433988111) HTTP/1.1" 403 None
2026-01-11 13:58:48,405 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): zhidao.baidu.com:443
2026-01-11 13:58:49,963 - urllib3.connectionpool - DEBUG - https://zhidao.baidu.com:443 "GET /question/185721017282382404.html) HTTP/1.1" 404 192
2026-01-11 13:58:49,965 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.zhihu.com:443
2026-01-11 13:58:50,649 - urllib3.connectionpool - DEBUG - https://www.zhihu.com:443 "GET /column/c_1918655957694650107) HTTP/1.1" 403 None
2026-01-11 20:39:47,210 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 20:39:47,212 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 20:39:47,213 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 20:39:47,213 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 20:39:47,215 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 20:39:47,215 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-11 20:39:47,215 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-11 20:39:47,215 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:41,591 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:41,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:41,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:41,592 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:41,768 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:41,768 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:41,768 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:41,768 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:47,641 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:47,641 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:47,641 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:47,641 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:47,642 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:47,644 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:47,644 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:47,644 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:51,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:51,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:51,179 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:51,180 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:51,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:51,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:51,182 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:51,182 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:52,473 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:52,473 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:52,474 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:52,474 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:52,475 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:52,475 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:52,475 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:52,475 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:52,529 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-12 22:22:53,185 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-12 22:22:53,186 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:22:53,187 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:22:53,208 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D9C993C2D0>
2026-01-12 22:22:53,208 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D9C97A0EF0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:22:53,275 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D9B333D090>
2026-01-12 22:22:53,275 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:22:53,275 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:22:53,276 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:22:53,276 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:22:53,276 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:22:57,781 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:22:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4492'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:22:57,781 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:22:57,785 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:22:57,786 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:22:57,786 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:22:57,786 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:22:57,787 - processor - INFO - Batch analysis successful
2026-01-12 22:22:57,787 - httpcore.connection - DEBUG - close.started
2026-01-12 22:22:57,787 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:22:57,789 - __main__ - INFO - Report structure analysis finalized
2026-01-12 22:22:57,844 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:57,844 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:57,844 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:57,844 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:57,845 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:57,845 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:22:57,845 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:22:57,845 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:10,996 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:10,997 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:10,997 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:10,997 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:11,147 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:11,147 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:11,147 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:11,148 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:17,055 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:17,055 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:17,055 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:17,056 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:17,057 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:17,057 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:17,058 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:17,058 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:19,059 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:19,059 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:19,059 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:19,059 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:19,060 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:19,061 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:19,061 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:19,061 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:21,164 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:21,165 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:21,165 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:21,165 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:21,166 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:21,167 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:21,167 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:21,167 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:21,222 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-12 22:27:21,670 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-12 22:27:21,672 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:27:21,673 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:27:21,700 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B4513A610>
2026-01-12 22:27:21,701 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B2B6C20F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:27:21,764 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B45270B90>
2026-01-12 22:27:21,764 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:27:21,765 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:27:21,765 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:27:21,765 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:27:21,765 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:27:26,121 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:27:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4342'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:27:26,122 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:27:26,122 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:27:26,122 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:27:26,122 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:27:26,122 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:27:26,123 - processor - INFO - Batch analysis successful
2026-01-12 22:27:26,123 - httpcore.connection - DEBUG - close.started
2026-01-12 22:27:26,123 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:27:26,125 - __main__ - INFO - Report structure analysis finalized
2026-01-12 22:27:26,189 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:26,189 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:26,190 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:26,190 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:26,192 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:26,192 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:26,192 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:26,192 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,176 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,176 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,176 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,176 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,178 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,178 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,178 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,178 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,252 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,252 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,252 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,252 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,253 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,253 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,254 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:27:58,254 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:27:58,260 - researcher - INFO - Researching 'Artificial Intelligence industry state 2023' (Original: Artificial Intelligence has se...) via sources: ['Web Search', 'Academic Papers']
2026-01-12 22:27:58,261 - researcher - INFO - Searching DuckDuckGo for: Artificial Intelligence industry state 2023 (since mid-2023)
2026-01-12 22:27:58,282 - primp.utils - DEBUG - Loaded CA certs
2026-01-12 22:27:58,292 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-12 22:27:58,294 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-12 22:27:58,305 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.171:443
2026-01-12 22:27:58,316 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.171:443
2026-01-12 22:27:58,340 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-12 22:27:58,510 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-12 22:27:58,510 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=1F0A68621A3E619631C47EBD1B58600D; expires=Sat, 06-Feb-2027 20:27:58 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-06 20:27:58.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:27:58,510 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=2CA98323A83865E6179195FCA95E6490; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:27:58,510 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Sat, 06-Feb-2027 20:27:58 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-06 20:27:58.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:27:58,510 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHD'
2026-01-12 22:27:58,512 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUID'
2026-01-12 22:27:58,512 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-12 22:27:58,512 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-12 22:27:58,512 - cookie_store.cookie_store - DEBUG - inserting secure cookie '_SS'
2026-01-12 22:27:58,512 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=01CF5D4CAED0EEC02A90B69FAA30A418~000000000000000000000000000000~YAAQrphmUggvCyebAQAAD9vksx4jUVl2JwhoRrI257byfCQAWutkMPqhh9gDVrXk2vGIB7ti4hN3Gp928LvdWSmeS756f7DuDuWW8f+qPqw1UvkzSX0vY3dtta2i6mRVyKurqvOxm8ld+jO2Q6MCX3ssL7XsoTPisCXxPxcZm6Xnckj/4mgjK8TrKuhOYSMPVw74c3nRSQ/e4sud2L5OwIy/2FhJN7B6p9GqQHJPs9P83S2wT+/PL3Lhd4TtBOuGT0UxaWihkgdqSxFFIYuJuPbyQFAabZXJEnmwKVmaj1cfhbWUnop4a92mBFyFVQ+tTTEtqcU6tidHwntoh72TIXPLVzhisQoPOkN5dnxZLi88unveAfFAK0c0fnsemiDivCbHZgOXNjDx0X5C; Domain=.bing.com; Path=/; Expires=Mon, 12 Jan 2026 22:27:58 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 472), expires: Some(DateTime(2026-01-12 22:27:58.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(481, 490)), path: Some(Indexed(497, 498)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:27:58,512 - primp - INFO - response: https://www.bing.com/search?q=Artificial+Intelligence+industry+state+2023+mid-2023 200
2026-01-12 22:27:58,512 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Artificial+Intelligence+industry+state+2023+mid-2023 200
2026-01-12 22:27:58,575 - researcher - INFO - Searching OpenAlex for: Artificial Intelligence industry state 2023
2026-01-12 22:27:58,595 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-12 22:28:00,218 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Artificial%20Intelligence%20industry%20state%202023&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-12 22:28:01,378 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:01,378 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:28:01,390 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B456FFE10>
2026-01-12 22:28:01,390 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B456B5D90> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:28:01,458 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B454ADED0>
2026-01-12 22:28:01,458 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:01,460 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:01,460 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:01,460 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:01,460 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:04,294 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2822'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:04,295 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:28:04,295 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:04,296 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:04,296 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:04,296 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:04,296 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:04,298 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:04,298 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:04,298 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:04,298 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:04,298 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:07,806 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:07 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3499'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:07,807 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:28:07,807 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:07,808 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:07,808 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:07,808 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:07,808 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:07,810 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:07,811 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:07,811 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:07,811 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:07,811 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:12,580 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4760'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:12,580 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:28:12,581 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:12,581 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:12,581 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:12,581 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:12,582 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:12,583 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:12,583 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:12,583 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:12,583 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:12,583 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:16,975 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4382'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:16,975 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:28:16,976 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:16,976 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:16,976 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:16,976 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:16,977 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:16,977 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:16,977 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:16,978 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:16,978 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:16,978 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:19,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2970'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:19,986 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:28:19,986 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:19,987 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:19,987 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:19,987 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:19,988 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:19,988 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:19,988 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:19,988 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:19,989 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:19,989 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:23,315 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3293'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:23,315 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:28:23,315 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:23,315 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:23,317 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:23,317 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:23,317 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:23,318 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:23,318 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:23,318 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:23,318 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:23,318 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:23,418 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=89'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:23,419 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-12 22:28:23,419 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:23,420 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:23,420 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:23,420 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:23,421 - researcher - ERROR - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 36.522424013s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}
2026-01-12 22:28:33,421 - updater - INFO - Updating chapter content with research findings
2026-01-12 22:28:33,834 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-12 22:28:33,834 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:33,835 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:28:33,846 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B45726A50>
2026-01-12 22:28:33,846 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B456B6210> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:28:33,919 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B45726A10>
2026-01-12 22:28:33,919 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:33,919 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:33,920 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:33,920 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:33,920 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:34,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=96'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:34,038 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-12 22:28:34,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:34,038 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:34,039 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:34,039 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:34,040 - updater - ERROR - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 25.908607177s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}
2026-01-12 22:28:34,041 - updater - ERROR - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 25.908607177s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 57, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 25.908607177s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}
2026-01-12 22:28:44,144 - researcher - INFO - Researching 'Large Language Models state early 2023' (Original: As of early 2023, GPT-4 is con...) via sources: ['Web Search', 'Academic Papers']
2026-01-12 22:28:44,144 - researcher - INFO - Searching DuckDuckGo for: Large Language Models state early 2023 (since early 2023)
2026-01-12 22:28:44,144 - primp.utils - DEBUG - Loaded CA certs
2026-01-12 22:28:44,145 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-12 22:28:44,145 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-12 22:28:44,154 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.179:443
2026-01-12 22:28:44,173 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.179:443
2026-01-12 22:28:44,188 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-12 22:28:44,322 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=3C7CBF849E966456066CA95B9F826568; expires=Sat, 06-Feb-2027 20:28:44 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-06 20:28:44.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=1922A9C63F5167AE326DBF193E45667A; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Sat, 06-Feb-2027 20:28:44 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-06 20:28:44.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHD=AF=NOFORM; domain=.bing.com; expires=Wed, 12-Jan-2028 20:28:44 GMT; path=/"), name: Indexed(0, 5), value: Indexed(6, 15), expires: Some(DateTime(2028-01-12 20:28:44.0 +00:00:00)), max_age: None, domain: Some(Indexed(24, 33)), path: Some(Indexed(79, 80)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUID=V=2&GUID=81C12EB34C144D92957F55CC984CE1DD&dmnchg=1; domain=.bing.com; expires=Wed, 12-Jan-2028 20:28:44 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 58), expires: Some(DateTime(2028-01-12 20:28:44.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHUSR=DOB=20260112; domain=.bing.com; expires=Wed, 12-Jan-2028 20:28:44 GMT; path=/"), name: Indexed(0, 7), value: Indexed(8, 20), expires: Some(DateTime(2028-01-12 20:28:44.0 +00:00:00)), max_age: None, domain: Some(Indexed(29, 38)), path: Some(Indexed(84, 85)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("SRCHHPGUSR=SRCHLANG=en&IG=9EABF63C4E8C4E32B838AAB9686B06D5; domain=.bing.com; expires=Wed, 12-Jan-2028 20:28:44 GMT; path=/"), name: Indexed(0, 10), value: Indexed(11, 58), expires: Some(DateTime(2028-01-12 20:28:44.0 +00:00:00)), max_age: None, domain: Some(Indexed(67, 76)), path: Some(Indexed(122, 123)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-12 22:28:44,323 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_SS=SID=1922A9C63F5167AE326DBF193E45667A; domain=.bing.com; path=/"), name: Indexed(0, 3), value: Indexed(4, 40), expires: None, max_age: None, domain: Some(Indexed(49, 58)), path: Some(Indexed(65, 66)), secure: None, http_only: None, same_site: None, partitioned: None }'
2026-01-12 22:28:44,324 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=AEEFF8F6C36F119260FED7CFEEB371BE~000000000000000000000000000000~YAAQtZhmUvqXfSubAQAA/43lsx55vVu640SqJKUgmkqZFqsitRPi5xIUG9awXS6a2rN3hNdsGAs0eQyrRkm9LEyptMsYuvlKEerfosszdcek2uQSaRH/E2xTA+pQbhcT3N+wpK6F3Oit2m2mHEpDddUHBojBKyPRE7LuSYjw8amvd6f2TJhAqpTZIlZ9omzUF08BwYnwH0mIX9GSzM5qKvx6M/MWlHk81stX+N+CKlu1LnMO1R5F2JVmUUkLDd8B59VX0eWrYYLyoXfYeZ5HHAyVgdNB+2dhafE7lQH1iosniJ6g24r49+SjKDw00iWXnnTk2DJitxw9yG32X7bymnbefbL6CyxhUCdf4Uy0A+a/Zlifa0sJdun0xi49xqHJNWu71P6Fai+xxWm5; Domain=.bing.com; Path=/; Expires=Mon, 12 Jan 2026 22:28:44 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 472), expires: Some(DateTime(2026-01-12 22:28:44.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(481, 490)), path: Some(Indexed(497, 498)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:28:44,324 - primp - INFO - response: https://www.bing.com/search?q=Large+Language+Models+state+early+2023+early+2023 200
2026-01-12 22:28:44,324 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Large+Language+Models+state+early+2023+early+2023 200
2026-01-12 22:28:44,365 - researcher - INFO - Searching OpenAlex for: Large Language Models state early 2023
2026-01-12 22:28:44,367 - httpcore.connection - DEBUG - close.started
2026-01-12 22:28:44,368 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:28:44,370 - httpcore.connection - DEBUG - close.started
2026-01-12 22:28:44,370 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:28:44,375 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-12 22:28:45,677 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Large%20Language%20Models%20state%20early%202023&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-12 22:28:46,698 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:46,698 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:28:46,711 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B4567F5D0>
2026-01-12 22:28:46,712 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B454E7F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:28:46,786 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B4567F510>
2026-01-12 22:28:46,786 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:46,786 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:46,787 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:46,787 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:46,787 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:28:46,890 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:28:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=93'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:28:46,890 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-12 22:28:46,890 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:28:46,891 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:28:46,891 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:28:46,891 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:28:46,891 - researcher - ERROR - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 13.050281718s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-12 22:28:54,870 - httpcore.connection - DEBUG - close.started
2026-01-12 22:28:54,871 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:28:56,892 - updater - INFO - Updating chapter content with research findings
2026-01-12 22:28:57,312 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-12 22:28:57,312 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:28:57,312 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:28:57,323 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B45586BD0>
2026-01-12 22:28:57,323 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B456B5BE0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:28:57,384 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B45585390>
2026-01-12 22:28:57,384 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:28:57,385 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:28:57,385 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:28:57,386 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:28:57,386 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:04,199 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=6799'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:04,199 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:29:04,199 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:04,199 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:04,199 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:04,199 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:04,200 - updater - INFO - Chapter update successful
2026-01-12 22:29:04,200 - httpcore.connection - DEBUG - close.started
2026-01-12 22:29:04,200 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:29:14,203 - researcher - INFO - Researching 'Generative AI era 2023 impact' (Original: The field of Artificial Intell...) via sources: ['Web Search', 'Academic Papers']
2026-01-12 22:29:14,204 - researcher - INFO - Searching DuckDuckGo for: Generative AI era 2023 impact (since 2023)
2026-01-12 22:29:14,204 - primp.utils - DEBUG - Loaded CA certs
2026-01-12 22:29:14,204 - rquest.connect - DEBUG - starting new connection: https://www.bing.com/
2026-01-12 22:29:14,205 - rquest.util.client.connect.dns - DEBUG - resolving www.bing.com
2026-01-12 22:29:14,211 - rquest.util.client.connect.http - DEBUG - connecting to 82.102.152.187:443
2026-01-12 22:29:14,219 - rquest.util.client.connect.http - DEBUG - connected to 82.102.152.187:443
2026-01-12 22:29:14,234 - rquest.util.client.pool - DEBUG - pooling idle connection for PoolKey { uri: https://www.bing.com/, alpn_protos: None, network: default }
2026-01-12 22:29:14,381 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'MUID'
2026-01-12 22:29:14,381 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("MUIDB=30CE0595038A67A12C94134A025466D9; expires=Sat, 06-Feb-2027 20:29:14 GMT; path=/; HttpOnly"), name: Indexed(0, 5), value: Indexed(6, 38), expires: Some(DateTime(2027-02-06 20:29:14.0 +00:00:00)), max_age: None, domain: None, path: Some(Indexed(84, 85)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:29:14,381 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_S=F=1&SID=293E12B41B30624A01E2046B1AEE63B7; domain=.bing.com; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 48), expires: None, max_age: None, domain: Some(Indexed(57, 66)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:29:14,381 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("_EDGE_V=1; domain=.bing.com; expires=Sat, 06-Feb-2027 20:29:14 GMT; path=/; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 9), expires: Some(DateTime(2027-02-06 20:29:14.0 +00:00:00)), max_age: None, domain: Some(Indexed(18, 27)), path: Some(Indexed(73, 74)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:29:14,382 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHD'
2026-01-12 22:29:14,382 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUID'
2026-01-12 22:29:14,382 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHUSR'
2026-01-12 22:29:14,382 - cookie_store.cookie_store - DEBUG - inserting secure cookie 'SRCHHPGUSR'
2026-01-12 22:29:14,382 - cookie_store.cookie_store - DEBUG - inserting secure cookie '_SS'
2026-01-12 22:29:14,382 - cookie_store.cookie_store - DEBUG - inserting Set-Cookie 'Cookie { cookie_string: Some("ak_bmsc=C8676761BF708EABCCB0F3F7742ED519~000000000000000000000000000000~YAAQnZhmUv0LCCObAQAAbwPmsx4MwxYimRx+jg5GAO+fK9v/KRDnvS6bdlWmPVKFsib3NoWXRgqG9o+4eZ1r1sMcZMi/x7udYWL5xaKw9sXqxnMyt4Yd29HYU9z2PVMvuEDXV/jmGuQucR71VQP+KLC4Tq+J2jiMPtFLEU/gSpgt5J/rXJUDh/BUvgB660IDwt2oJgHRSncaXNVfSR3XnVUUh51yieQUT+z05KTtqW1dbr4uNANU1G82gIotn/wX7WsFH3q6dVE2yaecjlJ1pDoj/qtEn8sUFTENtS9Q+cUoBvQlg9C42TmxBEA922HX2uu0nW4S3HUbroTZuvEqEAz7fM6sa1WlorvArvu/vno/DKxUhkpwOD+9baXYANbBlDE6b9qxWwRMytW0; Domain=.bing.com; Path=/; Expires=Mon, 12 Jan 2026 22:29:14 GMT; Max-Age=7200; HttpOnly"), name: Indexed(0, 7), value: Indexed(8, 472), expires: Some(DateTime(2026-01-12 22:29:14.0 +00:00:00)), max_age: Some(Duration { seconds: 7200, nanoseconds: 0 }), domain: Some(Indexed(481, 490)), path: Some(Indexed(497, 498)), secure: None, http_only: Some(true), same_site: None, partitioned: None }'
2026-01-12 22:29:14,382 - primp - INFO - response: https://www.bing.com/search?q=Generative+AI+era+2023+impact+2023 200
2026-01-12 22:29:14,383 - duckduckgo_search.DDGS - DEBUG - _get_url() https://www.bing.com/search?q=Generative+AI+era+2023+impact+2023 200
2026-01-12 22:29:14,423 - researcher - INFO - Searching OpenAlex for: Generative AI era 2023 impact
2026-01-12 22:29:14,424 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.openalex.org:443
2026-01-12 22:29:15,540 - urllib3.connectionpool - DEBUG - https://api.openalex.org:443 "GET /works?search=Generative%20AI%20era%202023%20impact&per_page=10&mailto=your-email@example.com HTTP/1.1" 200 None
2026-01-12 22:29:16,568 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:29:16,569 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:29:16,578 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B456BA650>
2026-01-12 22:29:16,578 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B455897F0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:29:16,644 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B456BA610>
2026-01-12 22:29:16,644 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:29:16,644 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:29:16,645 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:29:16,645 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:29:16,645 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:19,651 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2994'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:19,651 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:29:19,652 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:19,652 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:19,652 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:19,652 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:19,653 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:29:19,654 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:29:19,654 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:29:19,654 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:29:19,654 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:29:19,654 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:22,978 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3314'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:22,978 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:29:22,979 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:22,979 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:22,979 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:22,979 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:22,980 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:29:22,980 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:29:22,981 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:29:22,981 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:29:22,981 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:29:22,982 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:25,416 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2426'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:25,417 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:29:25,417 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:25,417 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:25,417 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:25,418 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:25,418 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:29:25,419 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:29:25,419 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:29:25,419 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:29:25,419 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:29:25,419 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:27,081 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:27 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1652'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:27,081 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:29:27,081 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:27,082 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:27,082 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:27,082 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:27,083 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:29:27,083 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:29:27,083 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:29:27,083 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:29:27,084 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:29:27,084 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:29,630 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2536'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:29,630 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2026-01-12 22:29:29,630 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:29,631 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:29,631 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:29,631 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:29,633 - httpcore.connection - DEBUG - close.started
2026-01-12 22:29:29,633 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:29:39,635 - updater - INFO - Updating chapter content with research findings
2026-01-12 22:29:40,029 - updater - DEBUG - Sending writing prompt to gemini-2.5-flash
2026-01-12 22:29:40,030 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2026-01-12 22:29:40,030 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2026-01-12 22:29:40,086 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B4569B690>
2026-01-12 22:29:40,086 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022B454E6BA0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-12 22:29:40,153 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022B4569B6D0>
2026-01-12 22:29:40,153 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2026-01-12 22:29:40,153 - httpcore.http11 - DEBUG - send_request_headers.complete
2026-01-12 22:29:40,153 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2026-01-12 22:29:40,153 - httpcore.http11 - DEBUG - send_request_body.complete
2026-01-12 22:29:40,153 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2026-01-12 22:29:40,260 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Mon, 12 Jan 2026 20:29:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=95'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-12 22:29:40,261 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2026-01-12 22:29:40,261 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2026-01-12 22:29:40,261 - httpcore.http11 - DEBUG - receive_response_body.complete
2026-01-12 22:29:40,261 - httpcore.http11 - DEBUG - response_closed.started
2026-01-12 22:29:40,261 - httpcore.http11 - DEBUG - response_closed.complete
2026-01-12 22:29:40,262 - updater - ERROR - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 19.674941168s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}
2026-01-12 22:29:40,262 - updater - ERROR - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 19.674941168s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\updater.py", line 57, in update_chapter
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "F:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 19.674941168s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}
2026-01-12 22:29:40,315 - httpcore.connection - DEBUG - close.started
2026-01-12 22:29:40,316 - httpcore.connection - DEBUG - close.complete
2026-01-12 22:29:40,349 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:29:40,349 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:29:40,349 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:29:40,349 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:29:40,350 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:29:40,350 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:29:40,350 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2026-01-12 22:29:40,351 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 12203
2026-01-12 22:29:40,364 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:40,827 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.28991/esj-2023-07-04-025 HTTP/1.1" 302 None
2026-01-12 22:29:40,828 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.ijournalse.org:443
2026-01-12 22:29:41,569 - urllib3.connectionpool - DEBUG - https://www.ijournalse.org:443 "GET /index.php/ESJ/article/view/1868 HTTP/1.1" 200 None
2026-01-12 22:29:41,571 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): tecnobits.com:443
2026-01-12 22:29:41,948 - urllib3.connectionpool - DEBUG - https://tecnobits.com:443 "GET /uk/ HTTP/1.1" 200 None
2026-01-12 22:29:41,953 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:42,534 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.1371/journal.pdig.0000198 HTTP/1.1" 302 None
2026-01-12 22:29:42,536 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): dx.plos.org:443
2026-01-12 22:29:42,925 - urllib3.connectionpool - DEBUG - https://dx.plos.org:443 "GET /10.1371/journal.pdig.0000198 HTTP/1.1" 301 338
2026-01-12 22:29:42,927 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): journals.plos.org:443
2026-01-12 22:29:43,369 - urllib3.connectionpool - DEBUG - https://journals.plos.org:443 "GET /plosone/doi?id=10.1371/journal.pdig.0000198 HTTP/1.1" 301 0
2026-01-12 22:29:43,625 - urllib3.connectionpool - DEBUG - https://journals.plos.org:443 "GET /digitalhealth/article?id=10.1371/journal.pdig.0000198 HTTP/1.1" 200 None
2026-01-12 22:29:43,629 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai.dev:443
2026-01-12 22:29:44,085 - urllib3.connectionpool - DEBUG - https://ai.dev:443 "GET /rate-limit HTTP/1.1" 301 235
2026-01-12 22:29:44,087 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): aistudio.google.com:443
2026-01-12 22:29:44,743 - urllib3.connectionpool - DEBUG - https://aistudio.google.com:443 "GET /rate-limit HTTP/1.1" 302 0
2026-01-12 22:29:44,746 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): accounts.google.com:443
2026-01-12 22:29:45,224 - urllib3.connectionpool - DEBUG - https://accounts.google.com:443 "GET /ServiceLogin?passive=1209600&continue=https://aistudio.google.com/rate-limit&followup=https://aistudio.google.com/rate-limit HTTP/1.1" 302 0
2026-01-12 22:29:45,305 - urllib3.connectionpool - DEBUG - https://accounts.google.com:443 "GET /InteractiveLogin?continue=https://aistudio.google.com/rate-limit&followup=https://aistudio.google.com/rate-limit&passive=1209600&dsh=S-1425954644:1768249785296630&ifkv=AXbMIuD4vNDv64qHWzmJ8egfkojaceFi3EJMjZvjs-jlFiFBNHTPsctwd3iIwjZnkZNNuqrtoNUwlQ HTTP/1.1" 302 None
2026-01-12 22:29:45,444 - urllib3.connectionpool - DEBUG - https://accounts.google.com:443 "GET /v3/signin/identifier?continue=https%3A%2F%2Faistudio.google.com%2Frate-limit&dsh=S-1425954644%3A1768249785296630&followup=https%3A%2F%2Faistudio.google.com%2Frate-limit&ifkv=AXbMIuAvx6ehKHwCvcZTkQ4flPFZZnOfrSNnh1mcvsyEBF4K_2LarXBC1TRwT2fX5wz3SeK3nTVecg&passive=1209600&flowName=GlifWebSignIn&flowEntry=ServiceLogin HTTP/1.1" 200 None
2026-01-12 22:29:45,446 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:45,850 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.61969/jai.1337500 HTTP/1.1" 302 None
2026-01-12 22:29:45,851 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): dergipark.org.tr:443
2026-01-12 22:29:46,620 - urllib3.connectionpool - DEBUG - https://dergipark.org.tr:443 "GET /en/doi/10.61969/jai.1337500 HTTP/1.1" 302 354
2026-01-12 22:29:46,825 - urllib3.connectionpool - DEBUG - https://dergipark.org.tr:443 "GET /en/pub/jai/article/1337500 HTTP/1.1" 200 None
2026-01-12 22:29:46,826 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): apps.microsoft.com:443
2026-01-12 22:29:47,329 - urllib3.connectionpool - DEBUG - https://apps.microsoft.com:443 "GET /detail/9plfnlnt3g5g HTTP/1.1" 302 0
2026-01-12 22:29:47,802 - urllib3.connectionpool - DEBUG - https://apps.microsoft.com:443 "GET /detail/9plfnlnt3g5g?hl=en-US&gl=IL HTTP/1.1" 200 None
2026-01-12 22:29:47,804 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.intel.com:443
2026-01-12 22:29:48,188 - urllib3.connectionpool - DEBUG - https://www.intel.com:443 "GET /content/www/us/en/support/articles/000055840/graphics/processor-graphics.html HTTP/1.1" 403 484
2026-01-12 22:29:48,190 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:48,531 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.3390/su151712983 HTTP/1.1" 302 None
2026-01-12 22:29:48,533 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.mdpi.com:443
2026-01-12 22:29:48,986 - urllib3.connectionpool - DEBUG - https://www.mdpi.com:443 "GET /2071-1050/15/17/12983 HTTP/1.1" 403 401
2026-01-12 22:29:48,988 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:49,302 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.1007/s44163-023-00089-x HTTP/1.1" 302 None
2026-01-12 22:29:49,303 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): link.springer.com:443
2026-01-12 22:29:49,787 - urllib3.connectionpool - DEBUG - https://link.springer.com:443 "GET /10.1007/s44163-023-00089-x HTTP/1.1" 301 166
2026-01-12 22:29:50,046 - urllib3.connectionpool - DEBUG - https://link.springer.com:443 "GET /article/10.1007/s44163-023-00089-x HTTP/1.1" 303 0
2026-01-12 22:29:50,050 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): idp.springer.com:443
2026-01-12 22:29:50,503 - urllib3.connectionpool - DEBUG - https://idp.springer.com:443 "GET /authorize?response_type=cookie&client_id=springerlink&redirect_uri=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs44163-023-00089-x HTTP/1.1" 302 0
2026-01-12 22:29:50,944 - urllib3.connectionpool - DEBUG - https://link.springer.com:443 "GET /article/10.1007/s44163-023-00089-x HTTP/1.1" 200 None
2026-01-12 22:29:50,948 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:51,444 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.3390/educsci13040410 HTTP/1.1" 302 None
2026-01-12 22:29:51,445 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.mdpi.com:443
2026-01-12 22:29:51,930 - urllib3.connectionpool - DEBUG - https://www.mdpi.com:443 "GET /2227-7102/13/4/410 HTTP/1.1" 403 400
2026-01-12 22:29:51,932 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai.google.dev:443
2026-01-12 22:29:52,474 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /gemini-api/docs/rate-limits' HTTP/1.1" 302 None
2026-01-12 22:29:52,824 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /oauth2authorize?return_url=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Frate-limits%26%2339%3B&prompt=none&auto_signin=True&scopes=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles.award+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevprofiles.full_control.firstparty HTTP/1.1" 302 None
2026-01-12 22:29:52,827 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): accounts.google.com:443
2026-01-12 22:29:53,287 - urllib3.connectionpool - DEBUG - https://accounts.google.com:443 "GET /o/oauth2/v2/auth?client_id=157101835696-ooapojlodmuabs2do2vuhhnf90bccmoi.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fai.google.dev%2Foauth2callback&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.profile+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgoogledevelopers+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles.award+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevprofiles.full_control.firstparty&access_type=online&response_type=code&state=%7B%22csrf_token%22%3A+%22ed527040b185e9f4ab78ce5ebb5179df04550dfa3fb94ae089c5af8ce106c6b8%22%2C+%22return_url%22%3A+%22https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Frate-limits%26%2339%3B%22%7D&prompt=none&auto_signin=True HTTP/1.1" 302 None
2026-01-12 22:29:53,510 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /oauth2callback?state=%7B%22csrf_token%22%3A+%22ed527040b185e9f4ab78ce5ebb5179df04550dfa3fb94ae089c5af8ce106c6b8%22%2C+%22return_url%22%3A+%22https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Frate-limits%26%2339%3B%22%7D&error_subtype=access_denied&error=interaction_required HTTP/1.1" 302 None
2026-01-12 22:29:53,888 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /gemini-api/docs/rate-limits& HTTP/1.1" 404 None
2026-01-12 22:29:53,892 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.artificialaiming.net:443
2026-01-12 22:29:54,524 - urllib3.connectionpool - DEBUG - https://www.artificialaiming.net:443 "GET /forum/index.php HTTP/1.1" 200 None
2026-01-12 22:29:54,526 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): doi.org:443
2026-01-12 22:29:54,854 - urllib3.connectionpool - DEBUG - https://doi.org:443 "GET /10.3390/healthcare11060887 HTTP/1.1" 302 None
2026-01-12 22:29:54,855 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.mdpi.com:443
2026-01-12 22:29:56,015 - urllib3.connectionpool - DEBUG - https://www.mdpi.com:443 "GET /2227-9032/11/6/887 HTTP/1.1" 403 400
2026-01-12 22:29:56,017 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): ai.google.dev:443
2026-01-12 22:29:56,733 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /gemini-api/docs/rate-limits HTTP/1.1" 302 None
2026-01-12 22:29:56,955 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /oauth2authorize?return_url=https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Frate-limits&prompt=none&auto_signin=True&scopes=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles.award+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevprofiles.full_control.firstparty HTTP/1.1" 302 None
2026-01-12 22:29:56,957 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): accounts.google.com:443
2026-01-12 22:29:57,406 - urllib3.connectionpool - DEBUG - https://accounts.google.com:443 "GET /o/oauth2/v2/auth?client_id=157101835696-ooapojlodmuabs2do2vuhhnf90bccmoi.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fai.google.dev%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgoogledevelopers+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdeveloperprofiles.award+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevprofiles.full_control.firstparty+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.profile&access_type=online&response_type=code&state=%7B%22csrf_token%22%3A+%22c51e0c217f483301e623ac7dbd78fdc5478cad7abf68d1597d8aa9ffce8ccd36%22%2C+%22return_url%22%3A+%22https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Frate-limits%22%7D&prompt=none&auto_signin=True HTTP/1.1" 302 None
2026-01-12 22:29:57,689 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /oauth2callback?state=%7B%22csrf_token%22%3A+%22c51e0c217f483301e623ac7dbd78fdc5478cad7abf68d1597d8aa9ffce8ccd36%22%2C+%22return_url%22%3A+%22https%3A%2F%2Fai.google.dev%2Fgemini-api%2Fdocs%2Frate-limits%22%7D&error_subtype=access_denied&error=interaction_required HTTP/1.1" 302 None
2026-01-12 22:29:58,043 - urllib3.connectionpool - DEBUG - https://ai.google.dev:443 "GET /gemini-api/docs/rate-limits HTTP/1.1" 200 None
2026-01-12 22:29:58,049 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.techspot.com:443
2026-01-12 22:29:58,384 - urllib3.connectionpool - DEBUG - https://www.techspot.com:443 "GET /downloads/7234-intel-graphics-command-center.html HTTP/1.1" 403 None
2026-01-12 22:29:58,385 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): www.softpedia.com:443
2026-01-12 22:29:58,712 - urllib3.connectionpool - DEBUG - https://www.softpedia.com:443 "GET /get/Tweak/Video-Tweak/Intel-Graphics-Command-Center.shtml HTTP/1.1" 403 None
