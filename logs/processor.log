2025-12-23 20:43:25.330 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:43:25.331 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:43:31.996 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:43:31.997 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:43:31.997 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:43:40.354 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Late 2022 - Mid-2023)
2025-12-23 20:43:40.354 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter introduces the significant rise in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It sets the stage for the report by summarizing the overall state of the AI industry. The report aims to cover the industry's landscape as of mid-2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.642 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: This chapter introduces the significant rise in AI's popularity, primarily driven by the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000188039D7AD0>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803A1FAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23380>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A23F60>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter introduces...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803953100>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:214 - Error processing Introduction: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.750 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:40.767 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter focuses on the advancements in Large ...' (Timeframe: Early 2023)
2025-12-23 20:43:40.768 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.040 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter focuses on the advancements in Large Language Models (LLMs) as of early 2023. GPT-4 is identified as the leading model, with other major players like Google and Meta also releasing significant models such as Bard and Llama 1. The current trend in LLM development is primarily centered on achieving greater scale and increasing parameter counts.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.042 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter focuses on the advancements in Large Language Models (LLMs) as of early 202...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803A29C90>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AAAB90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93380>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter focuses on...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A92200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.060 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.076 | INFO     | researcher:perform_research:26 - Performing research on topic: 'The chapter discusses the critical role of AI hard...' (Timeframe: 2023 (demand, expansion); 2020-2022 (energy concerns))
2025-12-23 20:43:41.077 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:45 - Research failed for topic 'The chapter discusses the critical role of AI hardware, specifically highlighting the high demand for NVIDIA's H100 GPUs. It notes the rapid expansion of datacenters throughout 2023 to accommodate the intensive training requirements of large AI models. Concerns regarding energy consumption are mentioned, with data primarily drawn from the 2020-2022 period.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.333 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ "\n    Research the following topic: The chapter discusses the critical role of AI hardware, specifically highlighting the hi...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB2950>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA5150>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8C20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8B80>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: The chapter discusses t...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A93740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.355 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.371 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This chapter addresses the global efforts and disc...' (Timeframe: June 2023)
2025-12-23 20:43:41.371 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:41.917 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This chapter addresses the global efforts and discussions surrounding AI regulation. It mentions the ongoing development of the AI Act in Europe. In the United States, initial hearings on AI safety have commenced, but no substantial federal legislation has been enacted as of June 2023.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.918 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This chapter addresses the global efforts and discussions surrounding AI regulation. It ...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AACD50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803AA9550>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A922A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A923E0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This chapter addresses ...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803A932E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.938 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:41.953 | INFO     | researcher:perform_research:26 - Performing research on topic: 'This concluding chapter emphasizes the rapid and d...' (Timeframe: 2023)
2025-12-23 20:43:41.954 | DEBUG    | researcher:perform_research:40 - Sending research prompt to gemini-2.5-flash
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:45 - Research failed for topic 'This concluding chapter emphasizes the rapid and dynamic pace of advancements within the AI field. It posits that 2023 serves as a pivotal year, marking the official commencement of the generative AI era.': 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.204 | ERROR    | researcher:perform_research:46 - 400 google_search_retrieval is not supported. Please use google_search tool instead.
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

> File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 41, in perform_research
    response = model.generate_content(prompt)
               │     │                └ '\n    Research the following topic: This concluding chapter emphasizes the rapid and dynamic pace of advancements within the...
               │     └ <function GenerativeModel.generate_content at 0x0000018803800B80>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
               │    │       └ <function GenerativeServiceClient.generate_content at 0x00000188030D5EE0>
               │    └ <google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000018803AB4D50>
               └ genai.GenerativeModel(
                     model_name='models/gemini-2.5-flash',
                     generation_config={},
                     safety_settings={},
                     tools=...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
               └ <google.api_core.gapic_v1.method._GapicCallable object at 0x0000018803ACEE10>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
           │             │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │             └ (model: "models/gemini-2.5-flash"
           │               contents {
           │                 parts {
           │                   text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA660>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
           └ <function retry_target at 0x0000018801AA5300>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
                 └ <function _retry_error_helper at 0x0000018801AA4AE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
          │              └ None
          └ InvalidArgument('google_search_retrieval is not supported. Please use google_search tool instead.')
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
             └ functools.partial(<function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803ACA5C0>, model: "models/gemini...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
           │     │       └ {'metadata': [('x-goog-request-params', 'model=models/gemini-2.5-flash'), ('x-goog-api-client', 'genai-py/0.8.6 gl-python/3.1...
           │     └ (model: "models/gemini-2.5-flash"
           │       contents {
           │         parts {
           │           text: "\n    Research the following topic: This concluding chapter...
           └ <function _wrap_unary_errors.<locals>.error_remapped_callable at 0x0000018803AC8EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
          │          └ <function from_grpc_error at 0x0000018801895F80>
          └ <module 'google.api_core.exceptions' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\api_core...

google.api_core.exceptions.InvalidArgument: 400 google_search_retrieval is not supported. Please use google_search tool instead.
2025-12-23 20:43:42.222 | ERROR    | __main__:<module>:214 - Error processing Conclusion: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:43:42.223 | ERROR    | __main__:<module>:215 - cannot access local variable 'response' where it is not associated with a value
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000187FF0ABEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000187FF0F0220>
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29716)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29716)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000187FFC414E0>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x00000187FFD5A340>
    └ ScriptRunner(_session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _main_script_path='app.py', _session_state={$$ID-4a06878fe03...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='8f81ec74-df1b-41fa-a421-3dd28eb6a9ca', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
        └ <function exec_func_with_error_handling at 0x00000187FFCE0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000188039536A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000187FCF24B50, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000188010C3190>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x00000188038A3240>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 52, in perform_research
    if hasattr(response, 'candidates') and response.candidates:

UnboundLocalError: cannot access local variable 'response' where it is not associated with a value
2025-12-23 20:57:39.388 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 5 chapters
2025-12-23 20:57:39.389 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:57:45.386 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:57:45.386 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:57:45.386 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:57:48.836 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the significant surge in A...' (Timeframe: Late 2022, mid-2023)
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.838 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.897 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: Early 2023)
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.898 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.918 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the high demand for AI-spec...' (Timeframe: 2023, 2020-2022)
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:214 - Error processing AI Hardware and Datacenters: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.919 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          │                └ {'id': 2, 'title': 'AI Hardware and Datacenters', 'content': 'The demand for H100 GPUs from NVIDIA is at an all-time high. In...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.936 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter examines the emerging regulatory envi...' (Timeframe: June 2023)
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:214 - Error processing AI Regulation: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.937 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          │                └ {'id': 3, 'title': 'AI Regulation', 'content': 'Governments are beginning to discuss the AI Act in Europe. In the US, there a...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.960 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter serves as a conclusion, emphasizing t...' (Timeframe: 2023)
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:57:48.961 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000026F5C8FBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000026F5C940220>
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 22068)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 22068)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000026F5D491530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x0000026F5D5AA340>
    └ ScriptRunner(_session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _main_script_path='app.py', _session_state={chapters: [{'id'...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='89d288b2-7abc-48d5-8fdf-5e7b84339e9f', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
        └ <function exec_func_with_error_handling at 0x0000026F5D530D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000026F621576A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000026F5AAB2BF0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000026F5D863150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 4, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x0000026F620A3420>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x0000026F620A3560>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x0000026F60F2C0E0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x0000026F60F1BD80>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x0000026F60F1B880>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:44.819 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 20:58:44.820 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 20:58:48.969 | DEBUG    | processor:analyze_all_chapters:79 - Received response from model
2025-12-23 20:58:48.970 | INFO     | processor:analyze_all_chapters:81 - Batch analysis successful
2025-12-23 20:58:48.970 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 20:58:53.462 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter introduces the recent surge in Artifi...' (Timeframe: Mid-2023)
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:214 - Error processing Introduction: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.464 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          │                └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: Early 2023)
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:214 - Error processing Large Language Models: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.491 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          │                └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.514 | INFO     | researcher:perform_research:27 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:214 - Error processing Conclusion: Unknown field for FunctionDeclaration: google_search
2025-12-23 20:58:53.515 | ERROR    | __main__:<module>:215 - Unknown field for FunctionDeclaration: google_search
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001AD58CBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001AD58D00220>
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18452)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18452)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001AD59851530>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-17848ce6bb60...
    │    └ <function ScriptRunner._run_script at 0x000001AD5996A340>
    └ ScriptRunner(_session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _main_script_path='app.py', _session_state={$$ID-d145211c64e...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='439c70f4-1770-49e8-b12c-07825cc1c203', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
        └ <function exec_func_with_error_handling at 0x000001AD598F0D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001AD5E55F2E0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001AD56F2A380, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

> File "F:\Horizon\report_updater_elisha_v1\app.py", line 202, in <module>
    findings = researcher.perform_research(chapter['topic'], chapter['timeframe'], st.session_state.api_key)
               │          │                │                 │                     │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001AD59C23150>
               │          │                │                 │                     └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
               │          │                │                 └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          │                └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
               │          └ <function perform_research at 0x000001AD5E4ABC40>
               └ <module 'researcher' from 'F:\\Horizon\\report_updater_elisha_v1\\researcher.py'>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 28, in perform_research
    model = get_research_model(api_key)
            │                  └ 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U'
            └ <function get_research_model at 0x000001AD5E459440>

  File "F:\Horizon\report_updater_elisha_v1\researcher.py", line 18, in get_research_model
    return genai.GenerativeModel(
           │     └ <class 'google.generativeai.generative_models.GenerativeModel'>
           └ <module 'google.generativeai' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generativeai\\_...

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\generative_models.py", line 87, in __init__
    self._tools = content_types.to_function_library(tools)
    │             │             │                   └ [{'google_search': {}}]
    │             │             └ <function to_function_library at 0x000001AD5E3C09A0>
    │             └ <module 'google.generativeai.types.content_types' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\goo...
    └ <unprintable GenerativeModel object>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 917, in to_function_library
    return FunctionLibrary(tools=lib)
           │                     └ [{'google_search': {}}]
           └ <class 'google.generativeai.types.content_types.FunctionLibrary'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 855, in __init__
    tools = _make_tools(tools)
            │           └ [{'google_search': {}}]
            └ <function _make_tools at 0x000001AD5E3C0680>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in _make_tools
    tools = [_make_tool(t) for t in tools]
             │                      └ [{'google_search': {}}]
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 898, in <listcomp>
    tools = [_make_tool(t) for t in tools]
             │          │      └ {'google_search': {}}
             │          └ {'google_search': {}}
             └ <function _make_tool at 0x000001AD5E3C0180>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\generativeai\types\content_types.py", line 823, in _make_tool
    return Tool(function_declarations=[protos.FunctionDeclaration(**fd)])
           │                           │      │                     └ {'google_search': {}}
           │                           │      └ <class 'google.ai.generativelanguage_v1beta.types.content.FunctionDeclaration'>
           │                           └ <module 'google.generativeai.protos' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\generati...
           └ <class 'google.generativeai.types.content_types.Tool'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\proto\message.py", line 724, in __init__
    raise ValueError(

ValueError: Unknown field for FunctionDeclaration: google_search
2025-12-23 21:14:44.441 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-23 21:14:45.102 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-23 21:14:49.854 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-23 21:14:49.854 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-23 21:14:49.855 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-23 21:14:58.112 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the recent ex...' (Timeframe: mid-2023)
2025-12-23 21:14:58.481 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:15:21.860 | INFO     | researcher:perform_research:42 - Research successful. Found 12108 characters of content.
2025-12-23 21:15:23.862 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:15:24.222 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:15:45.364 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:15:47.366 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter details the landscape of Large Langua...' (Timeframe: early 2023)
2025-12-23 21:15:47.762 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:09.674 | INFO     | researcher:perform_research:42 - Research successful. Found 11154 characters of content.
2025-12-23 21:16:11.677 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:12.027 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:16:26.683 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-23 21:16:28.686 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-23 21:16:29.012 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-23 21:16:46.375 | INFO     | researcher:perform_research:42 - Research successful. Found 9723 characters of content.
2025-12-23 21:16:48.377 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-23 21:16:48.711 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-23 21:17:11.604 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:27:49.696 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-24 10:27:50.456 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-24 10:27:55.243 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-24 10:27:55.245 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-24 10:27:55.247 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-24 10:28:45.890 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the significant rise in AI...' (Timeframe: Mid-2023)
2025-12-24 10:28:46.312 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:09.015 | INFO     | researcher:perform_research:42 - Research successful. Found 10491 characters of content.
2025-12-24 10:29:11.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:11.371 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:29:32.306 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:29:34.310 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter focuses on Large Language Models (LLM...' (Timeframe: Early 2023)
2025-12-24 10:29:34.681 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:29:54.234 | INFO     | researcher:perform_research:42 - Research successful. Found 7250 characters of content.
2025-12-24 10:29:56.237 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:29:56.605 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:30:17.885 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-24 10:30:19.887 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-24 10:30:20.250 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-24 10:30:41.015 | INFO     | researcher:perform_research:42 - Research successful. Found 8261 characters of content.
2025-12-24 10:30:43.019 | INFO     | updater:update_chapter:14 - Updating chapter content with research findings
2025-12-24 10:30:43.398 | DEBUG    | updater:update_chapter:42 - Sending writing prompt to gemini-2.5-flash
2025-12-24 10:31:01.544 | INFO     | updater:update_chapter:47 - Chapter update successful
2025-12-27 23:55:13.299 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-27 23:55:13.917 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-27 23:55:18.345 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-27 23:55:18.346 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-27 23:55:18.347 | INFO     | __main__:<module>:130 - Report structure analysis finalized
2025-12-27 23:56:10.830 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This introductory chapter highlights the significa...' (Timeframe: mid-2023)
2025-12-27 23:56:11.297 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:56:55.521 | INFO     | researcher:perform_research:42 - Research successful. Found 24714 characters of content.
2025-12-27 23:56:57.525 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:56:57.879 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:57:31.686 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:57:33.690 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter delves into the current landscape of ...' (Timeframe: early 2023)
2025-12-27 23:57:34.044 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:58:14.542 | INFO     | researcher:perform_research:42 - Research successful. Found 20622 characters of content.
2025-12-27 23:58:16.548 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:58:16.889 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-27 23:59:13.316 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-27 23:59:15.320 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter underscores the rapid evol...' (Timeframe: 2023)
2025-12-27 23:59:15.737 | DEBUG    | researcher:perform_research:32 - Sending research prompt to gemini-2.5-flash
2025-12-27 23:59:32.677 | INFO     | researcher:perform_research:42 - Research successful. Found 9811 characters of content.
2025-12-27 23:59:34.681 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-27 23:59:35.030 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 00:00:12.874 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:17:48.149 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-28 15:17:48.737 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-28 15:17:52.785 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-28 15:17:52.785 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-28 15:17:52.787 | INFO     | __main__:<module>:133 - Report structure analysis finalized
2025-12-28 15:17:59.361 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter introduces the report by highlighting...' (Timeframe: mid-2023)
2025-12-28 15:17:59.741 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:18:21.242 | INFO     | researcher:perform_research:44 - Research successful. Found 10131 characters of content.
2025-12-28 15:18:21.242 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:18:23.245 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:18:23.615 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:18:48.959 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:18:50.962 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This chapter discusses the landscape of Large Lang...' (Timeframe: early 2023)
2025-12-28 15:18:51.331 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:19:14.613 | INFO     | researcher:perform_research:44 - Research successful. Found 9606 characters of content.
2025-12-28 15:19:14.613 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:19:16.616 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:19:16.985 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:19:42.562 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-28 15:19:44.565 | INFO     | researcher:perform_research:17 - Performing research on topic: 'This concluding chapter emphasizes the rapid pace ...' (Timeframe: 2023)
2025-12-28 15:19:44.935 | DEBUG    | researcher:perform_research:34 - Sending research prompt to gemini-2.5-flash
2025-12-28 15:20:07.348 | INFO     | researcher:perform_research:44 - Research successful. Found 10421 characters of content.
2025-12-28 15:20:07.349 | DEBUG    | researcher:perform_research:64 - Search entry point found
2025-12-28 15:20:09.351 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-28 15:20:09.730 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-28 15:20:31.458 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:44:42.692 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-29 11:44:43.307 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-29 11:44:47.972 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-29 11:44:47.972 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-29 11:44:47.974 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-29 11:44:57.124 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:45:16.650 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant rise in popularity of Artificial Intelligence, catalyzed by the release of ChatGPT in late 2022. The report aims to provide a comprehensive overview of the AI industry's current status. It covers developments up to mid-2023.
2025-12-29 11:45:20.603 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:45:20.958 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:45:37.748 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:45:39.750 | INFO     | researcher:perform_research:100 - Researching 'This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:10.169 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on the advancements in Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions key competitors like Google's Bard and Meta's research-focused Llama 1. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2025-12-29 11:46:12.952 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:13.314 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:46:28.719 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-29 11:46:30.721 | INFO     | researcher:perform_research:100 - Researching 'The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.' via sources: ['Web Search', 'Academic Papers']
2025-12-29 11:46:48.931 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The conclusion emphasizes the rapid evolution of the Artificial Intelligence field. It posits that the year 2023 signifies a critical juncture, marking the official beginning of the generative AI era. This highlights a shift towards new capabilities and applications within AI.
2025-12-29 11:46:51.787 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-29 11:46:52.142 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-29 11:47:14.064 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:44:41.615 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2025-12-30 15:44:42.357 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2025-12-30 15:44:47.321 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2025-12-30 15:44:47.322 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2025-12-30 15:44:47.324 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2025-12-30 15:51:29.034 | INFO     | researcher:perform_research:100 - Researching 'This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:51:47.439 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This introductory chapter highlights the significant increase in Artificial Intelligence's popularity, largely spurred by the release of ChatGPT in late 2022. It sets the context for the report, which aims to provide an overview of the AI industry's status. The report will cover developments and the state of affairs as of mid-2023.
2025-12-30 15:51:51.143 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:51:51.486 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:07.301 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:09.304 | INFO     | researcher:perform_research:100 - Researching 'This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:52:28.602 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter delves into the current landscape of Large Language Models, noting GPT-4 as the state-of-the-art model in early 2023. It also mentions key contributions from other major players, such as Google's Bard and Meta's Llama 1, released for research. The primary development focus in the industry is identified as increasing model scale and parameter counts.
2025-12-30 15:52:31.384 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:52:31.734 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:52:55.703 | INFO     | updater:update_chapter:51 - Chapter update successful
2025-12-30 15:52:57.706 | INFO     | researcher:perform_research:100 - Researching 'The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.' via sources: ['Web Search', 'Academic Papers']
2025-12-30 15:53:12.097 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: The concluding chapter underscores the rapid evolution and dynamic nature of the Artificial Intelligence field. It specifically identifies 2023 as a landmark year, signifying the advent and beginning of the generative AI era. This marks a transformative period for the entire industry.
2025-12-30 15:53:20.828 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2025-12-30 15:53:21.171 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2025-12-30 15:53:34.584 | INFO     | updater:update_chapter:51 - Chapter update successful
2026-01-07 09:09:09.396 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:09:09.986 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:09:14.171 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:09:14.171 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:09:14.174 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 09:09:22.501 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:09:22.504 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This introductory chapter highlights the recent surge in Artificial Intelligence's popularity, primarily driven by the release of ChatGPT in late 2022. It establishes the purpose of the report, which is to provide a summary of the AI industry's current state. The analysis presented within the report is current as of mid-2023.
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:179 - Research Plan: ["What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?", 'What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?', "What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?"]
2026-01-07 09:09:28.215 | INFO     | researcher:perform_research:187 - Researching [1/3]: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:01.910 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What foundational developments and market shifts led to the rapid acceleration of AI adoption and public interest culminating in ChatGPT's late 2022 release?
2026-01-07 09:10:09.152 | INFO     | researcher:perform_research:187 - Researching [2/3]: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:43.394 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What significant technological advancements, market trends, and regulatory shifts have shaped the AI industry landscape between late 2023 and early 2025?
2026-01-07 09:10:55.384 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}
2026-01-07 09:10:55.384 | INFO     | researcher:perform_research:187 - Researching [3/3]: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:15.579 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: What are the key projected growth areas, ethical dilemmas, and practical challenges expected to define the AI industry's trajectory over the next 3-5 years?
2026-01-07 09:11:32.993 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 26.564203845s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 09:11:34.995 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:35.397 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:35.645 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:35.646 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ 'RESEARCH TOPIC: This introductory chapter highlights the recent surge in Artificial Intelligence\'s popularity, primarily dr...
                   │       │              └ {'id': 0, 'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the r...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D22CCD0>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
               └ <google.genai.models.Models object at 0x000002CA5D238F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
           │    └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d23b5d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D239590>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068169261712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D099940>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d2a1510 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d2a1510 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D22DAD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 23.916468723s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}
2026-01-07 09:11:37.742 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:37.743 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.274 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 21.284148628s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}
2026-01-07 09:11:38.274 | INFO     | researcher:perform_research:179 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts."]
2026-01-07 09:11:38.275 | INFO     | researcher:perform_research:187 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:38.802 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 20.758056872s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 09:11:38.803 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It notes the contributions of other major players, such as Google's Bard and Meta's research-focused Llama 1. The primary industry trend discussed for LLMs is the continuous effort to increase model scale and parameter counts.
2026-01-07 09:11:41.478 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:41.823 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:42.010 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. ...
                   │       │              └ {'id': 1, 'title': 'Large Language Models', 'content': 'As of early 2023, GPT-4 is the state-of-the-art model in the industry...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D1FAE90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
               └ <google.genai.models.Models object at 0x000002CA5D1BF710>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
           │    └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d1bf0d0 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D1BD9D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168762384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D14DC60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d155850 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d155850 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5BF81810>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 17.561626272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 09:11:44.040 | INFO     | researcher:perform_research:174 - Starting Deep Research for 'This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:11:44.040 | INFO     | researcher:generate_research_plan:97 - Generating research plan for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:44.579 | ERROR    | researcher:generate_research_plan:120 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.979854726s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:179 - Research Plan: ['This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.']
2026-01-07 09:11:44.579 | INFO     | researcher:perform_research:187 - Researching [1/1]: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:45.104 | ERROR    | researcher:search_web:161 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 14.454896646s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}
2026-01-07 09:11:45.104 | INFO     | researcher:search_openalex:19 - Searching OpenAlex for: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence domain. It marks the year 2023 as a pivotal moment, signaling the official beginning of the generative AI era.
2026-01-07 09:11:46.748 | ERROR    | researcher:search_openalex:88 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 12.810198849s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}
2026-01-07 09:11:48.750 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:11:49.130 | DEBUG    | updater:update_chapter:46 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:11:49.314 | ERROR    | updater:update_chapter:54 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:11:49.315 | ERROR    | updater:update_chapter:55 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002CA54E1BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002CA54E60220>
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 29240)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 29240)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002CA57DC1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000002CA57EDA340>
    └ ScriptRunner(_session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _main_script_path='app.py', _session_state={$$ID-9195a8cb6d1...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='34487cae-4c6c-4c67-9d8a-d5f18428245b', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
        └ <function exec_func_with_error_handling at 0x000002CA57E64D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002CA59742200>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000002CA55EF3750, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 246, in <module>
    updated_text = updater.update_chapter(chapter['content'], findings, st.session_state.api_key)
                   │       │              │                   │         │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002CA591C3C50>
                   │       │              │                   │         └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │       │              │                   └ "RESEARCH TOPIC: This concluding chapter underscores the rapid advancements occurring within the Artificial Intelligence doma...
                   │       │              └ {'id': 2, 'title': 'Conclusion', 'content': 'The AI field is moving fast, and 2023 marks the beginning of the generative AI e...
                   │       └ <function update_chapter at 0x000002CA5BF77060>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 47, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000002CA5BEF6E30>
               └ <google.genai.client.Client object at 0x000002CA5D16AE50>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000002CA5BAA5BC0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002CA5BA09D00>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
               └ <google.genai.models.Models object at 0x000002CA5D179F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002CA5BA09A80>
               └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002CA5BA099E0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
           │    └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002CA5B99CEA0>
         └ <Retrying object at 0x2ca5d179e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000002CA5D17B110>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 3068168477392: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002CA5D21D3A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002CA5B99C400>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002CA57BB2FC0>
          │    └ <Future at 0x2ca5d178810 state=finished raised ClientError>
          └ RetryError(<Future at 0x2ca5d178810 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000002CA5D23FFD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002CA5B99F7E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002CA5B99F920>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 5, model: gemini-2.5-flash\nPlease retry in 10.247610098s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '5'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 09:50:42.599 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 09:50:43.160 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 09:50:48.561 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 09:50:48.561 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 09:50:48.563 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 09:51:11.590 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:51:11.592 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This introductory chapter highlights the recent explosion in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It frames the report's purpose, which is to provide an overview of the AI industry's current status. The analysis within the report is specifically scoped to cover the period up to mid-2023.
2026-01-07 09:51:17.213 | INFO     | researcher:perform_research:190 - Research Plan: ['What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?', 'What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?']
2026-01-07 09:51:17.215 | INFO     | researcher:perform_research:202 - Researching [1/2]: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:51:35.760 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the immediate market and technological shifts in the AI industry following the release of ChatGPT in late 2022?
2026-01-07 09:52:13.970 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 45.664957344s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}
2026-01-07 09:52:28.972 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:29.541 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 30.094766163s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '30s'}]}}
2026-01-07 09:52:29.541 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the key technological advancements and market challenges projected for the AI industry between 2024 and 2025?
2026-01-07 09:52:46.418 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 13.221090948s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '13s'}]}}
2026-01-07 09:53:01.421 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:01.802 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:02.007 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:02.012 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3391D8A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
               └ <google.genai.models.Models object at 0x000001B3391D9890>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
           │    └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b3391d8b50 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B3391D9090>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869269013904: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B3391574C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b3391dbd10 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b3391dbd10 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3391D89D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 57.627163778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}
2026-01-07 09:53:17.115 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 09:53:17.115 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:17.678 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.971405313s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:190 - Research Plan: ["This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts."]
2026-01-07 09:53:17.679 | INFO     | researcher:perform_research:202 - Researching [1/1]: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:18.190 | ERROR    | researcher:search_web:172 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.442764386s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 09:53:18.190 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter details the landscape of Large Language Models (LLMs), identifying GPT-4 as the leading model as of early 2023. It also covers other significant developments, including the release of Google's Bard and Meta's Llama 1 for research. The primary focus in LLM development is currently on increasing model scale and parameter counts.
2026-01-07 09:53:35.186 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 24.449533971s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}
2026-01-07 09:53:50.189 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 09:53:50.557 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 09:53:50.739 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 09:53:50.740 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001B330DBBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001B330E00220>
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 31840)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 31840)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001B333D61C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-f4ceede1413b...
    │    └ <function ScriptRunner._run_script at 0x000001B333E7A340>
    └ ScriptRunner(_session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _main_script_path='app.py', _session_state={$$ID-17848ce6bb6...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='51e9b632-66a7-48c9-95c5-8617a22a3fe3', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
        └ <function exec_func_with_error_handling at 0x000001B333E04D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001B3390136A0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001B334989600, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001B337F76CA0>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001B337EEEE80>
               └ <google.genai.client.Client object at 0x000001B3392CC150>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001B337A9D4E0>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001B337A09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
               └ <google.genai.models.Models object at 0x000001B33930FCD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001B337A093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001B337A09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
           │    └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001B33799C7C0>
         └ <Retrying object at 0x1b33930ffd0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001B33930F5D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1869270286544: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001B339154E00>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001B33798BCE0>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001B333B52FC0>
          │    └ <Future at 0x1b339311d90 state=finished raised ClientError>
          └ RetryError(<Future at 0x1b339311d90 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyARSgRTlOsIQNw567YGIVDJvNlVm0Udk2U', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001B3392CB250>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001B33799F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001B33799F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 8.897314725s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}
2026-01-07 10:14:50.470 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:14:50.847 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:14:55.553 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:14:55.554 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:14:55.555 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:15:12.212 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:15:12.212 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the recent surge in AI's popularity, primarily driven by the release of ChatGPT in late 2022. It states that the report aims to summarize the state of the AI industry as of mid-2023. The widespread attention garnered by AI marks a significant shift in its public perception and application.
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?', "What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?"]
2026-01-07 10:15:20.646 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:15:49.985 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the initial post-ChatGPT surge in AI popularity reshaped industry adoption and public perception from mid-2023 through early 2025?
2026-01-07 10:16:26.772 | INFO     | researcher:perform_research:202 - Researching [2/2]: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:16:47.377 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What emerging AI technologies, applications, and their associated ethical and technical challenges are defining the industry's future trajectory in 2024-2025?
2026-01-07 10:17:46.355 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:17:46.755 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:19:23.031 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:19:38.034 | INFO     | researcher:perform_research:185 - Starting Deep Research for 'This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:19:38.035 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter discusses the current landscape of Large Language Models (LLMs), highlighting GPT-4 as the state-of-the-art as of early 2023. It mentions key competitors like Google's Bard and Meta's Llama 1, released for research. The primary focus in the industry is currently on scaling these models and increasing their parameter counts to enhance performance.
2026-01-07 10:19:46.939 | INFO     | researcher:perform_research:190 - Research Plan: ['How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?', 'What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?']
2026-01-07 10:19:46.940 | INFO     | researcher:perform_research:202 - Researching [1/2]: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:20:16.110 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: How has the competitive landscape and scaling strategies for state-of-the-art Large Language Models evolved since early 2023, and what are the key architectural and performance breakthroughs anticipated by 2025?
2026-01-07 10:21:09.081 | INFO     | researcher:perform_research:202 - Researching [2/2]: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:21:40.254 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What are the critical challenges and potential limitations for Large Language Models beyond current scaling paradigms, and what ethical considerations or novel architectural directions are projected to shape their long-term development and responsible deployment by 2025?
2026-01-07 10:22:14.716 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:22:15.051 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:22:34.756 | INFO     | updater:update_chapter:52 - Chapter update successful
2026-01-07 10:48:14.810 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:48:15.187 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:48:39.728 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:48:39.728 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:48:39.730 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:49:18.526 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 12 chapters
2026-01-07 10:49:18.879 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:49:43.236 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:49:43.236 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:49:43.238 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:12.610 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 10:51:12.980 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 10:51:17.738 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 10:51:17.739 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 10:51:17.740 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 10:51:22.165 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:51:22.167 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter introduces the significant rise in Artificial Intelligence's popularity, largely attributed to the release of ChatGPT in late 2022. It sets the scope for the report, which aims to provide a comprehensive summary of the AI industry's status. The report's analysis specifically focuses on the state of AI as of mid-2023.
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:206 - Research Plan: ["What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?", 'Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?']
2026-01-07 10:51:31.010 | INFO     | researcher:perform_research:218 - Researching [1/2]: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:01.435 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: What were the pivotal shifts in AI adoption and industry status following ChatGPT's release through mid-2023, and what key technological advancements and market trends have defined the generative AI sector in late 2023 and early 2024?
2026-01-07 10:52:38.711 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 20.884116721s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}
2026-01-07 10:52:53.713 | INFO     | researcher:perform_research:218 - Researching [2/2]: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:52:54.243 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 5.343283131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}
2026-01-07 10:52:54.243 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: Looking ahead to 2025 and beyond, what emerging applications and foundational research are expected to drive the next wave of AI innovation, and what are the primary regulatory, ethical, and market adoption challenges anticipated?
2026-01-07 10:53:11.097 | ERROR    | researcher:search_openalex:95 - OpenAlex search failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.493779927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 10:53:26.100 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:26.462 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:26.705 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73680D90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
               └ <google.genai.models.Models object at 0x0000023A73681C90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
           │    └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a73681f50 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A73681450>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450067562704: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A73698900>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a736b1710 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a736b1710 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A73680DD0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 32.88457809s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '32s'}]}}
2026-01-07 10:53:41.742 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.' sources=['Web Search', 'Academic Papers']
2026-01-07 10:53:41.743 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.275 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 17.311817408s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:206 - Research Plan: ["This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts."]
2026-01-07 10:53:42.275 | INFO     | researcher:perform_research:218 - Researching [1/1]: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:42.825 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 16.75827837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-01-07 10:53:42.829 | INFO     | researcher:search_openalex:20 - Searching OpenAlex for: This chapter focuses on Large Language Models (LLMs), identifying GPT-4 as the leading model in early 2023. It also mentions other significant players in the field, such as Google's Bard and Meta's Llama 1, which was released for research. The primary development trend discussed is the emphasis on increasing model scale and parameter counts.
2026-01-07 10:53:58.626 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 10:53:58.991 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 10:53:59.173 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 10:53:59.175 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x0000023A6D70BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x0000023A6D750220>
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42092)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42092)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000023A6E2A1C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x0000023A6E3BA340>
    └ ScriptRunner(_session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _main_script_path='app.py', _session_state={$$ID-2e29ce142ea...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='dc013af4-42bf-4662-a5cd-68a2b122f727', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
        └ <function exec_func_with_error_handling at 0x0000023A6E344D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x0000023A715420C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000023A6BF759C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x0000023A73476B60>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x0000023A733EEED0>
               └ <google.genai.client.Client object at 0x0000023A73789790>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000023A71F9D4E0>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000023A71F09620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
               └ <google.genai.models.Models object at 0x0000023A737A5910>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000023A71F093A0>
               └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000023A71F09300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
           │    └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000023A71E9C7C0>
         └ <Retrying object at 0x23a737a5c10 (stop=<tenacity.stop.stop_after_attempt object at 0x0000023A737695D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2450068757712: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x0000023A7361D1C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000023A71E8BCE0>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x0000023A6E092FC0>
          │    └ <Future at 0x23a7379d650 state=finished raised ClientError>
          └ RetryError(<Future at 0x23a7379d650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x0000023A736BE850>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000023A71E9F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000023A71E9F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 416.156527ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 14:36:12.208 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 14:36:12.780 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:36:17.840 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 14:36:17.841 | INFO     | processor:analyze_all_chapters:84 - Batch analysis successful
2026-01-07 14:36:17.843 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 14:36:31.908 | INFO     | researcher:perform_research:201 - Starting Deep Research for 'The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.' sources=['Web Search']
2026-01-07 14:36:31.908 | INFO     | researcher:generate_research_plan:104 - Generating research plan for: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:32.454 | ERROR    | researcher:generate_research_plan:131 - Failed to generate research plan: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.663638973s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:206 - Research Plan: ["The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023."]
2026-01-07 14:36:32.455 | INFO     | researcher:perform_research:218 - Researching [1/1]: The field of Artificial Intelligence experienced a significant boost in public interest following the release of ChatGPT in late 2022. This report aims to provide a comprehensive overview of the industry's current landscape. It specifically focuses on the state of AI as observed in mid-2023.
2026-01-07 14:36:33.032 | ERROR    | researcher:search_web:188 - Web research failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 26.077471594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '26s'}]}}
2026-01-07 14:36:48.035 | INFO     | updater:update_chapter:15 - Updating chapter content with research findings
2026-01-07 14:36:48.384 | DEBUG    | updater:update_chapter:47 - Sending writing prompt to gemini-2.5-flash
2026-01-07 14:36:48.571 | ERROR    | updater:update_chapter:55 - Failed to update chapter: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:36:48.572 | ERROR    | updater:update_chapter:56 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001A5426BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001A542700220>
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 25196)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 25196)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001A543251C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001A54336A340>
    └ ScriptRunner(_session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _main_script_path='app.py', _session_state={$$ID-0e9d11a9dce...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ff39b438-ff75-47e6-a24a-e91e3c2ec9d2', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
        └ <function exec_func_with_error_handling at 0x000001A5432F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001A54861D440>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001A5444E8510, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 276, in <module>
    updated_text = updater.update_chapter(
                   │       └ <function update_chapter at 0x000001A548476D40>
                   └ <module 'updater' from 'F:\\Horizon\\report_updater_elisha_v1\\updater.py'>

> File "F:\Horizon\report_updater_elisha_v1\updater.py", line 48, in update_chapter
    response = client.models.generate_content(
               │      └ <property object at 0x000001A5483F2ED0>
               └ <google.genai.client.Client object at 0x000001A548586690>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001A546EC14E0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001A546E2D620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
               └ <google.genai.models.Models object at 0x000001A5486A8410>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001A546E2D3A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001A546E2D300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
           │    └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001A546DAC7C0>
         └ <Retrying object at 0x1a548563ad0 (stop=<tenacity.stop.stop_after_attempt object at 0x000001A5485DADD0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1809396172176: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001A54863BBA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001A546D9BCE0>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001A543042FC0>
          │    └ <Future at 0x1a5486aa650 state=finished raised ClientError>
          └ RetryError(<Future at 0x1a5486aa650 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001A5485852D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001A546DAF100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001A546DAF240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 10.540337777s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}
2026-01-07 14:43:13.080 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:43:13.495 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:43:13.832 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 46.26599367s before retry 1/5...
2026-01-07 14:44:00.287 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.802821959s before retry 2/5...
2026-01-07 14:45:00.395 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.699339048s before retry 3/5...
2026-01-07 14:46:00.423 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.671072864s before retry 4/5...
2026-01-07 14:53:18.922 | INFO     | processor:analyze_all_chapters:51 - Starting batch analysis for 3 chapters
2026-01-07 14:53:19.316 | DEBUG    | processor:analyze_all_chapters:77 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 14:53:19.661 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 40.419676436s before retry 1/5...
2026-01-07 14:54:00.270 | WARNING  | utils:generate_content_with_retry:26 - Rate limit hit (429). Waiting 59.80022709s before retry 2/5...
2026-01-07 15:00:42.239 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:00:42.624 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:00:42.969 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 17.098254937s before retry 1/5...
2026-01-07 15:01:00.283 | WARNING  | utils:generate_content_with_retry:27 - Rate limit hit. Waiting 59.779638306s before retry 2/5...
2026-01-07 15:02:09.752 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:02:10.132 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.454 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001646F5BBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001646F600220>
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 42504)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 42504)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x0000016470151C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001647026A340>
    └ ScriptRunner(_session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _main_script_path='app.py', _session_state={$$ID-7ed703377b3...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='861a6455-5528-43f6-bb51-7d33efbaa15c', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
        └ <function exec_func_with_error_handling at 0x00000164701F4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000164701116C0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001647188A7B0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x0000016470523C10>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001647537B6A0>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000164752F7F60>
               └ <google.genai.client.Client object at 0x0000016475387810>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x0000016473E96700>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x0000016473E12840>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
               └ <google.genai.models.Models object at 0x00000164754B1CD0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x0000016473E125C0>
               └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x0000016473E12520>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
           │    └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x0000016473DA19E0>
         └ <Retrying object at 0x16475386190 (stop=<tenacity.stop.stop_after_attempt object at 0x00000164754E8390>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 1530976437264: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000164753C4EA0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x0000016473DA0F40>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001646FF42FC0>
          │    └ <Future at 0x16475583b50 state=finished raised ClientError>
          └ RetryError(<Future at 0x16475583b50 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000164753849D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x0000016473DBC360>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x0000016473DBC4A0>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 48.601946962s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}
2026-01-07 15:02:10.479 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:15.837 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:16.224 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.550 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000002401A86BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000002401A8B0220>
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 18380)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 18380)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000002401B401C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000002401B51A340>
    └ ScriptRunner(_session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f90b8455-cb25-4f5f-bb5b-3a3c88d7bac9', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
        └ <function exec_func_with_error_handling at 0x000002401B4A4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000002402060FCE0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x0000024018F322C0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 160, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000002401B7D3C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000002402057FA60>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000240204F3E20>
               └ <google.genai.client.Client object at 0x000002402058B850>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000240200AE980>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000002402000EAC0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
               └ <google.genai.models.Models object at 0x000002402074BD50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000002402000E840>
               └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000002402000E7A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
           │    └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000002401EF9DC60>
         └ <Retrying object at 0x24020696890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000240206DB2D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2474445754384: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000002402072A700>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000002401EF9D1C0>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000002401B1F2FC0>
          │    └ <Future at 0x2402075f150 state=finished raised ClientError>
          └ RetryError(<Future at 0x2402075f150 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000240206731D0>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000002401EFB85E0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000002401EFB8720>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 42.496924554s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}
2026-01-07 15:04:16.574 | INFO     | __main__:<module>:179 - Report structure analysis finalized
2026-01-07 15:04:58.257 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 15:04:58.650 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 15:04:58.867 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.868 | ERROR    | processor:analyze_all_chapters:88 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x00000247F4BDBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x00000247F4C20220>
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 35460)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 35460)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x00000247F5771C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x00000247F588A340>
    └ ScriptRunner(_session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _main_script_path='app.py', _session_state={chapters: [], $$...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='ccf03f2a-8071-4ca1-a9da-341473f84735', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
        └ <function exec_func_with_error_handling at 0x00000247F5814D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x00000247F8980540>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x00000247F2FCA050, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 141, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x00000247F5B43C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x00000247F9900360>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 77, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x00000247F9894680>
               └ <google.genai.client.Client object at 0x00000247F9A0B910>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x00000247F93E3380>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x00000247F935F4C0>
               │    └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
               └ <google.genai.models.Models object at 0x00000247F9AC91D0>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x00000247F935F240>
               └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x00000247F935F1A0>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
           │    └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x00000247F92D6660>
         └ <Retrying object at 0x247f9a59890 (stop=<tenacity.stop.stop_after_attempt object at 0x00000247F9A0A8D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2508154322192: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x00000247F9A05C60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x00000247F92D5BC0>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x00000247F5562FC0>
          │    └ <Future at 0x247f9ad4610 state=finished raised ClientError>
          └ RetryError(<Future at 0x247f9ad4610 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x00000247F814CF50>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x00000247F92ECFE0>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x00000247F92ED120>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 174.230603ms.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '0s'}]}}
2026-01-07 15:04:58.887 | INFO     | __main__:<module>:160 - Report structure analysis finalized
2026-01-07 19:16:57.307 | INFO     | processor:analyze_all_chapters:50 - Starting batch analysis for 3 chapters
2026-01-07 19:16:57.890 | DEBUG    | processor:analyze_all_chapters:76 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:17:02.488 | DEBUG    | processor:analyze_all_chapters:82 - Received response from model
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:87 - Error in batch analysis: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.488 | ERROR    | processor:analyze_all_chapters:88 - Expecting ',' delimiter: line 6 column 3 (char 435)
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001CDACEFBEC0>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001CDACF40220>
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 36616)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 36616)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001CDADA91C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001CDADBAA340>
    └ ScriptRunner(_session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _main_script_path='app.py', _session_state={source_metadata:...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f27ca754-295e-4931-bda9-9f9a7c45af5e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
        └ <function exec_func_with_error_handling at 0x000001CDADB34D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001CDB1CA1B20>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001CDAAF41EB0, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001CDADE63C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001CDB1C01D00>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 83, in analyze_all_chapters
    results = json.loads(response.text)
              │    │     │        └ <property object at 0x000001CDB1052CF0>
              │    │     └ GenerateContentResponse(
              │    │         automatic_function_calling_history=[],
              │    │         candidates=[
              │    │           Candidate(
              │    │             content=Content(
              │    │             ...
              │    └ <function loads at 0x000001CDAD1D6160>
              └ <module 'json' from 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib...

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           │                │      └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
           │                └ <function JSONDecoder.decode at 0x000001CDAD1D5A80>
           └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               │    │          │      │  └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    │          │      └ <built-in method match of re.Pattern object at 0x000001CDAD1ADD80>
               │    │          └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <function JSONDecoder.raw_decode at 0x000001CDAD1D5B20>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\json\decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
               │    │         │  └ 0
               │    │         └ '[\n  {\n    "summary": "This chapter introduces the report, highlighting the recent surge in Artificial Intelligence\'s popu...
               │    └ <_json.Scanner object at 0x000001CDAD19BBE0>
               └ <json.decoder.JSONDecoder object at 0x000001CDAD112A50>

json.decoder.JSONDecodeError: Expecting ',' delimiter: line 6 column 3 (char 435)
2026-01-07 19:17:02.503 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-07 19:50:16.203 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-07 19:50:16.579 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:99 - Error in batch analysis: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:16.929 | ERROR    | processor:analyze_all_chapters:100 - 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
Traceback (most recent call last):

  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1002, in _bootstrap
    self._bootstrap_inner()
    │    └ <function Thread._bootstrap_inner at 0x000001F636A9BEC0>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 1045, in _bootstrap_inner
    self.run()
    │    └ <function Thread.run at 0x000001F636AE0220>
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    │        │    └ ()
    │    │        └ <Thread(ScriptRunner.scriptThread, started 10472)>
    │    └ <bound method ScriptRunner._run_script_thread of ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_scrip...
    └ <Thread(ScriptRunner.scriptThread, started 10472)>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 378, in _run_script_thread
    self._run_script(request.rerun_data)
    │    │           │       └ <property object at 0x000001F637631C10>
    │    │           └ ScriptRequest(type=<ScriptRequestType.RERUN: 'RERUN'>, _rerun_data=RerunData(widget_states=widgets {
    │    │               id: "$$ID-8ccf69aff756...
    │    └ <function ScriptRunner._run_script at 0x000001F63774A340>
    └ ScriptRunner(_session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _main_script_path='app.py', _session_state={api_key: 'AIzaSy...
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 687, in _run_script
    ) = exec_func_with_error_handling(code_to_exec, ctx)
        │                             │             └ ScriptRunContext(session_id='f3f2816d-3f67-4f31-af20-a4a257669d3e', _enqueue=<bound method ScriptRunner._enqueue_forward_msg ...
        │                             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
        └ <function exec_func_with_error_handling at 0x000001F6376D4D60>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\exec_code.py", line 129, in exec_func_with_error_handling
    result = func()
             └ <function ScriptRunner._run_script.<locals>.code_to_exec at 0x000001F63C843740>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py", line 671, in code_to_exec
    exec(code, module.__dict__)  # noqa: S102
         │     │      └ <member '__dict__' of 'module' objects>
         │     └ <module '__main__' from 'app.py'>
         └ <code object <module> at 0x000001F634F1DD00, file "F:\Horizon\report_updater_elisha_v1\app.py", line 1>

  File "F:\Horizon\report_updater_elisha_v1\app.py", line 132, in <module>
    all_analysis = processor.analyze_all_chapters(raw_chapters, st.session_state.api_key)
                   │         │                    │             │  └ <streamlit.runtime.state.session_state_proxy.SessionStateProxy object at 0x000001F637A03C50>
                   │         │                    │             └ <module 'streamlit' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\streamlit\\__init__.py'>
                   │         │                    └ [{'title': 'Introduction', 'content': 'Artificial Intelligence has seen a massive surge in popularity following the release o...
                   │         └ <function analyze_all_chapters at 0x000001F63C796660>
                   └ <module 'processor' from 'F:\\Horizon\\report_updater_elisha_v1\\processor.py'>

> File "F:\Horizon\report_updater_elisha_v1\processor.py", line 87, in analyze_all_chapters
    response = client.models.generate_content(
               │      └ <property object at 0x000001F63C71ECA0>
               └ <google.genai.client.Client object at 0x000001F636A67A90>

  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               │    └ <function Models._generate_content at 0x000001F63C29D4E0>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               │    │           └ <function BaseApiClient.request at 0x000001F63C205620>
               │    └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
               └ <google.genai.models.Models object at 0x000001F63C969590>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               │    │        │             └ None
               │    │        └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
               │    └ <function BaseApiClient._request at 0x000001F63C2053A0>
               └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           │    │      │    │              │             └ False
           │    │      │    │              └ HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-a...
           │    │      │    └ <function BaseApiClient._request_once at 0x000001F63C205300>
           │    │      └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
           │    └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
           └ <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         │    │                └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
         │    └ <function BaseRetrying.iter at 0x000001F63C19C7C0>
         └ <Retrying object at 0x1f63c8b1e90 (stop=<tenacity.stop.stop_after_attempt object at 0x000001F63C9007D0>, wait=<tenacity.wait....
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             │      └ <RetryCallState 2157089684688: attempt #1; slept for 0.0; last result: failed (ClientError 429 RESOURCE_EXHAUSTED. {'error': ...
             └ <function BaseRetrying._post_stop_check_actions.<locals>.exc_check at 0x000001F63C843420>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          │         └ <function RetryError.reraise at 0x000001F63C187CE0>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          │    │            └ <function Future.result at 0x000001F637422FC0>
          │    └ <Future at 0x1f63c970fd0 state=finished raised ClientError>
          └ RetryError(<Future at 0x1f63c970fd0 state=finished raised ClientError>)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           └ None
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
          └ None
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             │   │       └ {}
             │   └ (HttpRequest(headers={'Content-Type': 'application/json', 'x-goog-api-key': 'AIzaSyAsySFdPwQhtYnskwyKMWky2jBZymJzsp8', 'user-...
             └ <bound method BaseApiClient._request_once of <google.genai._api_client.BaseApiClient object at 0x000001F63C7B0F90>>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
    │      │        │                  └ <Response [429 Too Many Requests]>
    │      │        └ <classmethod(<function APIError.raise_for_response at 0x000001F63C19F100>)>
    │      └ <class 'google.genai.errors.APIError'>
    └ <module 'google.genai.errors' from 'f:\\Horizon\\report_updater_elisha_v1\\.venv\\Lib\\site-packages\\google\\genai\\errors.py'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
    │   │           │        │            │              └ <Response [429 Too Many Requests]>
    │   │           │        │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
    │   │           │        └ 429
    │   │           └ <Response [429 Too Many Requests]>
    │   └ <classmethod(<function APIError.raise_error at 0x000001F63C19F240>)>
    └ <class 'google.genai.errors.APIError'>
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
          │           │            │              └ <Response [429 Too Many Requests]>
          │           │            └ {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more inf...
          │           └ 429
          └ <class 'google.genai.errors.ClientError'>

google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 41.413565599s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}
2026-01-07 19:50:17.020 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-08 09:27:30.290 | INFO     | processor:analyze_all_chapters:49 - Starting batch analysis for 3 chapters
2026-01-08 09:27:30.893 | DEBUG    | processor:analyze_all_chapters:86 - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:27:35.564 | INFO     | processor:analyze_all_chapters:96 - Batch analysis successful
2026-01-08 09:27:35.566 | INFO     | __main__:<module>:151 - Report structure analysis finalized
2026-01-08 09:44:52,765 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:44:53,189 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:44:53,370 - processor - ERROR - Error in batch analysis: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 09:44:53,370 - processor - ERROR - 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1201, in _request_once
    errors.APIError.raise_for_response(response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 121, in raise_for_response
    cls.raise_error(response.status_code, response_json, response)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\errors.py", line 146, in raise_error
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'Your API key was reported as leaked. Please use another API key.', 'status': 'PERMISSION_DENIED'}}
2026-01-08 09:46:06,396 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:46:06,810 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:46:11,781 - processor - INFO - Batch analysis successful
2026-01-08 09:47:59,637 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:48:00,017 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:48:05,077 - processor - INFO - Batch analysis successful
2026-01-08 09:57:30,559 - processor - INFO - Starting batch analysis for 12 chapters
2026-01-08 09:57:30,983 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:57:30,985 - processor - ERROR - Error in batch analysis: 'ascii' codec can't encode character '\u274c' in position 0: ordinal not in range(128)
2026-01-08 09:57:30,985 - processor - ERROR - 'ascii' codec can't encode character '\u274c' in position 0: ordinal not in range(128)
Traceback (most recent call last):
  File "F:\Horizon\report_updater_elisha_v1\processor.py", line 93, in analyze_all_chapters
    response = client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 5203, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\models.py", line 3985, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1388, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1224, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\google\genai\_api_client.py", line 1194, in _request_once
    response = self._httpx_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_client.py", line 812, in request
    request = self.build_request(
              ^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_client.py", line 367, in build_request
    headers = self._merge_headers(headers)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_client.py", line 430, in _merge_headers
    merged_headers.update(headers)
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_models.py", line 275, in update
    headers = Headers(headers)
              ^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_models.py", line 156, in __init__
    bytes_value = _normalize_header_value(v, encoding)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "f:\Horizon\report_updater_elisha_v1\.venv\Lib\site-packages\httpx\_models.py", line 82, in _normalize_header_value
    return value.encode(encoding or "ascii")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: 'ascii' codec can't encode character '\u274c' in position 0: ordinal not in range(128)
2026-01-08 09:59:25,259 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 09:59:25,671 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 09:59:35,084 - processor - INFO - Batch analysis successful
2026-01-08 10:19:38,914 - processor - INFO - Starting batch analysis for 3 chapters
2026-01-08 10:19:39,298 - processor - DEBUG - Sending batch analysis prompt to gemini-2.5-flash
2026-01-08 10:19:43,774 - processor - INFO - Batch analysis successful
